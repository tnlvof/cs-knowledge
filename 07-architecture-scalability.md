# 아키텍처/확장성 (Architecture & Scalability) - IT 서비스 운영 필수 지식

> 이 문서는 IT 서비스 운영에 필요한 아키텍처 및 확장성 지식을 레벨별로 정리한 학습 자료입니다.
> 퀴즈 생성 및 역량 평가에 활용할 수 있습니다.

## 레벨 가이드

| 레벨 | 대상 | 설명 |
|------|------|------|
| ⭐ Level 1 | 입문 | 개념 이해, 기본 용어 |
| ⭐⭐ Level 2 | 주니어 | 실무 적용, 트러블슈팅 기초 |
| ⭐⭐⭐ Level 3 | 시니어 | 아키텍처 설계, 성능 최적화 |
| ⭐⭐⭐⭐ Level 4 | 리드/CTO | 전략적 의사결정, 대규모 설계 |

---

## 1. 모놀리스 vs 마이크로서비스

### 개념 설명

모놀리스는 애플리케이션의 모든 기능이 하나의 코드베이스에 포함된 아키텍처다. 마이크로서비스는 기능별로 독립적인 서비스로 분리하여 각각 배포, 확장, 개발할 수 있는 아키텍처다.

### 레벨별 지식

> ⭐ **Level 1 (입문)**
> - 모놀리스와 마이크로서비스의 기본 개념
> - 각 아키텍처의 특징
> - 간단한 장단점 비교
>
> **Q: 모놀리스 아키텍처란?**
> **A:** 모든 기능이 단일 애플리케이션으로 통합된 구조. 하나의 코드베이스, 하나의 배포 단위, 하나의 데이터베이스를 공유한다.
>
> **Q: 마이크로서비스 아키텍처란?**
> **A:** 비즈니스 기능별로 독립적인 서비스로 분리된 구조. 각 서비스는 자체 데이터베이스를 가지고 API로 통신한다.
>
> **Q: 모놀리스의 장점은?**
> **A:** 개발과 배포가 단순, 로컬 함수 호출로 빠른 통신, 트랜잭션 관리 용이, 초기 개발 속도 빠름.
>
> **Q: 마이크로서비스의 장점은?**
> **A:** 서비스별 독립 배포, 기술 스택 자유로운 선택, 장애 격리, 팀별 독립 개발, 서비스별 확장 가능.

> ⭐⭐ **Level 2 (주니어)**
> - 각 아키텍처의 상세 장단점
> - 언제 어떤 아키텍처를 선택하는가
> - 모듈러 모놀리스 개념
>
> **Q: 모놀리스의 단점은?**
> **A:** 코드베이스 커지면 복잡도 증가, 작은 변경에도 전체 배포, 기술 스택 변경 어려움, 특정 기능만 확장 불가, 장애 전파 위험.
>
> **Q: 마이크로서비스의 단점은?**
> **A:** 분산 시스템 복잡성, 서비스 간 통신 오버헤드, 데이터 일관성 관리 어려움, 운영/모니터링 복잡, 초기 개발 비용 높음.
>
> **Q: 모듈러 모놀리스(Modular Monolith)란?**
> **A:** 모놀리스의 단순함을 유지하면서 내부를 모듈로 분리한 구조. 모듈 간 명확한 경계, 인터페이스 정의. 추후 마이크로서비스 전환 용이.
>
> **Q: 스타트업에서 어떤 아키텍처를 선택해야 하는가?**
> **A:** 초기에는 모놀리스로 시작하여 빠르게 제품 검증. 규모가 커지고 팀이 늘어나면 점진적으로 마이크로서비스 분리 고려.

> ⭐⭐⭐ **Level 3 (시니어)**
> - Strangler Fig 패턴
> - 서비스 분리 기준
> - 마이크로서비스 통신 패턴
>
> **Q: Strangler Fig 패턴이란?**
> **A:** 모놀리스를 점진적으로 마이크로서비스로 전환하는 패턴. 새 기능은 마이크로서비스로 개발, 기존 기능은 하나씩 추출하여 구 시스템을 점차 대체.
>
> **Q: 서비스 분리의 기준은?**
> **A:** 비즈니스 도메인(Bounded Context), 팀 구조, 변경 빈도, 확장 요구사항, 기술적 요구사항이 다른 경우. DDD 원칙 적용.
>
> **Q: 동기 vs 비동기 통신의 선택 기준은?**
> **A:** 동기(REST/gRPC)는 즉각적인 응답이 필요할 때. 비동기(메시지 큐)는 느슨한 결합, 장애 격리, 처리량 조절이 필요할 때.
>
> **Q: 서비스 간 데이터 공유는 어떻게 하는가?**
> **A:** API 호출, 이벤트 발행/구독, 데이터 복제. 직접 DB 접근은 금지. 서비스는 자신의 데이터에 대한 소유권을 가짐.

> ⭐⭐⭐⭐ **Level 4 (리드/CTO)**
> - 마이크로서비스 전환 전략
> - 조직 구조와 아키텍처
> - 운영 성숙도 평가
>
> **Q: 마이크로서비스 도입 전 필요한 것은?**
> **A:** CI/CD 파이프라인, 컨테이너 오케스트레이션, 서비스 디스커버리, 분산 모니터링, 로그 집계, 팀 조직 재편. 인프라와 문화적 준비가 선행.
>
> **Q: Conway의 법칙과 아키텍처의 관계는?**
> **A:** "시스템 구조는 조직의 커뮤니케이션 구조를 반영한다." 마이크로서비스 성공을 위해 팀을 서비스 단위로 조직하고 자율성 부여.
>
> **Q: 마이크로서비스로 전환하면 안 되는 경우는?**
> **A:** 소규모 팀, 도메인이 명확히 분리되지 않음, 운영 역량 부족, 빈번한 서비스 간 트랜잭션, 레거시 시스템 의존도 높음.

### 실무 시나리오

**시나리오: 모놀리스에서 서비스 분리 결정**
- 상황: 주문 처리 부하 증가로 전체 시스템 느려짐
- 분석: 주문 서비스만 별도 확장 필요, 결제는 외부 PG사와 통신
- 결정: 주문/결제 서비스 먼저 분리, API Gateway 도입, 이벤트로 재고 동기화

### 면접 빈출 질문
- Q: 마이크로서비스의 적절한 크기는?
- A: "한 팀이 소유하고 2주 내 재작성 가능한 크기", "단일 비즈니스 역량" 등의 기준. 너무 작으면 오버헤드, 너무 크면 모놀리스의 문제 발생.

---

## 2. API 설계

### 개념 설명

API(Application Programming Interface)는 시스템 간 통신을 위한 인터페이스다. REST, GraphQL, gRPC 등 다양한 스타일이 있으며, 좋은 API 설계는 사용성, 확장성, 유지보수성을 모두 고려한다.

### 레벨별 지식

> ⭐ **Level 1 (입문)**
> - REST API 기본 개념
> - HTTP 메서드와 상태 코드
> - 엔드포인트 설계 기초
>
> **Q: REST API란?**
> **A:** Representational State Transfer. HTTP를 기반으로 리소스를 URL로 표현하고, HTTP 메서드로 작업을 정의하는 아키텍처 스타일.
>
> **Q: 주요 HTTP 메서드의 용도는?**
> **A:** GET(조회), POST(생성), PUT(전체 수정), PATCH(부분 수정), DELETE(삭제). 멱등성(GET, PUT, DELETE)과 안전성(GET) 이해 필요.
>
> **Q: 자주 사용하는 HTTP 상태 코드는?**
> **A:** 200(성공), 201(생성됨), 400(잘못된 요청), 401(인증 필요), 403(권한 없음), 404(없음), 500(서버 오류).
>
> **Q: RESTful URL 설계 원칙은?**
> **A:** 명사 사용(/users), 계층 표현(/users/123/orders), 복수형 사용, 소문자와 하이픈 사용. 동사는 HTTP 메서드로 표현.

> ⭐⭐ **Level 2 (주니어)**
> - REST 성숙도 모델
> - 페이지네이션, 필터링, 정렬
> - API 버전 관리
>
> **Q: Richardson 성숙도 모델의 단계는?**
> **A:** Level 0(HTTP 터널링), Level 1(리소스), Level 2(HTTP 동사), Level 3(HATEOAS). 대부분의 API는 Level 2 수준.
>
> **Q: 페이지네이션 구현 방식은?**
> **A:** Offset 기반(page=1&limit=20), Cursor 기반(after=id123). Cursor가 대용량에 효율적. 응답에 총 개수, 다음 페이지 링크 포함.
>
> **Q: API 버전 관리 방법은?**
> **A:** URL 경로(/v1/users), 헤더(Accept: application/vnd.api.v1+json), 쿼리 파라미터(?version=1). URL 방식이 가장 직관적.
>
> **Q: 필터링과 정렬을 어떻게 설계하는가?**
> **A:** 쿼리 파라미터 사용. 필터: `/users?status=active&role=admin`, 정렬: `/users?sort=-created_at` (- 는 내림차순)

> ⭐⭐⭐ **Level 3 (시니어)**
> - GraphQL 스키마와 리졸버
> - gRPC와 Protocol Buffers
> - API 설계 패턴과 안티패턴
>
> **Q: GraphQL의 장단점은?**
> **A:** 장점: 필요한 데이터만 요청, 단일 엔드포인트, 강타입 스키마. 단점: 캐싱 어려움, N+1 문제, 학습 곡선, 복잡한 권한 관리.
>
> **Q: GraphQL N+1 문제 해결 방법은?**
> **A:** DataLoader 패턴 사용. 같은 리소스에 대한 요청을 배치로 모아 한 번에 처리. 예: 여러 사용자의 주문을 개별 쿼리 대신 IN 절로 조회.
>
> **Q: gRPC의 특징은?**
> **A:** HTTP/2 기반, Protocol Buffers(바이너리 직렬화), 양방향 스트리밍, 코드 생성. 내부 서비스 간 통신에 적합, REST보다 빠름.
>
> **Q: API 설계 안티패턴은?**
> **A:** 동사 사용 URL(/getUser), 너무 깊은 중첩, 일관성 없는 응답 형식, 과도한 데이터 노출, 버전 관리 없음, 에러 응답 불명확.

> ⭐⭐⭐⭐ **Level 4 (리드/CTO)**
> - API Gateway 설계
> - API 거버넌스
> - 대규모 API 플랫폼 운영
>
> **Q: API Gateway의 역할은?**
> **A:** 단일 진입점, 인증/인가, Rate Limiting, 요청 라우팅, 로드 밸런싱, 요청/응답 변환, 로깅/모니터링, 캐싱.
>
> **Q: API 거버넌스란?**
> **A:** 조직 전체의 API 표준, 설계 가이드라인, 리뷰 프로세스, 문서화 정책, 버전 관리 정책, 폐기(Deprecation) 정책 수립과 관리.
>
> **Q: BFF(Backend For Frontend) 패턴이란?**
> **A:** 프론트엔드 유형(Web, Mobile, IoT)별로 전용 API 서버를 둠. 각 클라이언트에 최적화된 데이터 형태와 API 제공. API Gateway와 결합.

### 실무 시나리오

**시나리오: REST vs GraphQL 선택**
- 요구사항: 모바일 앱에서 사용자 프로필 + 최근 주문 5개 + 알림 개수를 한 화면에 표시
- REST: 3개 API 호출 필요, Over-fetching 발생
- GraphQL: 단일 쿼리로 필요한 필드만 요청
- 결정: 클라이언트가 다양하고 요구사항이 자주 변경되면 GraphQL 고려

### 면접 빈출 질문
- Q: REST API의 멱등성(Idempotency)이란?
- A: 같은 요청을 여러 번 해도 결과가 동일한 것. GET, PUT, DELETE는 멱등, POST는 비멱등. PUT으로 생성하면 멱등한 생성 가능.

---

## 3. 메시지 큐

### 개념 설명

메시지 큐는 프로듀서와 컨슈머 사이에서 메시지를 비동기로 전달하는 미들웨어다. 시스템 간 결합도를 낮추고, 부하를 조절하며, 장애를 격리하는 역할을 한다.

### 레벨별 지식

> ⭐ **Level 1 (입문)**
> - 메시지 큐의 필요성
> - 기본 동작 원리 (Producer-Queue-Consumer)
> - 대표적인 메시지 큐 종류
>
> **Q: 메시지 큐를 사용하는 이유는?**
> **A:** 비동기 처리로 응답 시간 단축, 시스템 간 결합도 감소, 부하 조절(피크 트래픽 흡수), 장애 격리, 재처리 용이.
>
> **Q: 메시지 큐의 기본 동작은?**
> **A:** Producer가 메시지를 큐에 전송 → 큐에서 메시지 저장 → Consumer가 메시지를 가져가서 처리. 비동기로 동작.
>
> **Q: Kafka, RabbitMQ, SQS의 차이는?**
> **A:** Kafka는 고처리량/로그 스트리밍, RabbitMQ는 유연한 라우팅/프로토콜, SQS는 관리형 서버리스. 용도에 맞게 선택.

> ⭐⭐ **Level 2 (주니어)**
> - Kafka 기본 개념 (Topic, Partition, Consumer Group)
> - RabbitMQ 기본 개념 (Exchange, Queue, Routing)
> - 메시지 전달 보장
>
> **Q: Kafka의 Partition이란?**
> **A:** Topic을 물리적으로 분할한 단위. 순서 보장은 Partition 내에서만. Partition 수로 병렬 처리량 결정. 메시지는 키 해시로 Partition 할당.
>
> **Q: Consumer Group이란?**
> **A:** 같은 그룹 내 Consumer들이 Partition을 나눠서 처리. 한 Partition은 그룹 내 하나의 Consumer만 처리. 그룹 단위로 오프셋 관리.
>
> **Q: 메시지 전달 보장 수준은?**
> **A:** At-most-once(최대 1회, 유실 가능), At-least-once(최소 1회, 중복 가능), Exactly-once(정확히 1회). 비즈니스 요구에 맞게 선택.
>
> **Q: RabbitMQ Exchange 유형은?**
> **A:** Direct(라우팅 키 일치), Fanout(모든 큐), Topic(패턴 매칭), Headers(헤더 기반). 메시지 라우팅 요구사항에 따라 선택.

> ⭐⭐⭐ **Level 3 (시니어)**
> - Kafka Exactly-once 처리
> - 메시지 순서 보장
> - Dead Letter Queue
>
> **Q: Kafka에서 Exactly-once를 어떻게 구현하는가?**
> **A:** Idempotent Producer + Transactional API. Producer ID로 중복 전송 감지, 트랜잭션으로 여러 메시지 원자적 처리. Consumer도 트랜잭션으로 처리.
>
> **Q: 메시지 순서 보장 방법은?**
> **A:** Kafka: 같은 Partition으로 전송(같은 키 사용). RabbitMQ: 단일 Consumer로 처리. 순서가 중요한 메시지는 같은 그룹으로 묶어야 함.
>
> **Q: Dead Letter Queue(DLQ)란?**
> **A:** 처리 실패한 메시지를 저장하는 별도 큐. 재시도 한계 초과, 파싱 오류 등의 메시지를 분리. 이후 분석하거나 수동 처리.
>
> **Q: Backpressure 처리 방법은?**
> **A:** Consumer 처리 속도 < Producer 전송 속도일 때 발생. Consumer 확장, 배치 처리 최적화, Rate Limiting, 큐 용량 증가로 대응.

> ⭐⭐⭐⭐ **Level 4 (리드/CTO)**
> - 대규모 Kafka 클러스터 운영
> - 이벤트 스트리밍 아키텍처
> - 메시징 시스템 선택 전략
>
> **Q: Kafka 클러스터 규모 산정 기준은?**
> **A:** 처리량(메시지/초), 데이터 보존 기간, 복제 팩터, 컨슈머 지연 허용치. Broker 수 = (처리량 × 복제 × 보존기간) / (디스크 용량 × 처리 능력).
>
> **Q: Kafka vs Pulsar 비교는?**
> **A:** Kafka는 생태계 성숙, 높은 처리량. Pulsar는 다중 테넌시, 지역 복제, 저장과 서빙 분리. 대규모 멀티 클러스터면 Pulsar 고려.
>
> **Q: 이벤트 기반 아키텍처에서 메시지 큐 역할은?**
> **A:** 이벤트 브로커로서 이벤트 발행/구독, 이벤트 저장(Kafka의 로그), 서비스 간 결합 제거, 이벤트 소싱의 이벤트 스토어.

### 실무 시나리오

**시나리오: 주문 처리 비동기화**
- 문제: 주문 시 결제, 재고차감, 알림, 포인트적립 동기 처리로 10초 소요
- 해결:
```
주문 API → [Kafka: order-created]
                 ├→ 결제 서비스 (필수, 실패 시 보상)
                 ├→ 재고 서비스 (필수, 실패 시 보상)
                 ├→ 알림 서비스 (비필수, 재시도)
                 └→ 포인트 서비스 (비필수, 재시도)
```
- 결과: 응답 시간 1초 미만, 서비스 장애 격리

### 면접 빈출 질문
- Q: Kafka의 Consumer Lag이란?
- A: 최신 메시지 오프셋과 Consumer가 처리한 오프셋의 차이. Lag이 증가하면 Consumer가 처리 속도를 따라가지 못하는 것. 모니터링 필수.

---

## 4. 이벤트 드리븐 아키텍처

### 개념 설명

이벤트 드리븐 아키텍처(EDA)는 시스템 구성요소 간 이벤트를 통해 통신하는 아키텍처다. 느슨한 결합, 확장성, 실시간 반응성을 제공한다. 이벤트 소싱, CQRS와 자주 결합된다.

### 레벨별 지식

> ⭐ **Level 1 (입문)**
> - 이벤트 드리븐의 개념
> - 이벤트 vs 커맨드
> - 발행/구독(Pub/Sub) 모델
>
> **Q: 이벤트 드리븐 아키텍처란?**
> **A:** 시스템 상태 변화(이벤트)를 발행하고, 관심 있는 구성요소가 구독하여 반응하는 구조. 직접 호출 대신 이벤트로 통신.
>
> **Q: 이벤트와 커맨드의 차이는?**
> **A:** 커맨드는 "~을 해라"(명령), 이벤트는 "~이 발생했다"(사실). 커맨드는 특정 대상에게, 이벤트는 누가 구독할지 모름.
>
> **Q: Pub/Sub 모델의 장점은?**
> **A:** Publisher와 Subscriber가 서로를 몰라도 됨(느슨한 결합), Subscriber 추가/제거가 자유로움, 확장 용이.

> ⭐⭐ **Level 2 (주니어)**
> - 이벤트 발행/구독 구현
> - 이벤트 설계 원칙
> - 이벤트 버전 관리
>
> **Q: 좋은 이벤트 설계 원칙은?**
> **A:** 과거형 명명(OrderCreated), 불변(immutable), 자기 설명적(필요한 정보 포함), 버전 관리, 중복 처리 고려.
>
> **Q: 이벤트에 얼마나 많은 데이터를 포함해야 하는가?**
> **A:** 구독자가 추가 조회 없이 처리할 수 있을 만큼. 너무 적으면 N+1 조회, 너무 많으면 결합도 증가. "fat events" vs "thin events" 트레이드오프.
>
> **Q: 이벤트 스키마 변경은 어떻게 하는가?**
> **A:** 하위 호환성 유지(새 필드 추가만), 버전 필드 추가, 스키마 레지스트리 사용(Confluent Schema Registry), Consumer 먼저 업데이트.
>
> **Q: 이벤트 순서 보장이 필요한 경우는?**
> **A:** 같은 엔티티의 상태 변경 이벤트. 예: 주문 생성 → 결제 완료 → 배송 시작 순서 필요. Partition Key를 엔티티 ID로 설정.

> ⭐⭐⭐ **Level 3 (시니어)**
> - 이벤트 소싱(Event Sourcing)
> - Outbox 패턴
> - CDC(Change Data Capture)
>
> **Q: 이벤트 소싱이란?**
> **A:** 현재 상태 대신 상태 변경 이벤트를 저장. 이벤트를 순서대로 재생하여 현재 상태 도출. 완전한 이력, 시간 여행 쿼리 가능.
>
> **Q: 이벤트 소싱의 단점은?**
> **A:** 이벤트 수 증가로 재생 시간 증가(스냅샷으로 해결), 쿼리 어려움(CQRS로 해결), 이벤트 스키마 변경 복잡, 학습 곡선.
>
> **Q: Outbox 패턴이란?**
> **A:** DB 트랜잭션 내에서 Outbox 테이블에 이벤트 저장, 별도 프로세스가 Outbox를 읽어 메시지 큐에 발행. DB 변경과 이벤트 발행의 원자성 보장.
>
> **Q: CDC란?**
> **A:** Change Data Capture. DB 변경을 감지하여 이벤트로 발행. Debezium이 대표적. 기존 시스템 수정 없이 이벤트 드리븐 적용 가능.

> ⭐⭐⭐⭐ **Level 4 (리드/CTO)**
> - 이벤트 스토어 설계
> - 이벤트 드리븐 마이그레이션
> - 일관성 모델 설계
>
> **Q: 이벤트 스토어 선택 기준은?**
> **A:** 추가 전용(append-only), 순서 보장, 구독 지원, 스냅샷 기능. Kafka, EventStoreDB, PostgreSQL(테이블), DynamoDB(스트림) 등.
>
> **Q: 결과적 일관성(Eventual Consistency)을 어떻게 관리하는가?**
> **A:** 사용자에게 명시적 피드백("처리 중"), 폴링/웹소켓으로 상태 확인, 보상 트랜잭션 준비, 일관성 경계 명확히 정의.
>
> **Q: 이벤트 드리븐에서 분산 트랜잭션은?**
> **A:** 2PC 대신 Saga 패턴 사용. Choreography(이벤트 체인) 또는 Orchestration(중앙 조정자). 각 단계 실패 시 보상 이벤트 발행.

### 실무 시나리오

**시나리오: 레거시 시스템에 이벤트 드리븐 적용**
- 상황: 모놀리스 DB에서 변경을 다른 시스템에 전파 필요
- 해결: Debezium CDC로 DB 변경 감지 → Kafka로 이벤트 발행 → 구독자들이 반응
- 장점: 기존 코드 수정 없음, 점진적 마이크로서비스 전환 기반

### 면접 빈출 질문
- Q: 이벤트 소싱과 CRUD의 차이는?
- A: CRUD는 현재 상태만 저장(덮어쓰기), 이벤트 소싱은 모든 변경을 이벤트로 저장(추가만). 이벤트 소싱은 이력, 감사, 시간 여행 쿼리 가능.

---

## 5. CQRS (Command Query Responsibility Segregation)

### 개념 설명

CQRS는 읽기(Query)와 쓰기(Command) 모델을 분리하는 패턴이다. 각 모델을 독립적으로 최적화할 수 있어 복잡한 도메인에서 유용하다. 이벤트 소싱과 자주 결합된다.

### 레벨별 지식

> ⭐ **Level 1 (입문)**
> - CQRS의 기본 개념
> - 읽기/쓰기 분리의 이점
> - 일반적인 CRUD와의 차이
>
> **Q: CQRS란?**
> **A:** Command Query Responsibility Segregation. 데이터 변경(Command)과 데이터 조회(Query)를 위한 모델을 분리하는 아키텍처 패턴.
>
> **Q: CQRS를 사용하는 이유는?**
> **A:** 읽기와 쓰기의 요구사항이 다를 때 각각 최적화 가능. 읽기는 비정규화된 뷰로 빠르게, 쓰기는 정규화된 모델로 정합성 유지.
>
> **Q: CQRS의 가장 단순한 형태는?**
> **A:** 같은 DB에서 쓰기는 정규화된 테이블, 읽기는 View나 별도 테이블. 코드 레벨에서만 분리해도 복잡성 관리에 도움.

> ⭐⭐ **Level 2 (주니어)**
> - Command와 Query 모델 설계
> - 동기화 방식
> - CQRS 적용 판단 기준
>
> **Q: Command 모델의 특징은?**
> **A:** 도메인 로직 포함, 정규화된 스키마, 트랜잭션 보장, 유효성 검증. 비즈니스 규칙을 강제하는 역할.
>
> **Q: Query 모델의 특징은?**
> **A:** 조회에 최적화된 비정규화 스키마, 복잡한 조인 없음, 빠른 응답. 화면/API 요구사항에 맞춤 설계.
>
> **Q: 읽기 모델을 어떻게 갱신하는가?**
> **A:** 동기(Command 처리 시 함께 갱신) 또는 비동기(이벤트로 갱신). 비동기는 결과적 일관성, 동기는 즉각 일관성.
>
> **Q: CQRS를 적용하면 좋은 경우는?**
> **A:** 읽기/쓰기 비율 차이가 큼, 복잡한 도메인, 여러 뷰가 필요, 읽기/쓰기 확장 요구가 다름, 이벤트 소싱 사용.

> ⭐⭐⭐ **Level 3 (시니어)**
> - 이벤트 소싱과 CQRS 결합
> - 읽기 모델 투영(Projection)
> - 일관성 처리
>
> **Q: 이벤트 소싱 + CQRS 조합의 장점은?**
> **A:** 이벤트가 Command 모델(이벤트 저장) → 이벤트를 투영하여 Query 모델 생성. 여러 읽기 모델 구축 가능, 읽기 모델 재구축 용이.
>
> **Q: Projection이란?**
> **A:** 이벤트 스트림을 읽어 읽기 모델을 구축/갱신하는 프로세스. 이벤트 핸들러가 각 이벤트 타입에 따라 읽기 DB 업데이트.
>
> **Q: 읽기 모델 재구축은 언제 하는가?**
> **A:** 읽기 모델 스키마 변경, 버그 수정, 새로운 뷰 추가. 이벤트를 처음부터 다시 재생하여 읽기 모델 생성.
>
> **Q: 결과적 일관성 지연을 어떻게 처리하는가?**
> **A:** 쓰기 후 읽기는 Command 결과에서 직접 반환, 폴링으로 갱신 확인, 버전 번호로 일관성 체크, UI에서 낙관적 업데이트.

> ⭐⭐⭐⭐ **Level 4 (리드/CTO)**
> - 대규모 CQRS 시스템 설계
> - 읽기 저장소 선택
> - CQRS 안티패턴
>
> **Q: 읽기 저장소로 다른 DB를 사용하는 이유는?**
> **A:** 용도에 최적화된 DB 선택. 예: 쓰기는 PostgreSQL(트랜잭션), 읽기는 Elasticsearch(검색), Redis(캐시), MongoDB(문서).
>
> **Q: CQRS 도입 시 주의점은?**
> **A:** 복잡성 증가, 최종 일관성 관리 필요, 개발/테스트 어려움, 인프라 복잡. 단순한 CRUD에는 과도한 설계.
>
> **Q: CQRS 안티패턴은?**
> **A:** 모든 기능에 CQRS 적용, 동기 이벤트로 결합도 증가, 거대한 단일 읽기 모델, Projection 로직에 도메인 로직 포함.

### 실무 시나리오

**시나리오: 대시보드 조회 성능 문제**
- 문제: 대시보드에 주문, 고객, 상품 통계를 보여주는데 복잡한 조인으로 5초 소요
- 해결:
```
Command 모델: 각 도메인별 정규화된 테이블
Query 모델: dashboard_summary 테이블 (비정규화된 집계 데이터)
동기화: 주문/고객/상품 변경 이벤트 → dashboard_summary 갱신
```
- 결과: 대시보드 조회 50ms

### 면접 빈출 질문
- Q: CQRS에서 읽기 모델이 최신이 아닐 때 어떻게 하는가?
- A: 결과적 일관성을 수용하거나, 중요한 데이터는 Command 결과에서 직접 반환, 버전 체크로 일관성 확인, 동기 업데이트 사용.

---

## 6. 캐싱 아키텍처

### 개념 설명

캐싱 아키텍처는 시스템 전반에 걸쳐 캐시를 배치하고 관리하는 전략이다. CDN, 리버스 프록시, 애플리케이션 캐시, 데이터베이스 캐시 등 여러 계층에서 캐싱을 적용한다.

### 레벨별 지식

> ⭐ **Level 1 (입문)**
> - 캐시의 목적과 위치
> - 캐시 계층 개요
> - 기본적인 캐시 전략
>
> **Q: 캐시를 어디에 배치할 수 있는가?**
> **A:** 브라우저 → CDN → 로드밸런서/리버스프록시 → 애플리케이션(로컬/분산) → 데이터베이스. 사용자에 가까울수록 빠름.
>
> **Q: CDN 캐시의 역할은?**
> **A:** 정적 파일(이미지, JS, CSS)을 전 세계 엣지 서버에 캐시하여 지연 시간 감소, 원본 서버 부하 감소.
>
> **Q: 애플리케이션 캐시의 종류는?**
> **A:** 로컬 캐시(프로세스 메모리, 가장 빠름)와 분산 캐시(Redis, 여러 인스턴스 공유). 일반적으로 둘 다 사용.

> ⭐⭐ **Level 2 (주니어)**
> - HTTP 캐싱 헤더
> - 로컬 캐시 vs 분산 캐시
> - 캐시 무효화 전략
>
> **Q: HTTP 캐시 제어 헤더는?**
> **A:** Cache-Control(max-age, no-cache, private), ETag(내용 해시), Last-Modified(변경 시간). 조건부 요청으로 네트워크 절약.
>
> **Q: 로컬 캐시의 장단점은?**
> **A:** 장점: 네트워크 왕복 없음, 매우 빠름. 단점: 인스턴스 간 불일치, 메모리 제한, 인스턴스 재시작 시 유실.
>
> **Q: 분산 캐시의 장단점은?**
> **A:** 장점: 인스턴스 간 공유, 대용량 저장, 지속성 옵션. 단점: 네트워크 지연, 직렬화 비용, 관리 복잡.
>
> **Q: 캐시 무효화가 어려운 이유는?**
> **A:** "컴퓨터 과학의 두 가지 어려운 문제: 캐시 무효화와 이름 짓기." 언제, 무엇을 무효화할지 판단이 복잡하고 분산 환경에서 전파도 어려움.

> ⭐⭐⭐ **Level 3 (시니어)**
> - 멀티 레이어 캐시 설계
> - 캐시 워밍과 프리로딩
> - 캐시 실패 대응
>
> **Q: 멀티 레이어 캐시 전략은?**
> **A:** L1(로컬 메모리, 짧은 TTL) → L2(분산 캐시, 긴 TTL) → Origin(DB). 히트율을 단계별로 높여 DB 부하 최소화.
>
> **Q: 캐시 워밍(Cache Warming)이란?**
> **A:** 서비스 시작 시 자주 조회되는 데이터를 미리 캐시에 로드. 콜드 스타트 시 DB 부하 급증 방지. 배포 직전이나 시작 시 수행.
>
> **Q: 캐시 실패(Cache Failure) 시 대응은?**
> **A:** Circuit Breaker로 캐시 우회, DB 직접 조회(부하 고려), 기본값 반환, 에러 응답. 캐시 의존도에 따라 전략 결정.
>
> **Q: Write-Through vs Write-Behind 선택 기준은?**
> **A:** Write-Through는 일관성 중요할 때(쓰기 지연 허용), Write-Behind는 쓰기 성능 중요할 때(데이터 손실 위험 감수).

> ⭐⭐⭐⭐ **Level 4 (리드/CTO)**
> - 대규모 캐시 인프라 설계
> - 캐시 일관성 전략
> - 비용 최적화
>
> **Q: 글로벌 서비스에서 캐시 전략은?**
> **A:** 리전별 분산 캐시 클러스터, CDN 엣지 캐싱, 리전 간 복제 또는 독립, 캐시 미스 시 가장 가까운 리전 조회.
>
> **Q: 캐시 용량 산정 방법은?**
> **A:** 작업 세트(Working Set) 크기 × 히트율 목표. 히트율 80% 이상 목표, 메모리 비용 vs 원본 비용 비교.
>
> **Q: 캐시와 일관성 트레이드오프는?**
> **A:** 강한 일관성(Write-Through, 짧은 TTL)은 캐시 효과 감소. 약한 일관성(긴 TTL, 지연 무효화)은 stale 데이터 가능. 비즈니스 요구에 맞게 결정.

### 실무 시나리오

**시나리오: 상품 목록 페이지 캐싱**
- 아키텍처:
```
사용자 → CDN (정적 자산) → Nginx (페이지 캐시)
       → App → Local Cache (인기 상품)
             → Redis (상품 상세)
             → PostgreSQL
```
- 전략: 인기 상품은 로컬 캐시(1분), 일반 상품은 Redis(5분), DB 변경 시 이벤트로 무효화

### 면접 빈출 질문
- Q: 캐시와 데이터베이스의 일관성을 어떻게 보장하는가?
- A: 완벽한 일관성은 어렵다. 쓰기 시 캐시 무효화/갱신, 짧은 TTL, 이벤트 기반 무효화 조합. 비즈니스에 맞는 일관성 수준 선택.

---

## 7. 스케일링

### 개념 설명

스케일링은 시스템의 처리 용량을 조절하는 것이다. 수직 확장(더 큰 서버)과 수평 확장(더 많은 서버)이 있으며, 현대 클라우드 환경에서는 자동 스케일링이 일반적이다.

### 레벨별 지식

> ⭐ **Level 1 (입문)**
> - 수직 확장 vs 수평 확장
> - 로드 밸런싱 기초
> - 스케일링이 필요한 지표
>
> **Q: 수직 확장(Scale Up)이란?**
> **A:** 서버의 CPU, 메모리, 디스크를 증가시키는 것. 구성이 단순하지만 하드웨어 한계 존재, 비용 증가 곡선이 가파름.
>
> **Q: 수평 확장(Scale Out)이란?**
> **A:** 서버 수를 늘리는 것. 이론적으로 무한 확장 가능, 비용 효율적. 하지만 애플리케이션이 상태 비저장(Stateless)이어야 함.
>
> **Q: 로드 밸런서의 역할은?**
> **A:** 들어오는 요청을 여러 서버에 분산. 알고리즘(Round Robin, Least Connection, IP Hash), 헬스체크, SSL 종료 등 수행.
>
> **Q: 스케일링이 필요한 지표는?**
> **A:** CPU 사용률 80% 이상, 메모리 부족, 응답 시간 증가, 처리량 한계, 에러율 증가.

> ⭐⭐ **Level 2 (주니어)**
> - 상태 비저장 설계
> - 세션 관리 방법
> - 오토 스케일링 기초
>
> **Q: 상태 비저장(Stateless) 서버가 중요한 이유는?**
> **A:** 어떤 서버로 요청이 가도 동일하게 처리 가능. 서버 추가/제거가 자유로움. 세션, 캐시 등 상태는 외부 저장소로 분리.
>
> **Q: 세션을 어떻게 관리하는가?**
> **A:** Sticky Session(같은 서버로), Session Replication(모든 서버에 복제), 외부 세션 스토어(Redis), JWT(클라이언트 보관).
>
> **Q: Auto Scaling의 동작 원리는?**
> **A:** 메트릭(CPU, 요청 수 등)을 모니터링하여 임계값 초과 시 인스턴스 추가, 임계값 미만 시 인스턴스 제거. 최소/최대 인스턴스 수 설정.
>
> **Q: 스케일 인/아웃 시 주의점은?**
> **A:** 스케일 아웃 시 트래픽 분산 확인, 스케일 인 시 연결 드레이닝(기존 요청 완료 대기). 급격한 변동 방지를 위한 쿨다운 기간 설정.

> ⭐⭐⭐ **Level 3 (시니어)**
> - 스케일링 병목점 분석
> - 데이터베이스 스케일링
> - Amdahl의 법칙
>
> **Q: 스케일링 병목점을 어떻게 찾는가?**
> **A:** 리소스 사용률 모니터링(CPU, 메모리, I/O, 네트워크), 응답 시간 분해, 분산 트레이싱으로 느린 구간 식별, 부하 테스트.
>
> **Q: 데이터베이스 스케일링 방법은?**
> **A:** 수직 확장, 읽기 복제본(읽기 분산), 샤딩(쓰기 분산), 캐싱(부하 감소). DB는 상태가 있어 수평 확장이 어려움.
>
> **Q: Amdahl의 법칙이란?**
> **A:** 병렬화할 수 없는 부분이 전체 성능 향상의 한계를 결정. 10%가 직렬이면 아무리 병렬화해도 10배 이상 빨라질 수 없음.
>
> **Q: 마이크로서비스에서 스케일링 전략은?**
> **A:** 서비스별 독립 스케일링. 트래픽이 많은 서비스만 확장, 리소스 사용 패턴에 맞는 스케일링 정책 적용.

> ⭐⭐⭐⭐ **Level 4 (리드/CTO)**
> - 대규모 스케일링 아키텍처
> - 비용 최적화
> - 용량 계획
>
> **Q: 글로벌 스케일링 전략은?**
> **A:** 멀티 리전 배포, GeoDNS로 가장 가까운 리전으로 라우팅, 리전 간 데이터 동기화, 리전별 독립 스케일링.
>
> **Q: 스케일링과 비용 최적화 균형은?**
> **A:** Reserved Instance로 기본 용량 확보, Spot/Preemptible로 피크 대응, 정확한 메트릭 기반 스케일링, 리소스 사용률 최적화.
>
> **Q: 용량 계획(Capacity Planning)은 어떻게 하는가?**
> **A:** 현재 트래픽 분석, 성장률 예측, 피크 트래픽 대비, 버퍼 확보. 정기적인 부하 테스트로 현재 용량 파악, 비즈니스와 협업.

### 실무 시나리오

**시나리오: 타임세일 이벤트 대응**
- 예상: 평소 대비 10배 트래픽
- 준비:
  - 사전 스케일 아웃 (warm-up)
  - CDN/캐시 최대 활용
  - 큐로 주문 처리 부하 분산
  - Rate Limiting으로 과부하 방지
  - 비핵심 기능 일시 비활성화
- 모니터링: 실시간 대시보드, 알림 강화

### 면접 빈출 질문
- Q: 수직 확장과 수평 확장 중 어떤 것을 먼저 시도하는가?
- A: 수직 확장이 더 단순하므로 먼저 시도. 하드웨어 한계에 도달하거나 비용 효율이 떨어지면 수평 확장 고려.

---

## 8. CAP 정리와 분산 시스템

### 개념 설명

CAP 정리는 분산 시스템에서 일관성(Consistency), 가용성(Availability), 분할 내성(Partition Tolerance) 중 최대 두 가지만 보장할 수 있다는 이론이다. 분산 시스템 설계의 핵심 트레이드오프다.

### 레벨별 지식

> ⭐ **Level 1 (입문)**
> - CAP 정리의 기본 개념
> - C, A, P 각각의 의미
> - 왜 셋 다 가질 수 없는가
>
> **Q: CAP에서 C(Consistency)란?**
> **A:** 모든 노드가 같은 시점에 같은 데이터를 보는 것. 한 노드에서 쓰면 다른 노드에서 즉시 읽을 수 있어야 함.
>
> **Q: CAP에서 A(Availability)란?**
> **A:** 모든 요청이 응답을 받는 것(성공 또는 실패). 시스템이 항상 동작하며, 일부 노드 장애에도 서비스 가능.
>
> **Q: CAP에서 P(Partition Tolerance)란?**
> **A:** 네트워크 분할(노드 간 통신 불가)이 발생해도 시스템이 동작하는 것. 분산 시스템에서는 필수.
>
> **Q: 왜 셋 다 가질 수 없는가?**
> **A:** 네트워크 분할 시, 일관성을 유지하려면 일부 노드 응답을 거부(가용성 포기). 가용성을 유지하려면 stale 데이터 반환(일관성 포기).

> ⭐⭐ **Level 2 (주니어)**
> - CP vs AP 시스템 예시
> - 결과적 일관성
> - PACELC 정리
>
> **Q: CP 시스템의 예시는?**
> **A:** 전통적인 RDBMS, ZooKeeper, etcd. 네트워크 분할 시 쓰기를 거부하거나 쿼럼이 안 되면 응답 안 함. 일관성 우선.
>
> **Q: AP 시스템의 예시는?**
> **A:** Cassandra, DynamoDB(기본), CouchDB. 네트워크 분할에도 응답하지만 노드 간 데이터가 다를 수 있음. 가용성 우선.
>
> **Q: 결과적 일관성(Eventual Consistency)이란?**
> **A:** 업데이트가 모든 복제본에 결국 전파되어 최종적으로 일관된 상태가 됨. AP 시스템에서 일반적. 일시적 불일치 허용.
>
> **Q: PACELC 정리란?**
> **A:** CAP 확장. Partition 시 A vs C, Else(정상) 시 Latency vs Consistency. 예: PA/EL(Cassandra), PC/EC(MySQL).

> ⭐⭐⭐ **Level 3 (시니어)**
> - 합의 알고리즘 (Raft, Paxos)
> - 분산 트랜잭션
> - 분산 잠금
>
> **Q: Raft 알고리즘이란?**
> **A:** 분산 합의 알고리즘. 리더 선출, 로그 복제, 안전성 보장. Paxos보다 이해하기 쉬움. etcd, Consul에서 사용.
>
> **Q: 2PC(Two-Phase Commit)의 문제점은?**
> **A:** 코디네이터 장애 시 참여자가 블로킹, 지연 시간 증가, 확장성 제한. 마이크로서비스에서는 Saga 패턴 선호.
>
> **Q: Saga 패턴이란?**
> **A:** 분산 트랜잭션을 로컬 트랜잭션의 시퀀스로 분해. 각 단계 실패 시 보상 트랜잭션 실행. Choreography(이벤트) 또는 Orchestration(중앙 조정).
>
> **Q: 분산 잠금 구현 방법은?**
> **A:** Redis(SETNX, Redlock), ZooKeeper(ephemeral node), etcd(lease). 네트워크 지연, 클럭 드리프트 고려 필요.

> ⭐⭐⭐⭐ **Level 4 (리드/CTO)**
> - 분산 시스템 설계 원칙
> - 일관성 모델 선택
> - 장애 대응 전략
>
> **Q: 강한 일관성이 필요한 경우는?**
> **A:** 금융 트랜잭션, 재고 관리(초과 판매 방지), 예약 시스템, 리더 선출. 비즈니스 규칙상 불일치가 허용되지 않는 경우.
>
> **Q: 결과적 일관성이 적합한 경우는?**
> **A:** 소셜 피드, 알림, 로그, 추천. 약간의 지연이나 불일치가 사용자 경험에 큰 영향 없는 경우.
>
> **Q: 분산 시스템 장애 대응 원칙은?**
> **A:** Fail-fast(빠른 실패 감지), Fail-safe(안전한 기본값), Graceful Degradation(부분 기능 유지), Bulkhead(장애 격리).

### 실무 시나리오

**시나리오: 글로벌 전자상거래 재고 관리**
- 요구사항: 재고 초과 판매 방지, 글로벌 사용자 대응
- 설계:
  - 재고 변경: 강한 일관성 (단일 리전 마스터)
  - 재고 조회: 결과적 일관성 (리전별 캐시)
  - 주문 시: 마스터에서 재고 확인 후 차감
- 트레이드오프: 타 리전 주문 시 약간의 지연 발생

### 면접 빈출 질문
- Q: CAP에서 CA를 선택할 수 없는 이유는?
- A: 네트워크 분할은 피할 수 없으므로 P는 필수. 분할 발생 시 C와 A 중 선택해야 함. 단일 노드 시스템만 CA 가능(분산이 아님).

---

## 9. 서비스 메시

### 개념 설명

서비스 메시는 마이크로서비스 간 통신을 관리하는 인프라 계층이다. 사이드카 프록시를 통해 서비스 디스커버리, 로드 밸런싱, 보안, 관측성 등을 애플리케이션 코드 변경 없이 제공한다.

### 레벨별 지식

> ⭐ **Level 1 (입문)**
> - 서비스 메시의 필요성
> - 사이드카 패턴
> - 대표적인 서비스 메시 솔루션
>
> **Q: 서비스 메시가 필요한 이유는?**
> **A:** 마이크로서비스 수가 늘어나면 서비스 간 통신 관리가 복잡해짐. 디스커버리, 로드 밸런싱, 보안, 모니터링을 각 서비스에 구현하면 중복과 복잡성 증가.
>
> **Q: 사이드카 패턴이란?**
> **A:** 각 서비스 옆에 프록시 컨테이너를 배치. 모든 네트워크 트래픽이 프록시를 통과. 서비스 코드 변경 없이 횡단 관심사 처리.
>
> **Q: Istio와 Linkerd의 차이는?**
> **A:** Istio는 기능 풍부, 복잡, Envoy 기반. Linkerd는 경량, 단순, Rust 기반. 소규모는 Linkerd, 대규모/복잡한 요구사항은 Istio.

> ⭐⭐ **Level 2 (주니어)**
> - 서비스 메시의 주요 기능
> - 트래픽 관리
> - mTLS 통신
>
> **Q: 서비스 메시가 제공하는 기능은?**
> **A:** 서비스 디스커버리, 로드 밸런싱, 트래픽 제어(라우팅, 분할), 보안(mTLS), 관측성(메트릭, 트레이싱), 장애 처리(재시도, 타임아웃, 서킷 브레이커).
>
> **Q: 트래픽 분할(Traffic Splitting)이란?**
> **A:** 트래픽을 여러 버전으로 분산. 카나리 배포(신규 버전에 10%), A/B 테스트, 블루-그린 배포에 활용.
>
> **Q: mTLS(Mutual TLS)란?**
> **A:** 서비스 간 양방향 인증. 클라이언트와 서버 모두 인증서로 신원 확인. 서비스 메시가 자동으로 인증서 관리 및 암호화.
>
> **Q: 서비스 메시 없이 이 기능들을 구현하려면?**
> **A:** 각 서비스에 라이브러리 추가(Spring Cloud, Hystrix 등). 언어별 구현 필요, 버전 관리 어려움, 일관성 유지 어려움.

> ⭐⭐⭐ **Level 3 (시니어)**
> - 컨트롤 플레인과 데이터 플레인
> - 관측성 통합
> - 성능 영향
>
> **Q: 컨트롤 플레인과 데이터 플레인이란?**
> **A:** 컨트롤 플레인은 정책 관리, 설정 배포(Istio Pilot). 데이터 플레인은 실제 트래픽 처리(Envoy 프록시).
>
> **Q: 서비스 메시가 관측성을 어떻게 향상시키는가?**
> **A:** 모든 요청이 프록시를 통과하므로 자동으로 메트릭 수집, 분산 트레이싱, 액세스 로그 생성. 애플리케이션 코드 수정 없이 관측 가능.
>
> **Q: 서비스 메시의 성능 오버헤드는?**
> **A:** 요청당 수 ms 지연 추가, 메모리/CPU 사용 증가(사이드카 때문). 대부분의 경우 허용 가능하나 극저지연 요구 시 고려 필요.
>
> **Q: 서비스 메시 도입 시 주의점은?**
> **A:** 복잡성 증가, 학습 곡선, 디버깅 어려움, 리소스 오버헤드. 서비스 수가 적으면 오버엔지니어링일 수 있음.

> ⭐⭐⭐⭐ **Level 4 (리드/CTO)**
> - 멀티 클러스터 메시
> - 서비스 메시 도입 전략
> - 서비스 메시의 미래
>
> **Q: 멀티 클러스터 서비스 메시란?**
> **A:** 여러 Kubernetes 클러스터에 걸쳐 서비스 메시 확장. 클러스터 간 서비스 통신, 통합 관측성, 재해 복구에 활용.
>
> **Q: 서비스 메시 도입 단계는?**
> **A:** 1) 관측성 먼저(사이드카 인젝션만) 2) 트래픽 관리(라우팅, 로드밸런싱) 3) 보안(mTLS) 4) 정책(Rate Limiting, 인가). 점진적 도입.
>
> **Q: eBPF 기반 서비스 메시란?**
> **A:** 사이드카 없이 커널 레벨에서 네트워킹 처리. Cilium이 대표적. 오버헤드 감소, 리소스 효율 향상. 서비스 메시의 다음 발전 방향.

### 실무 시나리오

**시나리오: 마이크로서비스 통신 보안 강화**
- 요구사항: 서비스 간 통신 암호화, 서비스 인증
- 해결: Istio mTLS 활성화
```yaml
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  name: default
spec:
  mtls:
    mode: STRICT
```
- 결과: 모든 서비스 간 통신 자동 암호화, 인증서 자동 갱신

### 면접 빈출 질문
- Q: 서비스 메시 도입이 필요한 시점은?
- A: 마이크로서비스 10개 이상, 횡단 관심사(보안, 관측성) 일관 적용 필요, 트래픽 관리(카나리, A/B) 필요, 언어/프레임워크 다양.

---

## 10. 서버리스

### 개념 설명

서버리스는 서버 관리 없이 코드를 실행하는 클라우드 컴퓨팅 모델이다. Function as a Service(FaaS)가 대표적이며, 이벤트 기반으로 동작하고 사용한 만큼만 비용을 지불한다.

### 레벨별 지식

> ⭐ **Level 1 (입문)**
> - 서버리스의 개념
> - FaaS(Function as a Service)
> - 서버리스의 장단점
>
> **Q: 서버리스란?**
> **A:** 서버 프로비저닝, 관리 없이 코드 실행. 클라우드 제공자가 인프라 관리. 확장, 가용성 자동 처리. "서버가 없다"가 아닌 "서버를 관리하지 않는다".
>
> **Q: AWS Lambda는 어떻게 동작하는가?**
> **A:** 코드와 트리거 정의 → 이벤트 발생 시 컨테이너 생성 → 코드 실행 → 결과 반환 → 컨테이너 종료(또는 재사용). 실행 시간만 과금.
>
> **Q: 서버리스의 장점은?**
> **A:** 서버 관리 불필요, 자동 확장, 사용량 기반 과금(비용 효율), 빠른 배포, 운영 부담 감소.
>
> **Q: 서버리스의 단점은?**
> **A:** 콜드 스타트 지연, 실행 시간 제한, 상태 유지 어려움, 벤더 종속, 로컬 개발/디버깅 어려움.

> ⭐⭐ **Level 2 (주니어)**
> - 콜드 스타트 문제
> - 서버리스 사용 사례
> - 이벤트 소스
>
> **Q: 콜드 스타트란?**
> **A:** 함수 첫 호출 또는 오랜 유휴 후 호출 시 컨테이너 초기화로 인한 지연. Java/C# 등 런타임이 무거울수록 심함. 수백 ms ~ 수 초.
>
> **Q: 콜드 스타트 완화 방법은?**
> **A:** Provisioned Concurrency(미리 웜업), 경량 런타임(Node.js, Go), 패키지 크기 최소화, 정기적 호출로 웜 유지.
>
> **Q: 서버리스가 적합한 사용 사례는?**
> **A:** 이벤트 처리(파일 업로드, 메시지), API 백엔드(트래픽 변동 큼), 스케줄 작업(cron), 데이터 변환, 웹훅.
>
> **Q: 서버리스가 부적합한 경우는?**
> **A:** 장시간 실행 작업, 일정한 고트래픽, 실시간 저지연 요구, 복잡한 상태 관리, WebSocket.

> ⭐⭐⭐ **Level 3 (시니어)**
> - 서버리스 아키텍처 패턴
> - Edge Functions
> - 서버리스와 컨테이너 비교
>
> **Q: 서버리스 아키텍처 패턴은?**
> **A:** API Gateway + Lambda, 이벤트 기반 파이프라인(S3→Lambda→DynamoDB), Fan-out(SNS→다중 Lambda), Step Functions(워크플로).
>
> **Q: Edge Functions란?**
> **A:** CDN 엣지에서 실행되는 서버리스 함수. Cloudflare Workers, Vercel Edge Functions. 사용자에 가까워 극저지연, 전처리에 유용.
>
> **Q: Lambda vs Fargate vs ECS 선택 기준은?**
> **A:** Lambda: 단시간 이벤트 처리, 변동 트래픽. Fargate: 장시간 실행, 컨테이너 필요. ECS/EKS: 완전한 제어, 복잡한 요구사항.
>
> **Q: 서버리스에서 상태 관리는 어떻게 하는가?**
> **A:** 외부 저장소 사용. DynamoDB, Redis, S3. 함수는 상태 비저장(Stateless)으로 설계. 상태를 함수에 저장하지 않음.

> ⭐⭐⭐⭐ **Level 4 (리드/CTO)**
> - 서버리스 비용 최적화
> - 서버리스 성숙도 모델
> - 하이브리드 아키텍처
>
> **Q: 서버리스 비용 최적화 방법은?**
> **A:** 메모리 최적화(메모리와 CPU 비례), 실행 시간 단축, 불필요한 호출 제거, Provisioned Concurrency 적절히 사용, Reserved Concurrency로 과금 제어.
>
> **Q: 서버리스가 비쌀 수 있는 경우는?**
> **A:** 일정한 고트래픽(Reserved Instance가 저렴), 장시간 실행, 고메모리 요구. 트래픽 패턴 분석 후 결정.
>
> **Q: 서버리스와 컨테이너 하이브리드 전략은?**
> **A:** 변동 트래픽/이벤트 처리는 Lambda, 상시 실행/복잡한 서비스는 EKS/Fargate. 각각의 장점 활용.

### 실무 시나리오

**시나리오: 이미지 리사이징 서비스**
- 요구사항: S3 업로드 시 여러 크기로 리사이징
- 아키텍처:
```
S3 Upload → Lambda (리사이징) → S3 (리사이징된 이미지)
                              → DynamoDB (메타데이터)
```
- 장점: 업로드 빈도에 따라 자동 확장, 유휴 시 비용 없음

### 면접 빈출 질문
- Q: 서버리스에서 데이터베이스 연결은 어떻게 관리하는가?
- A: 연결 풀링이 어려움. RDS Proxy 사용, DynamoDB 같은 HTTP 기반 DB, 커넥션 재사용, 연결 수 제한.

---

## 11. DDD (Domain-Driven Design)

### 개념 설명

도메인 주도 설계(DDD)는 복잡한 소프트웨어를 도메인 모델 중심으로 설계하는 방법론이다. 비즈니스 도메인의 복잡성을 소프트웨어에 반영하고, 도메인 전문가와 개발자의 협업을 강조한다.

### 레벨별 지식

> ⭐ **Level 1 (입문)**
> - DDD의 기본 개념
> - 유비쿼터스 언어
> - 도메인과 서브도메인
>
> **Q: DDD란?**
> **A:** Domain-Driven Design. 복잡한 비즈니스 도메인을 모델링하고, 그 모델을 중심으로 소프트웨어를 설계하는 접근법.
>
> **Q: 유비쿼터스 언어(Ubiquitous Language)란?**
> **A:** 개발자와 도메인 전문가가 공유하는 공통 용어. 코드, 문서, 대화에서 동일한 용어 사용. 의사소통 오해 방지.
>
> **Q: 도메인과 서브도메인의 차이는?**
> **A:** 도메인은 비즈니스 전체 영역, 서브도메인은 도메인 내 세부 영역. 예: 이커머스(도메인) - 주문, 결제, 배송(서브도메인).
>
> **Q: 핵심/지원/일반 서브도메인이란?**
> **A:** 핵심(Core)은 경쟁 우위, 지원(Supporting)은 핵심을 돕는 영역, 일반(Generic)은 범용 기능. 핵심에 가장 많은 투자.

> ⭐⭐ **Level 2 (주니어)**
> - Bounded Context
> - 엔티티와 값 객체
> - 애그리거트
>
> **Q: Bounded Context란?**
> **A:** 특정 도메인 모델이 적용되는 경계. 같은 용어도 컨텍스트마다 의미가 다를 수 있음. 마이크로서비스 경계와 대응.
>
> **Q: 엔티티(Entity)와 값 객체(Value Object)의 차이는?**
> **A:** 엔티티는 고유 식별자로 구분(ID가 같으면 같은 객체), 값 객체는 속성값으로 구분(속성이 같으면 같은 객체). 값 객체는 불변.
>
> **Q: 애그리거트(Aggregate)란?**
> **A:** 일관성을 유지해야 하는 객체 묶음. 애그리거트 루트를 통해서만 접근. 트랜잭션 경계와 일치.
>
> **Q: 애그리거트 설계 원칙은?**
> **A:** 작게 유지, 다른 애그리거트는 ID로만 참조, 하나의 트랜잭션에서 하나의 애그리거트만 수정.

> ⭐⭐⭐ **Level 3 (시니어)**
> - 전략적 설계 vs 전술적 설계
> - Context Mapping
> - 도메인 이벤트
>
> **Q: 전략적 설계와 전술적 설계의 차이는?**
> **A:** 전략적은 큰 그림(Bounded Context, Context Map, 서브도메인), 전술적은 구현 패턴(엔티티, 값 객체, 애그리거트, 리포지토리).
>
> **Q: Context Mapping이란?**
> **A:** Bounded Context 간의 관계를 정의. Shared Kernel, Customer-Supplier, Conformist, Anti-corruption Layer 등의 패턴.
>
> **Q: Anti-corruption Layer(ACL)란?**
> **A:** 외부 시스템의 모델이 내부로 침투하지 않도록 변환 계층을 둠. 레거시 통합, 외부 API 통합 시 유용.
>
> **Q: 도메인 이벤트란?**
> **A:** 도메인에서 발생한 중요한 사건. "주문이 생성됨", "결제가 완료됨". Bounded Context 간 통신, 이벤트 소싱에 활용.

> ⭐⭐⭐⭐ **Level 4 (리드/CTO)**
> - DDD와 마이크로서비스
> - 이벤트 스토밍
> - DDD 도입 전략
>
> **Q: DDD와 마이크로서비스의 관계는?**
> **A:** Bounded Context가 마이크로서비스 경계의 좋은 기준. DDD로 도메인 분석 → Bounded Context 도출 → 마이크로서비스 설계.
>
> **Q: 이벤트 스토밍(Event Storming)이란?**
> **A:** 도메인 전문가와 개발자가 함께 도메인 이벤트를 포스트잇으로 나열하며 도메인을 탐색하는 워크샵. Bounded Context 도출에 효과적.
>
> **Q: DDD 도입 시 주의점은?**
> **A:** 모든 프로젝트에 필요하지 않음(단순 CRUD에는 과도), 학습 곡선 높음, 도메인 전문가 협업 필수, 점진적 도입.

### 실무 시나리오

**시나리오: 이커머스 Bounded Context 도출**
- 이벤트 스토밍 결과:
  - 주문 BC: 주문 생성, 주문 취소
  - 결제 BC: 결제 요청, 결제 완료
  - 재고 BC: 재고 차감, 재고 복원
  - 배송 BC: 배송 시작, 배송 완료
- Context Map: 주문 ← 결제(Customer-Supplier), 주문 → 재고(이벤트), 주문 → 배송(이벤트)

### 면접 빈출 질문
- Q: 애그리거트 크기를 어떻게 결정하는가?
- A: 트랜잭션 일관성이 필요한 범위로 최소화. 큰 애그리거트는 동시성 충돌 증가. 다른 애그리거트는 이벤트로 결과적 일관성.

---

## 12. 12-Factor App

### 개념 설명

12-Factor App은 클라우드 네이티브 애플리케이션 개발을 위한 12가지 방법론이다. Heroku 개발자들이 정리했으며, SaaS 애플리케이션의 확장성, 유지보수성, 이식성을 높이는 원칙을 제시한다.

### 레벨별 지식

> ⭐ **Level 1 (입문)**
> - 12-Factor App의 목적
> - 주요 팩터 개요
> - 클라우드 네이티브와의 관계
>
> **Q: 12-Factor App이란?**
> **A:** 확장 가능하고 유지보수하기 쉬운 SaaS 애플리케이션을 만들기 위한 12가지 원칙. 클라우드 환경에 최적화된 설계 지침.
>
> **Q: 왜 12-Factor를 따라야 하는가?**
> **A:** 환경 간 이식성, 클라우드 배포 적합성, 확장 용이성, 개발/운영 차이 최소화, CI/CD 친화적.
>
> **Q: 가장 중요한 팩터 3가지는?**
> **A:** Codebase(코드 관리), Config(설정 분리), Processes(상태 비저장). 이 세 가지가 클라우드 배포의 기초.

> ⭐⭐ **Level 2 (주니어)**
> - 각 팩터 상세 이해 (1~6)
> - 실무 적용 방법
> - 위반 사례와 문제점
>
> **Q: I. Codebase - 코드베이스란?**
> **A:** 하나의 코드베이스가 버전 관리되고, 여러 환경(dev, staging, prod)에 배포됨. 여러 앱이면 각각 코드베이스 분리.
>
> **Q: II. Dependencies - 의존성이란?**
> **A:** 모든 의존성을 명시적으로 선언(package.json, requirements.txt). 시스템 패키지에 의존하지 않음. 격리된 환경에서 실행 가능.
>
> **Q: III. Config - 설정이란?**
> **A:** 환경마다 다른 값(DB URL, API 키)은 환경 변수로 관리. 코드에 설정을 하드코딩하지 않음. 설정과 코드 분리.
>
> **Q: IV. Backing Services - 백엔드 서비스란?**
> **A:** DB, 캐시, 메시지 큐 등을 연결 가능한 리소스로 취급. URL 변경만으로 로컬 DB에서 클라우드 DB로 전환 가능.
>
> **Q: V. Build, Release, Run - 빌드, 릴리즈, 실행이란?**
> **A:** 빌드(코드→실행 파일), 릴리즈(빌드+설정), 실행(프로세스 시작)을 엄격히 분리. 릴리즈는 불변, 롤백 가능.
>
> **Q: VI. Processes - 프로세스란?**
> **A:** 앱은 상태 비저장(Stateless) 프로세스로 실행. 세션, 캐시 등은 외부 서비스(Redis)에 저장. 프로세스 종료/재시작이 자유로움.

> ⭐⭐⭐ **Level 3 (시니어)**
> - 각 팩터 상세 이해 (7~12)
> - 마이크로서비스와의 관계
> - 현대적 해석
>
> **Q: VII. Port Binding - 포트 바인딩이란?**
> **A:** 앱이 자체적으로 HTTP 서버를 실행하고 포트에 바인딩. 외부 웹 서버(Apache, Nginx)에 의존하지 않음.
>
> **Q: VIII. Concurrency - 동시성이란?**
> **A:** 프로세스 타입별로 수평 확장. 웹 프로세스, 워커 프로세스를 독립적으로 스케일링. 수직 확장보다 수평 확장 선호.
>
> **Q: IX. Disposability - 폐기 가능성이란?**
> **A:** 빠른 시작과 graceful 종료. 프로세스는 언제든 시작/중지 가능해야 함. 확장, 배포, 장애 복구에 중요.
>
> **Q: X. Dev/Prod Parity - 개발/운영 동일성이란?**
> **A:** 개발, 스테이징, 운영 환경을 최대한 동일하게. 같은 백엔드 서비스, 같은 의존성. 환경 차이로 인한 버그 방지.
>
> **Q: XI. Logs - 로그란?**
> **A:** 로그를 이벤트 스트림으로 취급. 파일에 저장하지 않고 stdout으로 출력. 로그 집계는 실행 환경이 담당.
>
> **Q: XII. Admin Processes - 관리 프로세스란?**
> **A:** 마이그레이션, 일회성 스크립트도 앱과 동일한 환경에서 실행. 같은 코드베이스, 같은 설정 사용.

> ⭐⭐⭐⭐ **Level 4 (리드/CTO)**
> - 12-Factor 확장 (15-Factor, Beyond)
> - 조직 도입 전략
> - 예외 사항 판단
>
> **Q: 12-Factor를 확장한 개념은?**
> **A:** 15-Factor(Telemetry, Security, Audit 추가), Beyond 12-Factor(API First, Graceful Degradation 등). 현대 클라우드 네이티브에 맞게 진화.
>
> **Q: 12-Factor를 따르기 어려운 경우는?**
> **A:** 레거시 시스템 통합, 상태 저장이 필수인 앱(게임 서버), 특수 하드웨어 의존, 규제로 인한 제약. 원칙 이해 후 상황에 맞게 적용.
>
> **Q: 조직에 12-Factor를 도입하려면?**
> **A:** 표준 가이드라인 문서화, 템플릿/보일러플레이트 제공, 코드 리뷰에서 검증, 인프라(CI/CD, 로깅)도 함께 정비.

### 실무 시나리오

**시나리오: 레거시 앱 12-Factor 적용**
- 현재 문제:
  - 설정이 코드에 하드코딩
  - 로그가 로컬 파일에 저장
  - 세션이 로컬 메모리에 저장
- 개선:
  1. 환경 변수로 설정 분리
  2. stdout 로깅 + 로그 수집기
  3. Redis로 세션 이동
  4. Docker화하여 환경 통일

### 면접 빈출 질문
- Q: 12-Factor 중 가장 중요한 것은?
- A: Config(설정 분리)와 Processes(상태 비저장). 이 두 가지가 확장성과 이식성의 핵심.

---

## 13. API Gateway

### 개념 설명

API Gateway는 클라이언트와 백엔드 서비스 사이의 단일 진입점이다. 인증, Rate Limiting, 라우팅, 로드 밸런싱, 요청/응답 변환 등을 처리하여 백엔드 서비스의 복잡성을 숨긴다.

### 레벨별 지식

> ⭐ **Level 1 (입문)**
> - API Gateway의 역할
> - 주요 기능 개요
> - 대표적인 솔루션
>
> **Q: API Gateway가 필요한 이유는?**
> **A:** 마이크로서비스가 많아지면 클라이언트가 각 서비스를 직접 호출하기 어려움. 단일 진입점으로 복잡성 숨김, 횡단 관심사 중앙 처리.
>
> **Q: API Gateway의 주요 기능은?**
> **A:** 요청 라우팅, 인증/인가, Rate Limiting, 요청/응답 변환, 로드 밸런싱, SSL 종료, 캐싱, 로깅/모니터링.
>
> **Q: 대표적인 API Gateway 솔루션은?**
> **A:** AWS API Gateway, Kong, NGINX Plus, Zuul, Ambassador. 클라우드 관리형 vs 셀프 호스팅 선택.

> ⭐⭐ **Level 2 (주니어)**
> - 인증/인가 처리
> - Rate Limiting 구현
> - 라우팅 설정
>
> **Q: API Gateway에서 인증을 어떻게 처리하는가?**
> **A:** JWT 검증, OAuth 토큰 검증, API Key 확인. 인증 실패 시 401 반환. 백엔드 서비스는 인증된 요청만 받음.
>
> **Q: Rate Limiting 전략은?**
> **A:** IP별, API Key별, 사용자별 제한. 시간 윈도우(초/분/시간)당 요청 수 제한. 429 Too Many Requests 응답.
>
> **Q: 경로 기반 라우팅이란?**
> **A:** URL 경로에 따라 다른 백엔드 서비스로 라우팅. 예: /users/* → User Service, /orders/* → Order Service.
>
> **Q: 요청/응답 변환의 예시는?**
> **A:** 헤더 추가/제거, 쿼리 파라미터 매핑, JSON 필드 변환, 응답 필터링(특정 필드 제거). 버전 호환성 유지에 유용.

> ⭐⭐⭐ **Level 3 (시니어)**
> - API Gateway 패턴
> - 성능과 확장성
> - 장애 대응
>
> **Q: API Gateway가 단일 장애점(SPOF)이 되지 않으려면?**
> **A:** 다중 인스턴스 배포, 로드 밸런서 앞에 배치, 헬스체크, 자동 복구. 클라우드 관리형은 자동으로 고가용성 제공.
>
> **Q: API Gateway 성능 최적화 방법은?**
> **A:** 응답 캐싱, 연결 풀링, 비동기 처리, 불필요한 처리 제거, 적절한 인스턴스 크기. Gateway가 병목이 되지 않도록 주의.
>
> **Q: BFF(Backend For Frontend) 패턴이란?**
> **A:** 클라이언트 유형(Web, Mobile)별로 전용 Gateway/API 서버를 둠. 각 클라이언트에 최적화된 API 제공.
>
> **Q: API 조합(Composition)이란?**
> **A:** 여러 백엔드 서비스 호출 결과를 Gateway에서 조합하여 반환. 클라이언트 요청 수 감소. 복잡성과 지연 시간 트레이드오프.

> ⭐⭐⭐⭐ **Level 4 (리드/CTO)**
> - API Gateway 전략 수립
> - API 생태계 관리
> - 멀티 클라우드/하이브리드
>
> **Q: API Gateway 선택 기준은?**
> **A:** 기능 요구사항, 성능, 확장성, 운영 복잡도, 비용, 벤더 종속, 기존 인프라와 통합. 관리형 vs 셀프 호스팅 트레이드오프.
>
> **Q: API 버전 폐기(Deprecation) 전략은?**
> **A:** 충분한 공지 기간, 단계적 전환, 사용량 모니터링, 호환성 유지 기간 설정. Gateway에서 구버전 호출 시 경고 헤더 추가.
>
> **Q: 멀티 게이트웨이 아키텍처란?**
> **A:** 내부용/외부용 Gateway 분리, 리전별 Gateway, 도메인별 Gateway. 트래픽 특성과 보안 요구사항에 따라 분리.

### 실무 시나리오

**시나리오: API Rate Limiting 설계**
- 요구사항: 무료 사용자 100req/min, 유료 사용자 1000req/min
- 구현 (Kong 예시):
```yaml
plugins:
  - name: rate-limiting
    config:
      minute: 100
      policy: local
      fault_tolerant: true
      hide_client_headers: false
```
- 유료 사용자는 별도 소비자 그룹으로 분리하여 다른 제한 적용

### 면접 빈출 질문
- Q: API Gateway와 로드 밸런서의 차이는?
- A: 로드 밸런서는 L4/L7 트래픽 분산. API Gateway는 L7에서 라우팅, 인증, 변환 등 애플리케이션 로직 처리. Gateway는 로드 밸런서 뒤에 배치.

---

## 14. Circuit Breaker

### 개념 설명

Circuit Breaker는 장애가 발생한 서비스로의 요청을 차단하여 시스템 전체 장애를 방지하는 패턴이다. 전기 회로 차단기처럼 동작하며, Closed, Open, Half-Open 세 가지 상태로 동작한다.

### 레벨별 지식

> ⭐ **Level 1 (입문)**
> - Circuit Breaker의 필요성
> - 기본 동작 원리
> - 세 가지 상태
>
> **Q: Circuit Breaker가 필요한 이유는?**
> **A:** 의존 서비스 장애 시 계속 요청하면 리소스 낭비, 타임아웃 누적, 연쇄 장애 발생. 빠르게 실패하여 시스템을 보호.
>
> **Q: Circuit Breaker의 세 가지 상태는?**
> **A:** Closed(정상, 요청 통과), Open(차단, 즉시 실패 반환), Half-Open(일부 요청으로 복구 확인).
>
> **Q: Circuit Breaker가 Open되면 어떻게 되는가?**
> **A:** 요청이 서비스로 전달되지 않고 즉시 에러 반환. 일정 시간 후 Half-Open으로 전환하여 복구 확인.

> ⭐⭐ **Level 2 (주니어)**
> - 상태 전이 조건
> - Fallback 처리
> - 구현 라이브러리
>
> **Q: Closed에서 Open으로 전이하는 조건은?**
> **A:** 일정 시간 내 실패 횟수 또는 실패율이 임계값 초과. 예: 10초간 5회 실패 또는 50% 실패율.
>
> **Q: Half-Open 상태의 동작은?**
> **A:** 제한된 수의 요청만 통과시켜 테스트. 성공하면 Closed로 복귀, 실패하면 다시 Open.
>
> **Q: Fallback이란?**
> **A:** Circuit Open 시 대체 응답 반환. 캐시된 데이터, 기본값, 다른 서비스 호출. 사용자 경험 유지.
>
> **Q: 대표적인 구현 라이브러리는?**
> **A:** Resilience4j(Java), Hystrix(deprecated), Polly(.NET), pybreaker(Python). 서비스 메시에서도 제공.

> ⭐⭐⭐ **Level 3 (시니어)**
> - 임계값 설계
> - 다른 패턴과 조합
> - 모니터링
>
> **Q: 적절한 임계값은 어떻게 설정하는가?**
> **A:** 서비스 특성에 따라 다름. 중요 서비스는 민감하게(낮은 임계값), 허용 가능한 서비스는 느슨하게. 부하 테스트로 튜닝.
>
> **Q: Retry와 Circuit Breaker의 조합은?**
> **A:** Retry → Circuit Breaker 순서. 재시도 실패도 Circuit Breaker에 집계. Circuit Open이면 재시도 없이 즉시 실패.
>
> **Q: Timeout과 Circuit Breaker의 관계는?**
> **A:** Timeout 발생도 실패로 집계. 적절한 Timeout 설정이 선행. Timeout 없이 무한 대기하면 Circuit Breaker 무의미.
>
> **Q: Circuit Breaker 모니터링 방법은?**
> **A:** 상태(Closed/Open/Half-Open), 실패율, 응답 시간, Fallback 호출 수. 대시보드에서 실시간 확인, Open 시 알림.

> ⭐⭐⭐⭐ **Level 4 (리드/CTO)**
> - 분산 환경에서의 Circuit Breaker
> - 조직 전체 적용 전략
> - Chaos Engineering과의 연계
>
> **Q: 분산 환경에서 Circuit Breaker 공유는?**
> **A:** 인스턴스별 독립 vs 중앙 집중. 독립은 구현 단순하지만 상태 불일치. 중앙(Redis)은 일관되지만 복잡성 증가.
>
> **Q: 서비스 메시의 Circuit Breaker와 애플리케이션 레벨의 차이는?**
> **A:** 서비스 메시는 네트워크 레벨에서 투명하게 적용. 애플리케이션 레벨은 더 세밀한 제어, Fallback 로직 구현 가능.
>
> **Q: Chaos Engineering으로 Circuit Breaker를 어떻게 검증하는가?**
> **A:** 의도적으로 서비스 장애 주입하여 Circuit Breaker 동작 확인. Open 전이, Fallback 동작, 복구 후 Closed 전이 검증.

### 실무 시나리오

**시나리오: 결제 서비스 Circuit Breaker**
- 요구사항: 결제 서비스 장애 시 주문 전체가 실패하지 않도록
- 구현 (Resilience4j):
```java
CircuitBreakerConfig config = CircuitBreakerConfig.custom()
    .failureRateThreshold(50)
    .waitDurationInOpenState(Duration.ofSeconds(30))
    .slidingWindowSize(10)
    .build();

// Fallback: 결제 보류 처리 후 나중에 재시도
```

### 면접 빈출 질문
- Q: Circuit Breaker와 Bulkhead의 차이는?
- A: Circuit Breaker는 실패 서비스 차단, Bulkhead는 리소스 격리(스레드풀, 커넥션 제한). 둘 다 장애 격리가 목적이지만 메커니즘이 다름.

---

## 15. Rate Limiting

### 개념 설명

Rate Limiting은 시간당 요청 수를 제한하여 시스템을 과부하로부터 보호하는 기법이다. API 남용 방지, 공정한 리소스 분배, DDoS 완화에 사용된다.

### 레벨별 지식

> ⭐ **Level 1 (입문)**
> - Rate Limiting의 필요성
> - 기본 개념
> - HTTP 429 응답
>
> **Q: Rate Limiting이 필요한 이유는?**
> **A:** API 남용 방지, 서버 과부하 방지, 공정한 리소스 분배, 비용 제어, DDoS 완화.
>
> **Q: Rate Limiting은 어디서 적용하는가?**
> **A:** API Gateway, 로드 밸런서, 애플리케이션 레벨, CDN. 여러 레이어에서 중첩 적용 가능.
>
> **Q: 429 Too Many Requests는 언제 반환하는가?**
> **A:** 클라이언트가 할당된 요청 한도를 초과했을 때. Retry-After 헤더로 재시도 시점 안내.

> ⭐⭐ **Level 2 (주니어)**
> - Rate Limiting 알고리즘
> - 제한 기준 (IP, API Key, User)
> - 응답 헤더 설계
>
> **Q: Token Bucket 알고리즘이란?**
> **A:** 버킷에 일정 속도로 토큰 추가, 요청마다 토큰 소비. 버킷이 비면 요청 거부. 버스트 트래픽 허용.
>
> **Q: Leaky Bucket 알고리즘이란?**
> **A:** 요청을 큐에 넣고 일정 속도로 처리. 큐가 차면 새 요청 거부. 출력 속도 일정. 버스트 트래픽 평준화.
>
> **Q: Sliding Window 알고리즘이란?**
> **A:** 현재 시점 기준으로 이전 시간 윈도우 내 요청 수 계산. Fixed Window의 경계 문제 해결. 더 정확한 제한.
>
> **Q: Rate Limit 관련 응답 헤더는?**
> **A:** X-RateLimit-Limit(총 한도), X-RateLimit-Remaining(남은 요청), X-RateLimit-Reset(리셋 시간). 클라이언트가 조절 가능.

> ⭐⭐⭐ **Level 3 (시니어)**
> - 분산 Rate Limiting
> - 동적 Rate Limiting
> - 계층적 제한
>
> **Q: 분산 환경에서 Rate Limiting은 어떻게 구현하는가?**
> **A:** 중앙 저장소(Redis)에서 카운터 관리. 각 인스턴스가 Redis를 조회하여 판단. 네트워크 지연과 일관성 트레이드오프.
>
> **Q: Redis로 Rate Limiting 구현 방법은?**
> **A:** INCR + EXPIRE로 카운터 구현. Lua 스크립트로 원자적 연산. Sliding Window는 Sorted Set 활용.
>
> **Q: 동적 Rate Limiting이란?**
> **A:** 시스템 부하에 따라 제한을 동적으로 조절. CPU 사용률 높으면 제한 강화, 여유 있으면 완화. 적응형 Rate Limiting.
>
> **Q: 계층적 Rate Limiting이란?**
> **A:** 여러 수준의 제한 적용. 예: 전체 API 10000req/min, 사용자별 100req/min, 엔드포인트별 10req/min. 각 수준에서 제한 적용.

> ⭐⭐⭐⭐ **Level 4 (리드/CTO)**
> - Rate Limiting 정책 설계
> - 비즈니스 요구사항 반영
> - 대규모 시스템 적용
>
> **Q: API Rate Limit 정책 설계 시 고려할 점은?**
> **A:** 사용자 티어별 차등 제한, 엔드포인트별 비용 차이, 버스트 허용량, 초과 시 대응(차단 vs 과금), 문서화.
>
> **Q: Rate Limiting과 과금 연동은?**
> **A:** 기본 한도 초과 시 추가 요금, 또는 상위 티어 업그레이드 유도. API 사용량 기반 과금 모델의 기초.
>
> **Q: 글로벌 Rate Limiting의 도전과제는?**
> **A:** 리전 간 동기화 지연, 중앙 저장소 의존, 네트워크 파티션 대응. 리전별 독립 + 글로벌 집계 하이브리드 방식.

### 실무 시나리오

**시나리오: API Rate Limiting 구현**
- 요구사항: 사용자별 100req/min, IP별 1000req/min
- Redis Lua 스크립트 (Sliding Window):
```lua
local key = KEYS[1]
local now = tonumber(ARGV[1])
local window = tonumber(ARGV[2])
local limit = tonumber(ARGV[3])

redis.call('ZREMRANGEBYSCORE', key, 0, now - window)
local count = redis.call('ZCARD', key)

if count < limit then
    redis.call('ZADD', key, now, now .. math.random())
    redis.call('EXPIRE', key, window / 1000)
    return 1
else
    return 0
end
```

### 면접 빈출 질문
- Q: Token Bucket과 Leaky Bucket의 차이는?
- A: Token Bucket은 버스트 허용(버킷에 토큰 쌓임), Leaky Bucket은 출력 속도 일정(버스트 평준화). 요구사항에 따라 선택.
