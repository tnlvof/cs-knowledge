# 데이터베이스 (Database) - IT 서비스 운영 필수 지식

> 이 문서는 IT 서비스 운영에 필요한 데이터베이스 지식을 레벨별로 정리한 학습 자료입니다.
> 퀴즈 생성 및 역량 평가에 활용할 수 있습니다.

## 레벨 가이드

| 레벨 | 대상 | 설명 |
|------|------|------|
| ⭐ Level 1 | 입문 | 개념 이해, 기본 용어 |
| ⭐⭐ Level 2 | 주니어 | 실무 적용, 트러블슈팅 기초 |
| ⭐⭐⭐ Level 3 | 시니어 | 아키텍처 설계, 성능 최적화 |
| ⭐⭐⭐⭐ Level 4 | 리드/CTO | 전략적 의사결정, 대규모 설계 |

---

## 1. RDBMS 핵심 개념

### 개념 설명

관계형 데이터베이스 관리 시스템(RDBMS)은 데이터를 테이블 형태로 저장하고, 테이블 간의 관계를 통해 데이터를 조직화하는 시스템이다. 정규화를 통해 데이터 중복을 최소화하고, 무결성을 보장한다.

### 레벨별 지식

> ⭐ **Level 1 (입문)**
> - 테이블(Table), 행(Row), 열(Column)의 개념
> - 기본키(Primary Key)와 외래키(Foreign Key)
> - 정규화의 목적: 데이터 중복 제거, 무결성 보장
>
> **Q: 기본키(Primary Key)란 무엇인가?**
> **A:** 테이블에서 각 행을 고유하게 식별하는 열 또는 열의 조합이다. NULL 값을 가질 수 없고, 테이블 내에서 유일해야 한다.
>
> **Q: 외래키(Foreign Key)의 역할은?**
> **A:** 다른 테이블의 기본키를 참조하여 테이블 간의 관계를 정의한다. 참조 무결성을 보장하는 역할을 한다.
>
> **Q: 정규화를 하는 이유는?**
> **A:** 데이터 중복을 제거하고, 삽입/수정/삭제 이상(Anomaly)을 방지하며, 데이터 무결성을 유지하기 위함이다.
>
> **Q: 1NF(제1정규형)의 조건은?**
> **A:** 모든 속성이 원자값(Atomic Value)만 가져야 한다. 즉, 하나의 컬럼에 여러 값이 들어가면 안 된다.

> ⭐⭐ **Level 2 (주니어)**
> - 1NF~3NF 정규화 단계 이해
> - ERD(Entity-Relationship Diagram) 작성
> - 반정규화의 필요성
>
> **Q: 2NF(제2정규형)를 만족하려면?**
> **A:** 1NF를 만족하면서 부분 함수 종속을 제거해야 한다. 기본키가 복합키일 때, 모든 비키 속성이 기본키 전체에 종속되어야 한다.
>
> **Q: 3NF(제3정규형)의 조건은?**
> **A:** 2NF를 만족하면서 이행적 함수 종속을 제거해야 한다. 비키 속성이 다른 비키 속성에 종속되면 안 된다.
>
> **Q: 반정규화(Denormalization)는 언제 하는가?**
> **A:** 조회 성능이 중요하고 JOIN이 빈번할 때, 의도적으로 중복을 허용하여 조회 속도를 높인다. 단, 데이터 정합성 관리 비용이 증가한다.
>
> **Q: ERD에서 1:N 관계를 표현하는 방법은?**
> **A:** N측 테이블에 1측 테이블의 기본키를 외래키로 추가한다. 예: 부서(1):직원(N) 관계에서 직원 테이블에 부서ID 외래키를 둔다.

> ⭐⭐⭐ **Level 3 (시니어)**
> - BCNF, 4NF, 5NF 고급 정규화
> - 정규화/반정규화 트레이드오프 결정
> - 대규모 시스템 ERD 설계
>
> **Q: BCNF(Boyce-Codd Normal Form)와 3NF의 차이는?**
> **A:** 3NF는 비키 속성의 이행 종속만 제거하지만, BCNF는 모든 결정자가 후보키여야 한다. 3NF를 만족해도 BCNF를 위반할 수 있다.
>
> **Q: 4NF(제4정규형)에서 제거하는 것은?**
> **A:** 다치 종속(Multi-valued Dependency)을 제거한다. 하나의 속성이 다른 속성과 독립적으로 여러 값을 가질 때 발생한다.
>
> **Q: 5NF(제5정규형)는 언제 필요한가?**
> **A:** 조인 종속(Join Dependency)을 제거해야 할 때 필요하다. 테이블을 분해했다가 다시 조인해도 원래 테이블이 복원되어야 한다.
>
> **Q: 정규화 수준을 어디까지 해야 하는가?**
> **A:** 일반적으로 3NF 또는 BCNF까지 적용한다. 과도한 정규화는 조인 비용을 증가시키므로 성능과 정합성 간 균형을 고려해야 한다.

> ⭐⭐⭐⭐ **Level 4 (리드/CTO)**
> - 전사적 데이터 모델링 전략
> - OLTP vs OLAP 아키텍처 설계
> - 데이터 거버넌스 체계 수립
>
> **Q: OLTP와 OLAP 시스템의 정규화 전략 차이는?**
> **A:** OLTP는 높은 정규화(3NF/BCNF)로 트랜잭션 성능과 정합성을 중시한다. OLAP은 스타/스노우플레이크 스키마로 반정규화하여 분석 쿼리 성능을 최적화한다.
>
> **Q: 스타 스키마(Star Schema)와 스노우플레이크 스키마(Snowflake Schema)의 차이는?**
> **A:** 스타 스키마는 팩트 테이블을 중심으로 비정규화된 디멘션 테이블이 연결된다. 스노우플레이크 스키마는 디멘션 테이블도 정규화되어 여러 테이블로 분리된다.
>
> **Q: 마이크로서비스에서 데이터 모델링 시 고려할 점은?**
> **A:** 각 서비스가 독립적인 데이터베이스를 가지므로 서비스 간 조인이 불가능하다. 이벤트 기반 동기화, 데이터 중복 허용, 결과적 일관성을 고려해야 한다.

### 실무 시나리오

**시나리오: 주문 시스템에서 조회 성능 저하**
- 문제: 주문 목록 조회 시 고객, 상품, 배송지 정보를 가져오기 위해 5개 테이블 JOIN 발생
- 진단: 정규화된 스키마에서 복잡한 JOIN으로 인한 성능 저하
- 해결: 조회용 반정규화 테이블 생성, 또는 CQRS 패턴으로 읽기 모델 분리

### 면접 빈출 질문
- Q: 정규화와 반정규화를 각각 언제 사용해야 하는가?
- A: 정규화는 데이터 무결성이 중요하고 쓰기 작업이 많을 때, 반정규화는 읽기 성능이 중요하고 데이터 변경이 적을 때 사용한다.

---

## 2. 인덱스 (Index)

### 개념 설명

인덱스는 데이터베이스 테이블의 검색 속도를 향상시키는 자료구조이다. 책의 색인처럼 특정 데이터의 위치를 빠르게 찾을 수 있게 해준다. 대부분의 RDBMS는 B+Tree 구조의 인덱스를 기본으로 사용한다.

### 레벨별 지식

> ⭐ **Level 1 (입문)**
> - 인덱스의 목적과 기본 개념
> - 인덱스가 검색을 빠르게 하는 원리
> - 인덱스의 장단점
>
> **Q: 인덱스를 사용하면 왜 조회가 빨라지는가?**
> **A:** 전체 테이블을 스캔(Full Table Scan)하지 않고, 정렬된 인덱스에서 이진 탐색처럼 빠르게 데이터 위치를 찾을 수 있기 때문이다.
>
> **Q: 인덱스의 단점은?**
> **A:** 추가 저장 공간이 필요하고, INSERT/UPDATE/DELETE 시 인덱스도 갱신해야 하므로 쓰기 성능이 저하된다.
>
> **Q: 어떤 컬럼에 인덱스를 생성해야 하는가?**
> **A:** WHERE 절, JOIN 조건, ORDER BY에 자주 사용되는 컬럼에 생성한다. 중복 값이 적은(선택도가 높은) 컬럼이 효과적이다.

> ⭐⭐ **Level 2 (주니어)**
> - B+Tree 인덱스 구조 이해
> - 복합 인덱스(Composite Index)
> - 인덱스 선택도(Selectivity)와 카디널리티(Cardinality)
>
> **Q: B+Tree 인덱스의 특징은?**
> **A:** 리프 노드에만 실제 데이터(또는 포인터)가 저장되고, 리프 노드들이 연결 리스트로 연결되어 범위 검색에 효율적이다. 트리 높이가 낮아 디스크 I/O가 적다.
>
> **Q: 복합 인덱스에서 컬럼 순서가 중요한 이유는?**
> **A:** 인덱스는 첫 번째 컬럼부터 순서대로 정렬된다. `(A, B, C)` 인덱스에서 B나 C만으로 검색하면 인덱스를 활용할 수 없다.
>
> **Q: 카디널리티(Cardinality)란?**
> **A:** 컬럼의 고유값 개수이다. 카디널리티가 높을수록(중복이 적을수록) 인덱스 효과가 좋다. 예: 주민번호(높음), 성별(낮음)
>
> **Q: 선택도(Selectivity)는 어떻게 계산하는가?**
> **A:** 선택도 = 고유값 수 / 전체 행 수. 1에 가까울수록 선택도가 높다. 선택도가 높은 컬럼이 인덱스에 적합하다.

> ⭐⭐⭐ **Level 3 (시니어)**
> - 커버링 인덱스(Covering Index)
> - Hash 인덱스 vs B+Tree
> - 인덱스 스캔 방식 (Index Only Scan, Index Scan, Bitmap Index Scan)
> - 부분 인덱스(Partial Index)
>
> **Q: 커버링 인덱스란?**
> **A:** 쿼리에서 필요한 모든 컬럼이 인덱스에 포함되어, 테이블에 접근하지 않고 인덱스만으로 쿼리를 처리할 수 있는 인덱스이다. I/O를 크게 줄인다.
>
> **Q: Hash 인덱스는 언제 사용하는가?**
> **A:** 동등 비교(=)만 하는 경우 O(1)로 매우 빠르다. 하지만 범위 검색, 정렬에는 사용할 수 없어 B+Tree보다 제한적이다.
>
> **Q: Bitmap Index Scan은 언제 발생하는가?**
> **A:** 여러 인덱스 조건을 AND/OR로 결합할 때, 각 인덱스에서 비트맵을 생성하여 교집합/합집합 연산 후 테이블에 접근한다.
>
> **Q: 부분 인덱스(Partial Index)의 활용 사례는?**
> **A:** 특정 조건의 데이터만 인덱싱한다. 예: `CREATE INDEX ON orders (created_at) WHERE status = 'pending'` - 처리 중인 주문만 빠르게 조회.

> ⭐⭐⭐⭐ **Level 4 (리드/CTO)**
> - 대규모 테이블 인덱스 전략
> - 인덱스 유지보수 비용 분석
> - 쓰기 중심 vs 읽기 중심 워크로드별 인덱스 설계
>
> **Q: 수억 건 테이블에서 인덱스 전략은?**
> **A:** 파티셔닝과 결합하여 파티션별 로컬 인덱스 사용, 부분 인덱스로 핫 데이터만 인덱싱, 커버링 인덱스로 테이블 접근 최소화, 비동기 인덱스 생성(CONCURRENTLY) 활용.
>
> **Q: 인덱스가 많으면 발생하는 문제는?**
> **A:** 쓰기 성능 저하, 저장 공간 증가, 옵티마이저 선택 복잡도 증가, 인덱스 유지보수 비용 증가. 사용하지 않는 인덱스는 정기적으로 정리해야 한다.
>
> **Q: 인덱스 사용 현황을 어떻게 모니터링하는가?**
> **A:** PostgreSQL의 경우 pg_stat_user_indexes 뷰에서 idx_scan 값으로 인덱스 사용 빈도를 확인한다. 사용되지 않는 인덱스는 제거를 검토한다.

### 실무 시나리오

**시나리오: 복합 인덱스 설계 실수**
- 문제: `(status, created_at)` 인덱스가 있는데 `WHERE created_at > '2024-01-01'` 쿼리가 느림
- 진단: 복합 인덱스의 첫 번째 컬럼(status)을 사용하지 않아 인덱스 활용 불가
- 해결: `created_at` 단독 인덱스 추가, 또는 쿼리에 status 조건 추가

### 면접 빈출 질문
- Q: 복합 인덱스 `(A, B, C)`에서 어떤 쿼리가 인덱스를 활용할 수 있는가?
- A: A 조건만, (A, B) 조건, (A, B, C) 조건은 활용 가능. B만 또는 C만 있는 조건은 활용 불가. A와 C만 있으면 A까지만 활용.

---

## 3. 실행계획 (Execution Plan)

### 개념 설명

실행계획은 데이터베이스가 SQL 쿼리를 어떻게 처리할지 보여주는 청사진이다. 옵티마이저가 생성하며, 어떤 인덱스를 사용하고, 어떤 순서로 조인하며, 어떤 알고리즘을 사용할지 결정한다.

### 레벨별 지식

> ⭐ **Level 1 (입문)**
> - EXPLAIN 명령어의 목적
> - Seq Scan vs Index Scan 차이
> - 실행계획 읽는 기본 방법
>
> **Q: EXPLAIN은 왜 사용하는가?**
> **A:** 쿼리가 어떻게 실행될지 미리 확인하여 성능 문제를 진단하고 최적화 방향을 결정하기 위함이다.
>
> **Q: Seq Scan(Sequential Scan)은 무엇인가?**
> **A:** 테이블의 모든 행을 순차적으로 읽는 방식이다. 인덱스를 사용하지 않으며, 대용량 테이블에서는 느리다.
>
> **Q: Index Scan은 언제 사용되는가?**
> **A:** 적절한 인덱스가 있고, 검색 조건이 테이블의 일부 행만 반환할 때 옵티마이저가 선택한다.

> ⭐⭐ **Level 2 (주니어)**
> - EXPLAIN ANALYZE로 실제 실행 통계 확인
> - 예상 비용(cost) vs 실제 실행 시간
> - 주요 스캔 방식 이해 (Seq Scan, Index Scan, Index Only Scan, Bitmap Scan)
>
> **Q: EXPLAIN과 EXPLAIN ANALYZE의 차이는?**
> **A:** EXPLAIN은 예상 실행계획만 보여주고, EXPLAIN ANALYZE는 실제로 쿼리를 실행하여 실제 시간과 행 수를 보여준다.
>
> **Q: cost는 무엇을 의미하는가?**
> **A:** 옵티마이저가 추정한 상대적인 작업 비용이다. 디스크 I/O, CPU 연산 등을 고려하며, 단위는 시간이 아닌 추상적인 값이다.
>
> **Q: Index Only Scan은 Index Scan과 어떻게 다른가?**
> **A:** Index Only Scan은 필요한 모든 데이터가 인덱스에 있어 테이블에 접근하지 않는다. Index Scan은 인덱스로 위치를 찾은 후 테이블에서 데이터를 읽는다.
>
> **Q: 예상 행 수와 실제 행 수가 크게 다르면?**
> **A:** 통계 정보가 오래되었을 가능성이 높다. ANALYZE 명령으로 통계를 갱신해야 옵티마이저가 정확한 계획을 세울 수 있다.

> ⭐⭐⭐ **Level 3 (시니어)**
> - Join 알고리즘 (Nested Loop, Hash Join, Merge Join)
> - 통계 정보와 옵티마이저
> - 힌트(Hint)를 통한 실행계획 제어
>
> **Q: Nested Loop Join은 언제 효율적인가?**
> **A:** 외부 테이블이 작고 내부 테이블에 인덱스가 있을 때 효율적이다. O(N*M)이지만 인덱스로 내부 탐색을 줄일 수 있다.
>
> **Q: Hash Join의 동작 방식은?**
> **A:** 작은 테이블로 해시 테이블을 만들고(Build), 큰 테이블을 스캔하며 해시 테이블과 매칭(Probe)한다. 동등 조인에서 대량 데이터에 효율적이다.
>
> **Q: Merge Join의 특징은?**
> **A:** 두 테이블이 조인 키로 정렬되어 있을 때 효율적이다. 정렬된 데이터를 병합하며 순차 스캔한다. 정렬 비용이 있으면 비효율적일 수 있다.
>
> **Q: 통계 정보가 부정확하면 어떤 문제가 발생하는가?**
> **A:** 옵티마이저가 잘못된 실행계획을 선택한다. 예: 실제 100만 건인데 1000건으로 추정하면 Nested Loop을 선택하여 성능 저하.

> ⭐⭐⭐⭐ **Level 4 (리드/CTO)**
> - 옵티마이저 동작 원리 심층 이해
> - 대규모 쿼리 최적화 전략
> - 실행계획 캐싱과 Prepared Statement
>
> **Q: PostgreSQL의 옵티마이저는 어떤 방식인가?**
> **A:** 비용 기반 옵티마이저(Cost-Based Optimizer)로, 다양한 실행계획의 비용을 추정하여 가장 낮은 비용의 계획을 선택한다.
>
> **Q: 파티션 프루닝(Partition Pruning)이란?**
> **A:** 쿼리 조건에 해당하지 않는 파티션을 스캔에서 제외하는 최적화이다. 실행계획에서 제외된 파티션을 확인할 수 있다.
>
> **Q: Prepared Statement가 성능에 미치는 영향은?**
> **A:** 파싱/계획 수립 비용을 절약하지만, 제네릭 플랜을 사용할 경우 특정 파라미터에 최적화되지 않을 수 있다. PostgreSQL 12+에서 자동 전환된다.

### 실무 시나리오

**시나리오: 느린 쿼리 분석**
```sql
EXPLAIN ANALYZE SELECT * FROM orders o
JOIN customers c ON o.customer_id = c.id
WHERE o.created_at > '2024-01-01';
```
- 진단: Hash Join 대신 Nested Loop이 선택됨, 예상 행 수 100 vs 실제 100만
- 원인: orders 테이블 통계 정보 오래됨
- 해결: `ANALYZE orders;` 실행 후 쿼리 재실행

### 면접 빈출 질문
- Q: 실행계획에서 가장 먼저 확인해야 할 것은?
- A: 스캔 방식(Seq Scan vs Index Scan), 예상 행 수와 실제 행 수 차이, 가장 비용이 높은 단계를 순서대로 확인한다.

---

## 4. 트랜잭션 (Transaction)

### 개념 설명

트랜잭션은 데이터베이스의 상태를 변화시키는 논리적 작업 단위이다. 여러 SQL 문을 하나의 단위로 묶어 전체가 성공하거나 전체가 실패하도록 보장한다. ACID 속성을 통해 데이터 무결성을 보장한다.

### 레벨별 지식

> ⭐ **Level 1 (입문)**
> - 트랜잭션의 정의와 필요성
> - COMMIT과 ROLLBACK
> - ACID 속성 개요
>
> **Q: 트랜잭션이 필요한 이유는?**
> **A:** 여러 작업을 하나의 단위로 처리하여, 중간에 실패해도 데이터 정합성을 유지하기 위함이다. 예: 계좌이체에서 출금만 되고 입금이 안 되는 상황 방지.
>
> **Q: ACID에서 A(Atomicity)란?**
> **A:** 원자성. 트랜잭션의 모든 작업이 완전히 수행되거나 전혀 수행되지 않아야 한다. 부분 실행은 없다.
>
> **Q: COMMIT과 ROLLBACK의 차이는?**
> **A:** COMMIT은 트랜잭션의 변경사항을 영구적으로 저장한다. ROLLBACK은 트랜잭션의 변경사항을 취소하고 이전 상태로 되돌린다.

> ⭐⭐ **Level 2 (주니어)**
> - ACID 속성 상세 이해
> - 격리 수준(Isolation Level) 4단계
> - 격리 수준별 발생하는 문제 (Dirty Read, Non-repeatable Read, Phantom Read)
>
> **Q: C(Consistency)는 무엇을 보장하는가?**
> **A:** 일관성. 트랜잭션 전후로 데이터베이스가 일관된 상태를 유지해야 한다. 무결성 제약조건을 위반하는 트랜잭션은 거부된다.
>
> **Q: I(Isolation)은 왜 필요한가?**
> **A:** 격리성. 동시에 실행되는 트랜잭션들이 서로 영향을 주지 않아야 한다. 마치 순차적으로 실행된 것처럼 보여야 한다.
>
> **Q: Dirty Read란?**
> **A:** 다른 트랜잭션이 아직 커밋하지 않은 데이터를 읽는 것. 그 트랜잭션이 롤백하면 잘못된 데이터를 읽은 것이 된다.
>
> **Q: Non-repeatable Read와 Phantom Read의 차이는?**
> **A:** Non-repeatable Read는 같은 행을 다시 읽을 때 값이 변경된 것. Phantom Read는 같은 쿼리를 다시 실행할 때 새로운 행이 추가/삭제된 것.

> ⭐⭐⭐ **Level 3 (시니어)**
> - MVCC(Multi-Version Concurrency Control) 동작 원리
> - 데드락(Deadlock) 감지와 해결
> - 격리 수준 선택 전략
>
> **Q: MVCC는 어떻게 동작하는가?**
> **A:** 데이터 변경 시 새 버전을 생성하고 이전 버전을 유지한다. 각 트랜잭션은 시작 시점의 스냅샷을 보며, 읽기와 쓰기가 서로 블로킹하지 않는다.
>
> **Q: PostgreSQL에서 MVCC의 구현 방식은?**
> **A:** 각 행에 xmin(생성 트랜잭션), xmax(삭제 트랜잭션) 정보를 저장한다. 트랜잭션은 자신의 스냅샷에서 보이는 행만 읽는다. VACUUM이 오래된 버전을 정리한다.
>
> **Q: 데드락은 어떻게 발생하는가?**
> **A:** 두 트랜잭션이 서로 상대방이 잡고 있는 잠금을 기다릴 때 발생한다. 예: T1이 A를 잠그고 B를 기다림, T2가 B를 잠그고 A를 기다림.
>
> **Q: 데드락을 어떻게 해결하는가?**
> **A:** 데이터베이스가 자동 감지하여 한 트랜잭션을 롤백시킨다. 예방하려면 잠금 순서를 일관되게 하거나, 타임아웃을 설정한다.

> ⭐⭐⭐⭐ **Level 4 (리드/CTO)**
> - 분산 트랜잭션 전략
> - 격리 수준과 성능 트레이드오프
> - 대규모 시스템의 트랜잭션 설계
>
> **Q: Serializable과 Repeatable Read의 성능 차이는?**
> **A:** Serializable은 직렬화 이상을 완전히 방지하지만 잠금 범위가 넓어 동시성이 낮다. Repeatable Read는 Phantom Read만 허용하여 더 높은 동시성을 제공한다.
>
> **Q: 마이크로서비스에서 트랜잭션을 어떻게 처리하는가?**
> **A:** 서비스별 로컬 트랜잭션을 사용하고, 서비스 간에는 Saga 패턴(보상 트랜잭션) 또는 이벤트 소싱을 통해 결과적 일관성을 달성한다.
>
> **Q: Long-running 트랜잭션의 문제는?**
> **A:** 잠금을 오래 유지하여 동시성 저하, MVCC에서 오래된 스냅샷 유지로 인한 테이블 부풀림(bloat), 다른 트랜잭션 블로킹의 원인이 된다.

### 실무 시나리오

**시나리오: 데드락 빈번 발생**
- 문제: 주문 처리 시 재고 차감과 결제 처리에서 데드락 발생
- 진단: 트랜잭션마다 다른 순서로 테이블 잠금
- 해결: 모든 트랜잭션에서 재고 -> 결제 순서로 일관된 잠금 순서 적용

### 면접 빈출 질문
- Q: REPEATABLE READ에서도 발생할 수 있는 문제는?
- A: Phantom Read. 같은 범위 쿼리를 두 번 실행할 때 다른 트랜잭션이 삽입한 새 행이 보일 수 있다. PostgreSQL의 RR은 MVCC로 Phantom을 방지한다.

---

## 5. 잠금 (Locking)

### 개념 설명

잠금은 동시에 여러 트랜잭션이 같은 데이터에 접근할 때 충돌을 방지하는 메커니즘이다. 데이터 무결성을 보장하지만, 과도한 잠금은 동시성을 저하시킨다.

### 레벨별 지식

> ⭐ **Level 1 (입문)**
> - 잠금이 필요한 이유
> - 공유 잠금(Shared Lock)과 배타 잠금(Exclusive Lock)
> - 잠금의 기본 동작
>
> **Q: 공유 잠금과 배타 잠금의 차이는?**
> **A:** 공유 잠금은 읽기용으로 여러 트랜잭션이 동시에 획득 가능하다. 배타 잠금은 쓰기용으로 하나의 트랜잭션만 획득 가능하며 다른 모든 잠금을 차단한다.
>
> **Q: SELECT 문은 잠금을 사용하는가?**
> **A:** 기본 SELECT는 MVCC 덕분에 잠금 없이 읽는다. SELECT FOR UPDATE/SHARE를 사용하면 명시적으로 잠금을 획득한다.
>
> **Q: UPDATE 문은 어떤 잠금을 사용하는가?**
> **A:** 대상 행에 배타 잠금(Row Exclusive Lock)을 획득한다. 다른 트랜잭션은 해당 행을 수정하거나 삭제할 수 없다.

> ⭐⭐ **Level 2 (주니어)**
> - Row Lock과 Table Lock
> - SELECT FOR UPDATE vs SELECT FOR SHARE
> - 잠금 대기와 타임아웃
>
> **Q: Row Lock과 Table Lock은 언제 사용되는가?**
> **A:** Row Lock은 특정 행만 잠그며 일반적인 DML에서 사용된다. Table Lock은 DDL이나 명시적 LOCK 문에서 사용되며 전체 테이블에 영향을 준다.
>
> **Q: SELECT FOR UPDATE는 언제 사용하는가?**
> **A:** 읽은 데이터를 이후 수정할 예정일 때 사용한다. 다른 트랜잭션이 같은 행을 수정하지 못하게 미리 잠근다. 예: 재고 확인 후 차감.
>
> **Q: NOWAIT와 SKIP LOCKED의 차이는?**
> **A:** NOWAIT는 잠금을 즉시 획득할 수 없으면 에러를 반환한다. SKIP LOCKED는 잠긴 행을 건너뛰고 잠금 가능한 행만 반환한다.
>
> **Q: 잠금 타임아웃 설정은 왜 중요한가?**
> **A:** 무한 대기를 방지하고, 데드락 상황에서 빠르게 실패하여 시스템 전체 지연을 막기 위함이다. lock_timeout 파라미터로 설정한다.

> ⭐⭐⭐ **Level 3 (시니어)**
> - 갭 락(Gap Lock)과 넥스트 키 락(Next-Key Lock)
> - 낙관적 잠금(Optimistic Locking)과 비관적 잠금(Pessimistic Locking)
> - 인텐트 잠금(Intent Lock)
>
> **Q: 갭 락(Gap Lock)은 무엇인가?**
> **A:** MySQL InnoDB에서 인덱스 레코드 사이의 "간격"을 잠그는 것이다. 범위 검색 시 Phantom Read를 방지하기 위해 사용된다.
>
> **Q: 넥스트 키 락(Next-Key Lock)이란?**
> **A:** 인덱스 레코드와 그 앞의 갭을 함께 잠그는 것이다. Record Lock + Gap Lock이다. MySQL InnoDB의 기본 잠금 방식이다.
>
> **Q: 낙관적 잠금 vs 비관적 잠금의 선택 기준은?**
> **A:** 충돌이 적으면 낙관적 잠금(버전 체크), 충돌이 많으면 비관적 잠금(SELECT FOR UPDATE)이 효율적이다. 낙관적은 재시도 로직이 필요하다.
>
> **Q: 낙관적 잠금을 어떻게 구현하는가?**
> **A:** version 컬럼을 사용한다. `UPDATE ... WHERE id = ? AND version = ?` 후 affected rows가 0이면 충돌로 간주하고 재시도한다.

> ⭐⭐⭐⭐ **Level 4 (리드/CTO)**
> - 잠금 경합 분석과 최적화
> - 분산 잠금 전략
> - 잠금 에스컬레이션
>
> **Q: 잠금 경합을 어떻게 모니터링하는가?**
> **A:** PostgreSQL: pg_locks, pg_stat_activity로 대기 중인 잠금 확인. 잠금 대기 시간, 블로킹 쿼리를 분석하여 병목을 찾는다.
>
> **Q: 분산 시스템에서 잠금을 어떻게 구현하는가?**
> **A:** Redis의 SETNX/Redlock, ZooKeeper의 순차 노드, etcd의 lease를 사용한다. 네트워크 파티션, 클럭 드리프트를 고려해야 한다.
>
> **Q: 핫스팟(Hotspot) 행의 잠금 문제를 어떻게 해결하는가?**
> **A:** 카운터 샤딩(여러 행으로 분산), 비동기 처리(큐 사용), 낙관적 잠금 + 재시도, 또는 Redis 같은 인메모리 저장소 사용.

### 실무 시나리오

**시나리오: 재고 동시 차감 문제**
```sql
-- 문제: 동시에 100개 주문이 들어와 재고가 음수가 됨
-- 해결: SELECT FOR UPDATE 사용
BEGIN;
SELECT stock FROM products WHERE id = 1 FOR UPDATE;
-- 재고 확인 후
UPDATE products SET stock = stock - 1 WHERE id = 1;
COMMIT;
```

### 면접 빈출 질문
- Q: SELECT FOR UPDATE와 UPDATE 문의 차이는?
- A: SELECT FOR UPDATE는 읽기 시점에 잠금을 획득하여 읽은 값을 기반으로 안전하게 수정할 수 있다. UPDATE는 수정 시점에만 잠금을 획득한다.

---

## 6. 복제 (Replication)

### 개념 설명

복제는 데이터베이스의 데이터를 여러 서버에 복사하는 것이다. 고가용성, 읽기 부하 분산, 재해 복구를 위해 사용된다. Primary-Replica 구조가 가장 일반적이다.

### 레벨별 지식

> ⭐ **Level 1 (입문)**
> - 복제가 필요한 이유
> - Primary(Master)와 Replica(Slave) 역할
> - 읽기 부하 분산
>
> **Q: 복제를 사용하는 이유는?**
> **A:** 고가용성(Primary 장애 시 Replica로 전환), 읽기 성능 향상(읽기 쿼리 분산), 재해 복구(지역 분산 복제), 백업(Replica에서 백업 수행).
>
> **Q: Primary와 Replica의 역할은?**
> **A:** Primary는 쓰기를 처리하고 변경사항을 Replica에 전달한다. Replica는 Primary의 변경사항을 받아 적용하고 읽기 쿼리를 처리한다.
>
> **Q: 읽기/쓰기 분리의 장점은?**
> **A:** Primary는 쓰기에만 집중하고, 읽기는 여러 Replica에 분산하여 전체 처리량을 높일 수 있다. 읽기가 많은 워크로드에 효과적이다.

> ⭐⭐ **Level 2 (주니어)**
> - 동기 vs 비동기 복제
> - 복제 지연(Replication Lag)
> - 스트리밍 복제 vs 논리 복제
>
> **Q: 동기 복제와 비동기 복제의 차이는?**
> **A:** 동기 복제는 Replica에 적용될 때까지 커밋을 대기하여 데이터 손실이 없다. 비동기 복제는 즉시 커밋하여 빠르지만 데이터 손실 위험이 있다.
>
> **Q: 복제 지연(Replication Lag)이란?**
> **A:** Primary의 변경사항이 Replica에 적용되기까지의 시간 차이다. 비동기 복제에서 발생하며, 읽기 일관성 문제를 야기할 수 있다.
>
> **Q: 스트리밍 복제(Streaming Replication)란?**
> **A:** PostgreSQL에서 WAL(Write-Ahead Log) 레코드를 실시간으로 Replica에 전송하는 방식이다. 물리적 복제로, Replica는 Primary와 동일한 바이너리 상태를 가진다.
>
> **Q: 논리 복제(Logical Replication)는 언제 사용하는가?**
> **A:** 특정 테이블만 복제하거나, 다른 버전/다른 DBMS 간 복제, 데이터 변환이 필요할 때 사용한다. 행 단위 변경사항을 논리적으로 전달한다.

> ⭐⭐⭐ **Level 3 (시니어)**
> - 반동기 복제(Semi-synchronous)
> - 복제 토폴로지 설계
> - 복제 지연 대응 전략
>
> **Q: 반동기 복제의 동작 방식은?**
> **A:** 최소 하나의 Replica가 WAL을 수신 확인할 때까지 커밋을 대기한다. 동기보다 빠르면서 비동기보다 안전한 중간 지점이다.
>
> **Q: 복제 지연에 어떻게 대응하는가?**
> **A:** 1) 쓰기 후 읽기를 Primary에서 수행 2) 버전 또는 타임스탬프로 일관성 확인 3) 복제 지연 모니터링 및 알림 4) 지연이 심하면 해당 Replica 제외
>
> **Q: Cascading Replication이란?**
> **A:** Replica가 다른 Replica의 소스가 되는 구조다. Primary 부하를 줄이고, 지역 분산 시 네트워크 비용을 절감할 수 있다.
>
> **Q: 체인 복제의 장단점은?**
> **A:** 장점은 Primary 부하 감소, 네트워크 효율화. 단점은 체인이 길수록 지연 누적, 중간 노드 장애 시 하위 노드 영향.

> ⭐⭐⭐⭐ **Level 4 (리드/CTO)**
> - 멀티 리전 복제 전략
> - 자동 페일오버 설계
> - 복제 일관성 모델 선택
>
> **Q: 멀티 리전 복제에서 고려할 점은?**
> **A:** 네트워크 지연으로 인한 복제 지연, 리전 간 동기 복제의 성능 영향, 스플릿 브레인 방지, 지역별 규제 준수(GDPR 등).
>
> **Q: 자동 페일오버를 어떻게 구현하는가?**
> **A:** Patroni, repmgr 등 HA 솔루션 사용. 합의 알고리즘(Raft, Paxos)으로 리더 선출, VIP 전환 또는 DNS 업데이트로 연결 전환.
>
> **Q: 복제 설계 시 CAP 정리와의 관계는?**
> **A:** 동기 복제(CP)는 일관성을 보장하지만 네트워크 파티션 시 가용성이 떨어진다. 비동기 복제(AP)는 가용성을 유지하지만 일관성이 떨어진다.

### 실무 시나리오

**시나리오: 복제 지연으로 인한 데이터 불일치**
- 문제: 사용자가 주문 후 즉시 조회하면 주문이 안 보임
- 원인: 쓰기는 Primary, 읽기는 Replica에서 수행. 복제 지연 발생
- 해결: 쓰기 직후 읽기는 Primary에서 수행하도록 라우팅, 또는 세션 기반 일관성 적용

### 면접 빈출 질문
- Q: 동기 복제의 단점은?
- A: 모든 쓰기가 Replica 응답을 기다려야 하므로 지연 시간이 증가한다. Replica 장애 시 쓰기가 차단될 수 있어 가용성이 저하된다.

---

## 7. 샤딩 (Sharding)

### 개념 설명

샤딩은 데이터를 여러 데이터베이스 서버에 분산 저장하는 수평 파티셔닝 기법이다. 단일 서버의 용량과 성능 한계를 극복하여 대규모 데이터를 처리할 수 있게 한다.

### 레벨별 지식

> ⭐ **Level 1 (입문)**
> - 샤딩이 필요한 이유
> - 수평 분할 vs 수직 분할
> - 샤드 키의 개념
>
> **Q: 샤딩은 왜 필요한가?**
> **A:** 단일 데이터베이스가 저장할 수 있는 데이터양과 처리할 수 있는 트래픽에 한계가 있기 때문이다. 수평 확장으로 이를 극복한다.
>
> **Q: 수평 분할과 수직 분할의 차이는?**
> **A:** 수평 분할은 행 단위로 데이터를 나눈다(예: 사용자 ID로 분할). 수직 분할은 열 단위로 나눈다(예: 자주 쓰는 컬럼만 분리).
>
> **Q: 샤드 키란?**
> **A:** 데이터를 어느 샤드에 저장할지 결정하는 기준이 되는 컬럼이다. 샤드 키 선택이 샤딩 성능의 핵심이다.

> ⭐⭐ **Level 2 (주니어)**
> - 샤딩 전략 (Range, Hash, Directory)
> - 샤드 키 선택 기준
> - 샤딩의 장단점
>
> **Q: Range 샤딩의 장단점은?**
> **A:** 장점은 범위 쿼리가 효율적이고 직관적이다. 단점은 데이터가 특정 샤드에 몰릴 수 있다(핫스팟). 예: 최근 날짜에 쓰기 집중.
>
> **Q: Hash 샤딩의 특징은?**
> **A:** 샤드 키를 해시하여 균등하게 분산한다. 데이터 분포가 고르지만 범위 쿼리가 모든 샤드를 조회해야 하는 단점이 있다.
>
> **Q: 좋은 샤드 키의 조건은?**
> **A:** 카디널리티가 높고(고유값이 많고), 쿼리에 자주 포함되며, 데이터가 균등하게 분산되고, 핫스팟이 발생하지 않는 키.
>
> **Q: 샤딩의 단점은?**
> **A:** 조인이 어렵고, 트랜잭션 관리가 복잡하며, 리밸런싱이 어렵고, 운영 복잡도가 높다. 애플리케이션 수정이 필요할 수 있다.

> ⭐⭐⭐ **Level 3 (시니어)**
> - Consistent Hashing
> - 샤드 리밸런싱 전략
> - 크로스 샤드 쿼리 처리
>
> **Q: Consistent Hashing이란?**
> **A:** 해시 링에 샤드를 배치하고, 키의 해시값에서 시계방향으로 가장 가까운 샤드에 할당한다. 샤드 추가/제거 시 영향받는 데이터가 최소화된다.
>
> **Q: 리밸런싱 시 고려할 점은?**
> **A:** 서비스 중단 없이 데이터 이동, 이동 중 읽기/쓰기 처리, 이전 샤드에서 신규 샤드로의 점진적 전환, 복제본 동기화.
>
> **Q: 크로스 샤드 조인을 어떻게 처리하는가?**
> **A:** 1) 애플리케이션에서 각 샤드 결과를 병합 2) 자주 조인되는 데이터를 같은 샤드에 배치 3) 조인 결과를 비정규화하여 저장 4) 전문 미들웨어 사용.
>
> **Q: 글로벌 테이블(Reference Table)이란?**
> **A:** 모든 샤드에 동일하게 복제되는 읽기 전용 테이블이다. 코드 테이블, 설정 데이터 등 변경이 적고 조인이 필요한 데이터에 사용한다.

> ⭐⭐⭐⭐ **Level 4 (리드/CTO)**
> - 샤딩 솔루션 선택 (Vitess, Citus, ProxySQL)
> - 샤딩 아키텍처 설계
> - 샤딩 마이그레이션 전략
>
> **Q: Vitess와 Citus의 차이점은?**
> **A:** Vitess는 MySQL 기반으로 YouTube에서 개발, 쿼리 라우팅과 연결 풀링 제공. Citus는 PostgreSQL 확장으로 분산 테이블과 분산 쿼리를 지원한다.
>
> **Q: 샤딩 없이 확장하는 대안은?**
> **A:** 읽기 복제본 확장, 캐싱 강화, 쿼리 최적화, 수직 확장(더 큰 하드웨어), 아카이빙(오래된 데이터 분리), 파티셔닝.
>
> **Q: 샤딩 도입 시점은 어떻게 결정하는가?**
> **A:** 단일 DB 한계에 도달했을 때(디스크, 연결 수, 쿼리 성능). 샤딩은 복잡도가 높으므로 다른 최적화를 먼저 시도하고 마지막 수단으로 고려한다.

### 실무 시나리오

**시나리오: 샤드 키 잘못 선택**
- 문제: created_at으로 샤딩했는데 최근 데이터 샤드에 쓰기 집중
- 진단: Range 샤딩에서 시간 기반 키는 핫스팟 발생
- 해결: user_id로 Hash 샤딩 변경, 또는 복합 샤드 키 (user_id, created_at) 사용

### 면접 빈출 질문
- Q: 샤딩과 파티셔닝의 차이는?
- A: 파티셔닝은 단일 DB 내에서 테이블을 물리적으로 분할한다. 샤딩은 여러 DB 서버에 데이터를 분산한다. 샤딩이 더 큰 규모의 확장성을 제공한다.

---

## 8. 파티셔닝 (Partitioning)

### 개념 설명

파티셔닝은 하나의 큰 테이블을 여러 개의 작은 물리적 조각(파티션)으로 분할하는 기법이다. 단일 데이터베이스 내에서 대용량 테이블의 관리와 쿼리 성능을 향상시킨다.

### 레벨별 지식

> ⭐ **Level 1 (입문)**
> - 파티셔닝의 목적
> - 파티션 유형 개요 (Range, Hash, List)
> - 파티셔닝의 장점
>
> **Q: 파티셔닝을 하는 이유는?**
> **A:** 대용량 테이블의 쿼리 성능 향상, 관리 용이성(파티션별 백업/삭제), 오래된 데이터 쉽게 아카이빙, 병렬 처리 가능.
>
> **Q: Range 파티셔닝은 언제 사용하는가?**
> **A:** 날짜나 숫자 범위로 데이터를 나눌 때 사용한다. 예: 월별 로그 테이블, 연도별 주문 테이블.
>
> **Q: 파티셔닝의 주요 장점은?**
> **A:** 쿼리 시 필요한 파티션만 스캔(파티션 프루닝), 파티션별 독립적인 인덱스, 파티션 단위 삭제/아카이빙이 빠름.

> ⭐⭐ **Level 2 (주니어)**
> - 파티션 프루닝(Partition Pruning)
> - 각 파티션 유형의 특징
> - 파티션 키 선택 기준
>
> **Q: 파티션 프루닝이란?**
> **A:** 쿼리 조건에 맞지 않는 파티션을 스캔에서 제외하는 최적화이다. WHERE 절에 파티션 키가 포함되어야 효과적이다.
>
> **Q: Hash 파티셔닝의 특징은?**
> **A:** 파티션 키를 해시하여 데이터를 균등 분배한다. 범위 쿼리는 비효율적이지만 특정 키로 조회할 때 효과적이다.
>
> **Q: List 파티셔닝은 언제 사용하는가?**
> **A:** 특정 값 목록으로 분류할 때 사용한다. 예: 지역별(서울, 부산, 대전), 상태별(대기, 처리중, 완료).
>
> **Q: 파티션 키 선택 시 고려할 점은?**
> **A:** 쿼리 패턴(자주 필터링되는 컬럼), 데이터 분포(균등 분배), 관리 요구사항(시간 기반 아카이빙).

> ⭐⭐⭐ **Level 3 (시니어)**
> - 서브 파티셔닝
> - 파티션 관리 (추가, 분할, 병합, 삭제)
> - 파티셔닝과 인덱스
>
> **Q: 서브 파티셔닝(Composite Partitioning)이란?**
> **A:** 파티션을 다시 서브 파티션으로 분할하는 것이다. 예: Range-Hash로 월별로 나눈 후 각 월을 Hash로 분산.
>
> **Q: 글로벌 인덱스와 로컬 인덱스의 차이는?**
> **A:** 로컬 인덱스는 파티션별로 생성되어 파티션 작업 시 영향 범위가 작다. 글로벌 인덱스는 전체 테이블에 하나로 파티션 작업 시 재구축 필요.
>
> **Q: 파티션 삭제가 DELETE보다 빠른 이유는?**
> **A:** DELETE는 행마다 작업하고 로그를 남기지만, 파티션 DROP은 메타데이터만 변경하므로 거의 즉시 완료된다.
>
> **Q: 파티션 분할(SPLIT)은 언제 필요한가?**
> **A:** 한 파티션이 너무 커졌을 때 더 작은 범위로 나눈다. 예: 연간 파티션을 분기별로 분할.

> ⭐⭐⭐⭐ **Level 4 (리드/CTO)**
> - 파티셔닝 전략 설계
> - 파티셔닝 vs 샤딩 결정
> - 대규모 파티셔닝 마이그레이션
>
> **Q: 파티셔닝과 샤딩 중 어떤 것을 선택해야 하는가?**
> **A:** 단일 서버 한계 내에서 해결 가능하면 파티셔닝, 여러 서버로 확장이 필요하면 샤딩. 파티셔닝이 운영이 단순하므로 먼저 고려.
>
> **Q: 파티셔닝이 효과가 없는 경우는?**
> **A:** 쿼리에 파티션 키가 없어 프루닝이 안 되는 경우, 파티션 수가 너무 많아 오버헤드가 커지는 경우, 핫 파티션에 부하 집중.
>
> **Q: 기존 테이블을 파티셔닝하는 방법은?**
> **A:** 1) 새 파티션 테이블 생성 후 데이터 이관 2) pg_partman 같은 도구 사용 3) 뷰와 INSTEAD OF 트리거로 점진적 전환.

### 실무 시나리오

**시나리오: 로그 테이블 비대화**
- 문제: 5년치 로그 10억 건, 조회 느림, 디스크 부족
- 해결: 월별 Range 파티셔닝 적용, 6개월 이전 파티션은 분리된 테이블스페이스로 이동, 1년 이전 파티션 DROP

### 면접 빈출 질문
- Q: 파티셔닝 시 주의할 점은?
- A: 쿼리에 파티션 키 포함 필수, 파티션 수가 너무 많으면 오버헤드, 외래 키 제약 사용 어려움, 유니크 제약에 파티션 키 포함 필요.

---

## 9. 백업 및 복구 (Backup & Recovery)

### 개념 설명

백업과 복구는 데이터 손실로부터 시스템을 보호하는 핵심 운영 활동이다. 물리적/논리적 백업 방식, 특정 시점 복구(PITR) 등 다양한 전략을 통해 데이터를 안전하게 보호한다.

### 레벨별 지식

> ⭐ **Level 1 (입문)**
> - 백업의 필요성과 종류
> - 논리적 백업 vs 물리적 백업
> - 백업 주기 결정
>
> **Q: 백업이 필요한 이유는?**
> **A:** 하드웨어 장애, 소프트웨어 버그, 휴먼 에러, 랜섬웨어 등으로 인한 데이터 손실을 복구하기 위함이다.
>
> **Q: 논리적 백업과 물리적 백업의 차이는?**
> **A:** 논리적 백업은 SQL 문장으로 데이터를 내보냄(pg_dump). 물리적 백업은 데이터 파일을 직접 복사함(pg_basebackup). 물리적이 대용량에 빠름.
>
> **Q: 전체 백업과 증분 백업의 차이는?**
> **A:** 전체 백업은 모든 데이터를 백업한다. 증분 백업은 이전 백업 이후 변경된 데이터만 백업하여 시간과 공간을 절약한다.

> ⭐⭐ **Level 2 (주니어)**
> - pg_dump / pg_restore 사용
> - pg_basebackup 사용
> - 백업 검증의 중요성
>
> **Q: pg_dump의 주요 옵션은?**
> **A:** `-F c` (커스텀 포맷, 압축됨), `-j` (병렬 덤프), `--schema-only` (스키마만), `--data-only` (데이터만), `-t` (특정 테이블).
>
> **Q: pg_basebackup은 언제 사용하는가?**
> **A:** 물리적 전체 백업을 위해 사용한다. 스트리밍 복제 구성, PITR을 위한 기본 백업, 복제본 구축에 활용된다.
>
> **Q: 백업 검증을 왜 해야 하는가?**
> **A:** 실제 복구가 필요할 때 백업이 손상되었거나 불완전할 수 있다. 정기적으로 복구 테스트를 수행하여 백업의 유효성을 확인해야 한다.
>
> **Q: 핫 백업(Hot Backup)이란?**
> **A:** 데이터베이스가 온라인 상태에서 수행하는 백업이다. 서비스 중단 없이 백업 가능하며, PostgreSQL의 pg_basebackup이 지원한다.

> ⭐⭐⭐ **Level 3 (시니어)**
> - PITR (Point-In-Time Recovery)
> - WAL 아카이빙
> - 복구 전략 설계
>
> **Q: PITR이란?**
> **A:** 특정 시점으로 데이터베이스를 복구하는 기능이다. 기본 백업 + WAL 아카이브를 사용하여 장애 발생 직전이나 잘못된 쿼리 실행 전 시점으로 복구한다.
>
> **Q: WAL 아카이빙은 어떻게 구성하는가?**
> **A:** postgresql.conf에서 archive_mode=on, archive_command 설정. WAL 파일이 생성될 때마다 안전한 저장소로 복사된다.
>
> **Q: RTO와 RPO란?**
> **A:** RTO(Recovery Time Objective)는 복구에 허용되는 최대 시간. RPO(Recovery Point Objective)는 허용 가능한 최대 데이터 손실 시간. 비즈니스 요구사항에 따라 결정.
>
> **Q: 연속 아카이빙의 장점은?**
> **A:** 전체 백업 사이의 변경사항도 복구 가능, 특정 시점 복구(PITR) 지원, 복제 구성의 기반, 최소한의 데이터 손실(RPO 최소화).

> ⭐⭐⭐⭐ **Level 4 (리드/CTO)**
> - 재해 복구(DR) 전략
> - 백업 인프라 설계
> - 복구 테스트 프로세스
>
> **Q: 3-2-1 백업 규칙이란?**
> **A:** 3개의 데이터 복사본, 2개의 다른 저장 매체, 1개의 오프사이트 보관. 재해 상황에서도 데이터를 복구할 수 있도록 보장한다.
>
> **Q: 크로스 리전 재해 복구 전략은?**
> **A:** 다른 리전에 대기 복제본 유지, WAL 아카이브를 S3/GCS에 저장, 정기적인 DR 훈련으로 절차 검증, 자동 페일오버 또는 수동 전환 절차 수립.
>
> **Q: 백업 성능 최적화 방법은?**
> **A:** 병렬 덤프(-j), 압축 사용, 증분/차등 백업, 복제본에서 백업 수행, 네트워크 대역폭 충분히 확보, 백업 시간대 분산.

### 실무 시나리오

**시나리오: 실수로 테이블 DROP**
- 문제: 운영 DB에서 실수로 중요 테이블 DROP 실행
- 해결: PITR로 DROP 직전 시점으로 복구
```bash
pg_basebackup으로 만든 기본 백업 복원
recovery.conf에 recovery_target_time 설정
WAL 아카이브 적용하여 해당 시점까지 복구
```

### 면접 빈출 질문
- Q: 백업은 있는데 복구가 실패하는 경우는?
- A: 백업 파일 손상, WAL 아카이브 누락, 버전 불일치, 복구 절차 오류. 정기적인 복구 테스트로 방지해야 한다.

---

## 10. 커넥션 풀링 (Connection Pooling)

### 개념 설명

커넥션 풀링은 데이터베이스 연결을 미리 생성하여 풀에 유지하고, 필요할 때 재사용하는 기법이다. 연결 생성 오버헤드를 줄이고 데이터베이스 리소스를 효율적으로 사용한다.

### 레벨별 지식

> ⭐ **Level 1 (입문)**
> - 커넥션 풀링이 필요한 이유
> - 커넥션 생성 비용
> - 기본 동작 방식
>
> **Q: 커넥션 풀링이 필요한 이유는?**
> **A:** DB 연결 생성은 비용이 높다(TCP 핸드셰이크, 인증, 메모리 할당). 매 요청마다 연결을 만들면 성능이 저하되고 DB 리소스가 고갈된다.
>
> **Q: 커넥션 풀의 동작 방식은?**
> **A:** 미리 일정 수의 연결을 생성하여 풀에 유지한다. 애플리케이션이 요청하면 풀에서 연결을 빌려주고, 사용 후 반환받아 재사용한다.
>
> **Q: 커넥션 풀 없이 발생하는 문제는?**
> **A:** 연결 생성 지연, DB 최대 연결 수 초과, 리소스 고갈로 인한 서비스 장애, 연결 생성/해제 오버헤드.

> ⭐⭐ **Level 2 (주니어)**
> - 풀 사이즈 설정 (min, max)
> - 연결 유효성 검사
> - 타임아웃 설정
>
> **Q: 최적의 풀 사이즈는 어떻게 결정하는가?**
> **A:** 일반적으로 `(CPU 코어 수 * 2) + 유효 스핀들 수`. 벤치마크로 검증해야 한다. 너무 크면 DB 부하 증가, 너무 작으면 대기 발생.
>
> **Q: 연결 유효성 검사는 왜 필요한가?**
> **A:** 오래된 연결이 끊어졌을 수 있다. 사용 전 검사(validation query)로 죽은 연결 사용을 방지한다. 성능 영향을 고려하여 주기 설정.
>
> **Q: connection timeout과 idle timeout의 차이는?**
> **A:** connection timeout은 새 연결 획득 대기 시간. idle timeout은 사용하지 않는 연결을 풀에서 제거하는 시간.
>
> **Q: 연결 누수(Connection Leak)란?**
> **A:** 연결을 빌려간 후 반환하지 않는 것. 풀이 고갈되어 새 요청이 대기하게 된다. 반드시 finally 블록이나 try-with-resources로 반환해야 한다.

> ⭐⭐⭐ **Level 3 (시니어)**
> - PgBouncer vs HikariCP
> - 트랜잭션 풀링 vs 세션 풀링
> - 커넥션 풀 모니터링
>
> **Q: PgBouncer의 풀링 모드는?**
> **A:** Session(세션 동안 연결 유지), Transaction(트랜잭션 동안만), Statement(각 쿼리마다). Transaction 모드가 가장 효율적이지만 세션 기능 제한.
>
> **Q: Transaction 풀링에서 사용할 수 없는 기능은?**
> **A:** Prepared Statement(세션 범위), 세션 변수(SET), LISTEN/NOTIFY, 임시 테이블. 이런 기능이 필요하면 Session 풀링 사용.
>
> **Q: HikariCP의 특징은?**
> **A:** Java 기반 고성능 커넥션 풀. 빠른 연결 획득, 연결 누수 감지, 상세 메트릭 제공. Spring Boot 기본 풀로 사용됨.
>
> **Q: 커넥션 풀 병목을 어떻게 진단하는가?**
> **A:** 대기 중인 요청 수, 평균 획득 시간, 활성 연결 수 모니터링. HikariCP는 JMX/Micrometer 메트릭 제공.

> ⭐⭐⭐⭐ **Level 4 (리드/CTO)**
> - 대규모 시스템 커넥션 관리
> - 멀티 DB 커넥션 전략
> - 클라우드 환경 커넥션 관리
>
> **Q: 수천 개 인스턴스에서 커넥션 관리 전략은?**
> **A:** 각 인스턴스 풀 사이즈 최소화, 중앙 집중식 풀러(PgBouncer) 도입, 서버리스 연결(Aurora Serverless), 읽기/쓰기 분리.
>
> **Q: PgBouncer를 배치하는 위치는?**
> **A:** 1) 애플리케이션과 같은 호스트 2) 별도 서버 3) 각 DB 앞에 배치. 규모와 요구사항에 따라 선택. 고가용성을 위해 이중화.
>
> **Q: 컨테이너 환경에서 커넥션 관리 주의점은?**
> **A:** 스케일 아웃 시 연결 수 급증 가능. 외부 풀러 사용, 연결 수 제한, 자동 스케일링 정책과 DB 연결 수 연계 고려.

### 실무 시나리오

**시나리오: 피크 시간 커넥션 풀 고갈**
- 문제: 트래픽 급증 시 "too many connections" 에러
- 진단: max 풀 사이즈 < 동시 요청 수, DB max_connections 한계
- 해결: 풀 사이즈 조정, PgBouncer 도입, 쿼리 최적화로 점유 시간 단축

### 면접 빈출 질문
- Q: 커넥션 풀 사이즈가 클수록 좋은가?
- A: 아니다. 너무 크면 DB 리소스(메모리, CPU) 부담 증가, 컨텍스트 스위칭 오버헤드. 적절한 크기를 벤치마크로 찾아야 한다.

---

## 11. Slow Query 최적화

### 개념 설명

Slow Query는 실행 시간이 임계값을 초과하는 쿼리다. 시스템 성능 저하의 주요 원인이며, 식별과 최적화가 지속적으로 필요하다. 실행계획 분석, 인덱스 튜닝, 쿼리 리팩토링 등으로 해결한다.

### 레벨별 지식

> ⭐ **Level 1 (입문)**
> - Slow Query의 정의와 영향
> - 느린 쿼리 로그 설정
> - 기본적인 최적화 방법
>
> **Q: Slow Query를 어떻게 식별하는가?**
> **A:** PostgreSQL: log_min_duration_statement 설정으로 임계값 초과 쿼리 로깅. 또는 pg_stat_statements로 쿼리별 통계 수집.
>
> **Q: Slow Query가 시스템에 미치는 영향은?**
> **A:** CPU/메모리/I/O 리소스 점유, 다른 쿼리 지연, 잠금 보유 시간 증가, 커넥션 점유로 풀 고갈, 전체 서비스 응답 시간 증가.
>
> **Q: 기본적인 최적화 방법은?**
> **A:** 필요한 컬럼만 SELECT, WHERE 절에 인덱스 활용, 불필요한 서브쿼리 제거, LIMIT 사용, JOIN 최소화.

> ⭐⭐ **Level 2 (주니어)**
> - pg_stat_statements 활용
> - 실행계획 분석을 통한 최적화
> - 인덱스 추가/수정
>
> **Q: pg_stat_statements로 무엇을 확인하는가?**
> **A:** 쿼리별 호출 횟수, 총 실행 시간, 평균 시간, 행 수. total_time과 calls로 정렬하여 가장 영향 큰 쿼리 식별.
>
> **Q: 실행계획에서 비효율적인 패턴은?**
> **A:** Seq Scan on 대용량 테이블, Nested Loop on 큰 테이블, Sort with large memory, 예상 vs 실제 행 수 큰 차이.
>
> **Q: N+1 쿼리 문제란?**
> **A:** 목록 조회 후 각 항목마다 추가 쿼리 실행. 예: 주문 10건 조회 후 각 주문의 상품 조회 = 11번 쿼리. JOIN이나 배치 로딩으로 해결.
>
> **Q: 인덱스를 추가해도 안 쓰이는 경우는?**
> **A:** 테이블이 작아서 Seq Scan이 더 효율적, 인덱스 선택도가 낮음, 함수를 적용한 컬럼, 잘못된 데이터 타입 비교, 통계 정보 오래됨.

> ⭐⭐⭐ **Level 3 (시니어)**
> - 쿼리 리팩토링 기법
> - 파라미터 튜닝
> - 배치 처리 최적화
>
> **Q: 서브쿼리를 JOIN으로 변환하는 이유는?**
> **A:** 서브쿼리는 중첩 루프로 실행될 수 있다. JOIN은 옵티마이저가 최적의 조인 알고리즘을 선택할 수 있어 더 효율적인 경우가 많다.
>
> **Q: work_mem 파라미터의 영향은?**
> **A:** 정렬, 해시 조인에 사용되는 메모리. 너무 작으면 디스크 사용(slow), 너무 크면 메모리 부족. 쿼리 복잡도와 동시 연결 수 고려.
>
> **Q: 대량 데이터 처리 시 최적화 방법은?**
> **A:** 배치 크기 조절, COPY 명령 사용(INSERT 대신), 인덱스 비활성화 후 작업, 트랜잭션 분할, 병렬 처리.
>
> **Q: CTE(WITH 절)의 성능 특성은?**
> **A:** PostgreSQL 12 이전은 CTE가 항상 물리화되어 최적화가 제한됨. 12 이후 인라인이 가능하지만 MATERIALIZED 힌트로 제어 가능.

> ⭐⭐⭐⭐ **Level 4 (리드/CTO)**
> - 전사 쿼리 성능 관리 체계
> - 자동화된 슬로우 쿼리 감지
> - 성능 SLO 설정
>
> **Q: 쿼리 성능 모니터링 체계 구축 방법은?**
> **A:** pg_stat_statements 데이터 정기 수집, 대시보드(Grafana)로 시각화, 임계값 초과 시 알림, 주기적인 성능 리뷰 프로세스.
>
> **Q: 데이터베이스 성능 SLO 예시는?**
> **A:** p99 쿼리 응답 시간 < 100ms, 슬로우 쿼리(>1s) 비율 < 0.1%, 평균 쿼리 시간 < 10ms. 비즈니스 요구사항에 맞게 설정.
>
> **Q: 쿼리 성능 저하를 예방하는 방법은?**
> **A:** 코드 리뷰에서 쿼리 검토, 테스트 환경에서 실행계획 확인, 점진적 배포, 변경 후 성능 메트릭 모니터링.

### 실무 시나리오

**시나리오: 대시보드 페이지 로딩 10초**
- 진단: 하나의 페이지에서 50개 쿼리 실행 (N+1 문제)
- 분석: 주문 목록 조회 후 각 주문별 상품, 고객 정보 개별 조회
- 해결: JOIN으로 통합, 필요한 데이터만 SELECT, 결과 캐싱 적용

### 면접 빈출 질문
- Q: 쿼리 최적화 순서는?
- A: 1) 실행계획 분석 2) 인덱스 확인/추가 3) 쿼리 리팩토링 4) 파라미터 튜닝 5) 아키텍처 개선(캐싱, 비정규화) 순으로 접근.

---

## 12. NoSQL 데이터베이스

### 개념 설명

NoSQL은 비관계형 데이터베이스로, 스키마 유연성, 수평 확장성, 높은 성능을 제공한다. 문서형, 키-값, 컬럼형, 그래프형 등 다양한 유형이 있으며, 용도에 맞게 선택한다.

### 레벨별 지식

> ⭐ **Level 1 (입문)**
> - NoSQL vs RDBMS 차이
> - NoSQL 유형 개요
> - 사용 사례
>
> **Q: NoSQL이 RDBMS와 다른 점은?**
> **A:** 스키마가 유연하고, 조인 없이 비정규화된 데이터 저장, 수평 확장이 용이, ACID 대신 BASE 특성을 가지는 경우가 많다.
>
> **Q: 문서형 데이터베이스(MongoDB)의 특징은?**
> **A:** JSON/BSON 형태로 데이터 저장, 중첩 구조 지원, 스키마 유연, 관련 데이터를 하나의 문서에 저장하여 조인 불필요.
>
> **Q: 키-값 저장소(Redis)는 언제 사용하는가?**
> **A:** 캐싱, 세션 저장, 실시간 리더보드, 메시지 큐 등 빠른 읽기/쓰기가 필요하고 단순한 조회 패턴일 때 사용.

> ⭐⭐ **Level 2 (주니어)**
> - MongoDB 기본 개념 (Collection, Document)
> - Redis 자료구조
> - DynamoDB 파티션 키/정렬 키
>
> **Q: MongoDB에서 인덱싱은 어떻게 하는가?**
> **A:** createIndex()로 생성. 단일/복합/멀티키(배열)/텍스트/지리공간 인덱스 지원. RDBMS와 유사하게 쿼리 성능 향상.
>
> **Q: Redis의 주요 자료구조는?**
> **A:** String(단순 값), List(큐/스택), Set(집합 연산), Sorted Set(순위), Hash(필드-값 맵), Stream(로그). 용도에 맞게 선택.
>
> **Q: DynamoDB의 파티션 키와 정렬 키는?**
> **A:** 파티션 키는 데이터 분산 기준(필수), 정렬 키는 같은 파티션 내 정렬 기준(선택). 함께 사용하면 복합 기본 키.
>
> **Q: Redis 영속성 옵션은?**
> **A:** RDB(스냅샷), AOF(명령어 로그), 둘 다 사용 가능. RDB는 복구가 빠르고 AOF는 데이터 손실이 적다.

> ⭐⭐⭐ **Level 3 (시니어)**
> - MongoDB 집계 파이프라인
> - Redis 클러스터
> - DynamoDB 용량 모드와 GSI
>
> **Q: MongoDB 집계 파이프라인이란?**
> **A:** 데이터 처리 단계를 파이프라인으로 연결. $match(필터), $group(집계), $sort(정렬), $project(필드 선택) 등의 스테이지 조합.
>
> **Q: Redis 클러스터의 동작 방식은?**
> **A:** 16384개 해시 슬롯을 노드에 분배. 키는 CRC16 해시로 슬롯에 매핑. 자동 샤딩과 페일오버 지원. 클라이언트가 리다이렉션 처리.
>
> **Q: DynamoDB GSI(Global Secondary Index)란?**
> **A:** 기본 키와 다른 속성으로 쿼리할 수 있는 인덱스. 별도 파티션에 데이터 복제. LSI(Local)는 같은 파티션 내에서만 동작.
>
> **Q: Redis에서 메모리 관리 전략은?**
> **A:** maxmemory 설정, eviction 정책(LRU, LFU, random, volatile), 적절한 데이터 구조 선택, TTL 설정으로 자동 만료.

> ⭐⭐⭐⭐ **Level 4 (리드/CTO)**
> - Polyglot Persistence
> - NoSQL 선택 기준
> - 대규모 NoSQL 아키텍처
>
> **Q: Polyglot Persistence란?**
> **A:** 하나의 애플리케이션에서 여러 종류의 데이터베이스를 용도에 맞게 사용하는 것. 예: PostgreSQL(트랜잭션) + Redis(캐시) + Elasticsearch(검색).
>
> **Q: MongoDB vs DynamoDB 선택 기준은?**
> **A:** MongoDB는 복잡한 쿼리, 집계, 유연한 스키마에 적합. DynamoDB는 예측 가능한 접근 패턴, 무한 확장성, AWS 통합에 적합.
>
> **Q: NoSQL 도입 시 주의점은?**
> **A:** 트랜잭션 제한, 조인 불가로 인한 데이터 모델링 복잡성, 일관성 모델 이해, 운영 복잡성. RDBMS로 충분한 경우 무리하게 도입하지 않는다.

### 실무 시나리오

**시나리오: 실시간 랭킹 시스템**
- 요구사항: 수백만 사용자 점수 실시간 업데이트, 상위 100명 조회
- 해결: Redis Sorted Set 사용
```redis
ZADD leaderboard 1000 "user:123"  # 점수 설정
ZREVRANGE leaderboard 0 99 WITHSCORES  # 상위 100명
ZRANK leaderboard "user:123"  # 순위 조회
```

### 면접 빈출 질문
- Q: CAP 정리에서 MongoDB와 DynamoDB는 어디에 해당하는가?
- A: MongoDB는 기본적으로 CP(일관성+파티션 허용), DynamoDB는 설정에 따라 AP(eventually consistent) 또는 CP(strongly consistent read) 선택 가능.

---

## 13. 캐싱 전략 (Caching Strategies)

### 개념 설명

캐싱은 자주 접근하는 데이터를 빠른 저장소에 임시 저장하여 응답 시간을 줄이고 데이터베이스 부하를 낮추는 기법이다. 캐시 패턴과 무효화 전략이 핵심이다.

### 레벨별 지식

> ⭐ **Level 1 (입문)**
> - 캐싱의 목적과 이점
> - 캐시 히트와 미스
> - TTL(Time-To-Live)
>
> **Q: 캐싱을 사용하는 이유는?**
> **A:** 데이터베이스 조회보다 훨씬 빠른 응답, DB 부하 감소, 비용 절감, 더 많은 동시 요청 처리 가능.
>
> **Q: 캐시 히트율이 중요한 이유는?**
> **A:** 히트율이 높을수록 캐시 효과가 크다. 히트율 = 캐시 히트 / (히트 + 미스). 80% 이상이 일반적인 목표.
>
> **Q: TTL을 어떻게 설정해야 하는가?**
> **A:** 데이터 변경 빈도, 허용 가능한 불일치 시간, 메모리 용량을 고려. 변경이 적은 데이터는 긴 TTL, 자주 변경되는 데이터는 짧은 TTL.

> ⭐⭐ **Level 2 (주니어)**
> - Cache-Aside 패턴
> - Read-Through / Write-Through
> - Write-Behind (Write-Back)
>
> **Q: Cache-Aside 패턴의 동작은?**
> **A:** 1) 캐시 조회 2) 미스 시 DB 조회 3) 결과를 캐시에 저장 4) 반환. 쓰기 시 DB 업데이트 후 캐시 무효화. 가장 일반적인 패턴.
>
> **Q: Read-Through와 Cache-Aside의 차이는?**
> **A:** Read-Through는 캐시가 DB 조회를 담당하고 애플리케이션은 항상 캐시에만 요청. Cache-Aside는 애플리케이션이 DB와 캐시를 직접 관리.
>
> **Q: Write-Through의 장단점은?**
> **A:** 장점은 캐시와 DB가 항상 동기화. 단점은 모든 쓰기에 두 곳 저장으로 지연 증가. 읽기가 많고 쓰기가 적을 때 적합.
>
> **Q: Write-Behind는 언제 사용하는가?**
> **A:** 쓰기 성능이 중요할 때. 캐시에 먼저 쓰고 비동기로 DB에 반영. 데이터 손실 위험이 있어 내구성이 중요하지 않은 데이터에 적합.

> ⭐⭐⭐ **Level 3 (시니어)**
> - 캐시 무효화 전략
> - Thundering Herd 문제
> - Cache Stampede 방지
>
> **Q: 캐시 무효화 전략의 종류는?**
> **A:** 1) TTL 만료 2) 이벤트 기반(데이터 변경 시 삭제) 3) 버전 기반(키에 버전 포함) 4) Pub/Sub으로 분산 무효화.
>
> **Q: Thundering Herd 문제란?**
> **A:** 인기 캐시 키가 만료될 때 동시에 많은 요청이 DB로 몰리는 현상. DB에 과부하를 유발하고 서비스 장애로 이어질 수 있다.
>
> **Q: Thundering Herd를 어떻게 방지하는가?**
> **A:** 1) 뮤텍스/락으로 하나의 요청만 DB 조회 2) 만료 전 미리 갱신(background refresh) 3) TTL에 랜덤 지터 추가 4) 스태일 데이터 허용.
>
> **Q: Stale-While-Revalidate 패턴이란?**
> **A:** 만료된 캐시 데이터를 즉시 반환하면서 백그라운드에서 새 데이터를 가져와 갱신. 응답 속도와 데이터 신선도 균형.

> ⭐⭐⭐⭐ **Level 4 (리드/CTO)**
> - 멀티 레이어 캐시 아키텍처
> - 분산 캐시 설계
> - 캐시 워밍 전략
>
> **Q: 멀티 레이어 캐시 구조는?**
> **A:** L1: 로컬 메모리(가장 빠름) → L2: 분산 캐시(Redis) → L3: CDN → Origin(DB). 계층별로 히트율을 높여 부하 분산.
>
> **Q: 캐시 워밍(Cache Warming)이 필요한 경우는?**
> **A:** 서비스 시작 시 캐시가 비어있어 콜드 스타트 발생. 배포 전 미리 자주 조회되는 데이터를 캐시에 로드.
>
> **Q: 분산 캐시의 일관성 문제 해결 방법은?**
> **A:** 1) 캐시 무효화 이벤트 발행 2) Redis Pub/Sub 또는 Kafka로 전파 3) 버전 기반 키 사용 4) 짧은 TTL로 최종 일관성.

### 실무 시나리오

**시나리오: 인기 상품 페이지 캐시 만료**
- 문제: 인기 상품 캐시 만료 시 수천 요청이 동시에 DB 조회
- 해결:
```python
def get_product(product_id):
    cached = redis.get(f"product:{product_id}")
    if cached:
        return cached

    # 락 획득 시도
    if redis.set(f"lock:product:{product_id}", "1", nx=True, ex=10):
        product = db.query(product_id)
        redis.setex(f"product:{product_id}", 3600, product)
        redis.delete(f"lock:product:{product_id}")
        return product
    else:
        # 다른 요청이 갱신 중, 잠시 대기 후 재시도
        time.sleep(0.1)
        return get_product(product_id)
```

### 면접 빈출 질문
- Q: 캐시와 DB의 데이터 정합성을 어떻게 보장하는가?
- A: 완벽한 정합성은 어렵다. 쓰기 시 캐시 무효화, 짧은 TTL, 이벤트 기반 갱신을 조합하여 최종 일관성을 달성한다.

---

## 14. 검색엔진 (Elasticsearch)

### 개념 설명

Elasticsearch는 Apache Lucene 기반의 분산 검색 및 분석 엔진이다. 역인덱스(Inverted Index)를 사용하여 대량의 텍스트 데이터에서 빠른 전문 검색을 제공한다.

### 레벨별 지식

> ⭐ **Level 1 (입문)**
> - Elasticsearch의 용도
> - 인덱스, 문서, 필드 개념
> - 기본 검색 쿼리
>
> **Q: Elasticsearch는 언제 사용하는가?**
> **A:** 전문 검색(Full-text Search), 로그 분석, 실시간 모니터링, 복잡한 검색 조건이 필요할 때. RDBMS의 LIKE 검색보다 훨씬 빠르고 유연.
>
> **Q: 역인덱스(Inverted Index)란?**
> **A:** 단어를 키로, 해당 단어가 포함된 문서 목록을 값으로 저장하는 구조. "apple"을 검색하면 바로 해당 문서들을 찾을 수 있다.
>
> **Q: 인덱스, 문서, 필드의 관계는?**
> **A:** 인덱스는 문서의 컬렉션(RDBMS의 테이블), 문서는 JSON 형태의 데이터 단위(행), 필드는 문서 내의 키-값(열).

> ⭐⭐ **Level 2 (주니어)**
> - 매핑(Mapping) 설정
> - 분석기(Analyzer)
> - 기본 쿼리 DSL
>
> **Q: 매핑(Mapping)이란?**
> **A:** 문서의 각 필드에 대한 데이터 타입과 분석 방법을 정의. text(분석됨), keyword(정확히 일치), date, integer 등의 타입 지정.
>
> **Q: 분석기(Analyzer)의 구성 요소는?**
> **A:** Character Filter(문자 전처리) → Tokenizer(토큰 분리) → Token Filter(토큰 후처리). 예: HTML 제거 → 공백 분리 → 소문자화.
>
> **Q: match 쿼리와 term 쿼리의 차이는?**
> **A:** match는 검색어를 분석하여 검색(전문 검색), term은 검색어를 분석 없이 정확히 일치하는 것을 검색(keyword 필드용).
>
> **Q: bool 쿼리의 구성 요소는?**
> **A:** must(AND, 점수 영향), filter(AND, 점수 무관), should(OR), must_not(NOT). 복잡한 조건을 조합할 때 사용.

> ⭐⭐⭐ **Level 3 (시니어)**
> - 집계(Aggregation)
> - 클러스터 아키텍처
> - 성능 튜닝
>
> **Q: 집계(Aggregation)의 종류는?**
> **A:** Metric(avg, sum, max), Bucket(terms, histogram, date_histogram), Pipeline(이전 집계 결과 처리). SQL의 GROUP BY + 집계함수와 유사.
>
> **Q: 샤드와 레플리카의 역할은?**
> **A:** 샤드는 데이터를 분산 저장(수평 확장), 레플리카는 샤드의 복제본(고가용성, 읽기 분산). 인덱스 생성 시 설정.
>
> **Q: 검색 성능을 최적화하는 방법은?**
> **A:** 적절한 샤드 수, 불필요한 필드 분석 제외, filter 컨텍스트 활용(캐싱), 적절한 bulk 사이즈, 리프레시 간격 조정.
>
> **Q: 인덱스 별칭(Alias)을 사용하는 이유는?**
> **A:** 무중단 인덱스 재구성(새 인덱스 생성 후 별칭 전환), 여러 인덱스 통합 검색, 필터링된 뷰 제공.

> ⭐⭐⭐⭐ **Level 4 (리드/CTO)**
> - 대규모 클러스터 운영
> - 인덱스 라이프사이클 관리(ILM)
> - 검색 아키텍처 설계
>
> **Q: 클러스터 규모 산정 기준은?**
> **A:** 데이터 크기, 색인/검색 처리량, 복제본 수, 메모리(힙 30GB 이하), 샤드 수(노드당 20개 이하 권장).
>
> **Q: ILM(Index Lifecycle Management)이란?**
> **A:** 인덱스의 생애주기를 자동 관리. Hot(활성) → Warm(읽기 전용) → Cold(아카이브) → Delete 단계별로 정책 적용.
>
> **Q: Elasticsearch와 RDBMS를 함께 사용하는 패턴은?**
> **A:** RDBMS를 원본 데이터 저장소로, Elasticsearch를 검색용으로 사용. CDC 또는 배치 동기화로 데이터 연동.

### 실무 시나리오

**시나리오: 상품 검색 기능 구현**
- 요구사항: 상품명, 설명에서 전문 검색, 카테고리/가격 필터, 관련성 정렬
- 구현:
```json
{
  "query": {
    "bool": {
      "must": [
        { "multi_match": { "query": "무선 이어폰", "fields": ["name^2", "description"] } }
      ],
      "filter": [
        { "term": { "category": "electronics" } },
        { "range": { "price": { "gte": 50000, "lte": 200000 } } }
      ]
    }
  }
}
```

### 면접 빈출 질문
- Q: Elasticsearch가 RDBMS 검색보다 빠른 이유는?
- A: 역인덱스 구조로 O(1)에 가까운 검색, 분산 처리로 병렬 검색, 텍스트 분석으로 유연한 매칭, 결과 캐싱.

---

## 15. 데이터 모델링

### 개념 설명

데이터 모델링은 비즈니스 요구사항을 데이터베이스 스키마로 변환하는 과정이다. 개념적, 논리적, 물리적 모델링 단계를 거치며, 정규화와 성능 사이의 균형을 찾는 것이 핵심이다.

### 레벨별 지식

> ⭐ **Level 1 (입문)**
> - 데이터 모델링의 단계
> - 엔티티와 관계
> - ERD 기본 표기법
>
> **Q: 데이터 모델링의 3단계는?**
> **A:** 개념적(비즈니스 개념 정의) → 논리적(엔티티, 속성, 관계 정의) → 물리적(테이블, 컬럼, 인덱스 정의).
>
> **Q: 엔티티(Entity)란?**
> **A:** 저장하고 관리할 필요가 있는 데이터 대상. 예: 고객, 주문, 상품. 테이블로 구현된다.
>
> **Q: 관계(Relationship)의 종류는?**
> **A:** 1:1(일대일), 1:N(일대다), N:M(다대다). N:M은 중간 테이블로 1:N 두 개로 분해.

> ⭐⭐ **Level 2 (주니어)**
> - 식별자와 비식별자 관계
> - 제약조건 설계
> - 데이터 타입 선택
>
> **Q: 식별 관계와 비식별 관계의 차이는?**
> **A:** 식별 관계는 부모 기본키가 자식의 기본키 일부가 됨(강한 종속). 비식별 관계는 외래키로만 참조(약한 종속).
>
> **Q: VARCHAR vs TEXT 선택 기준은?**
> **A:** 길이 제한이 필요하면 VARCHAR, 제한 없는 긴 텍스트면 TEXT. PostgreSQL에서는 성능 차이가 거의 없으나 의미 전달 면에서 구분.
>
> **Q: NULL 허용 여부는 어떻게 결정하는가?**
> **A:** 비즈니스 규칙에 따라 결정. 필수 값은 NOT NULL, 선택 값은 NULL 허용. NULL이 많으면 조회 로직 복잡해짐.
>
> **Q: 기본값(DEFAULT)을 설정하는 경우는?**
> **A:** 생성일시(CURRENT_TIMESTAMP), 상태(초기 상태), 카운터(0) 등 자동 설정이 필요한 경우.

> ⭐⭐⭐ **Level 3 (시니어)**
> - 정규화 vs 비정규화 트레이드오프
> - 성능을 고려한 물리 설계
> - 이력 관리 패턴
>
> **Q: 이력 데이터를 어떻게 관리하는가?**
> **A:** 1) 별도 이력 테이블 2) 유효 시작/종료일 컬럼 추가 3) 소프트 삭제(deleted_at) 4) 이벤트 소싱. 요구사항에 따라 선택.
>
> **Q: 다형성(Polymorphism)을 DB에서 어떻게 구현하는가?**
> **A:** 1) 단일 테이블(type 컬럼 + NULL 가능 컬럼들) 2) 타입별 테이블 + 조인 3) 타입별 완전 분리 테이블. 조회 패턴에 따라 선택.
>
> **Q: JSON 컬럼은 언제 사용하는가?**
> **A:** 스키마가 유동적, 중첩 구조, 조회는 하지만 검색/집계는 안 하는 데이터. 남용하면 RDBMS 장점을 잃음.
>
> **Q: 계층 구조 데이터 모델링 방법은?**
> **A:** 1) 인접 리스트(parent_id) 2) 경로 열거(path) 3) 중첩 집합 4) Closure Table. 조회/수정 패턴에 따라 선택.

> ⭐⭐⭐⭐ **Level 4 (리드/CTO)**
> - OLTP vs OLAP 모델링
> - 도메인 주도 설계와 데이터 모델링
> - 대규모 시스템 데이터 아키텍처
>
> **Q: OLTP와 OLAP의 데이터 모델 차이는?**
> **A:** OLTP는 정규화된 ERD, 트랜잭션 최적화. OLAP은 스타/스노우플레이크 스키마, 분석 쿼리 최적화. ETL로 OLTP→OLAP 전환.
>
> **Q: DDD의 Aggregate를 DB에 어떻게 매핑하는가?**
> **A:** Aggregate Root가 기본 테이블, 하위 엔티티는 1:N 관계. Aggregate 경계는 트랜잭션 경계와 일치. Aggregate 간은 ID 참조만.
>
> **Q: 마이크로서비스에서 데이터 모델링 원칙은?**
> **A:** 서비스별 독립적 DB, 서비스 간 데이터 복제 허용, 이벤트로 동기화, 결과적 일관성 수용. 조인 불가하므로 읽기 모델 별도 구축.

### 실무 시나리오

**시나리오: 주문 시스템 데이터 모델링**
- 요구사항: 주문, 주문상품, 결제, 배송 관리
- 설계:
  - orders (주문 기본 정보, 상태)
  - order_items (주문별 상품, 수량, 가격)
  - payments (결제 정보, 외부 결제 ID)
  - shipments (배송 정보, 추적번호)
- 고려사항: 주문-결제 1:N(부분결제), 주문-배송 1:N(분리배송), 가격 스냅샷 저장

### 면접 빈출 질문
- Q: 외래키 제약조건을 사용해야 하는가?
- A: 데이터 무결성 보장을 위해 권장. 단, 대량 데이터 로딩 시 성능 영향, 샤딩 시 적용 어려움. 마이크로서비스에서는 애플리케이션에서 관리하기도 함.

