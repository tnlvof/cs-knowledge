-- seed-v3-diff3-mon-sec.sql
-- 시니어급 (난이도 3) CS 퀴즈 문제
-- monitoring 25문제 + security 25문제 = 총 50문제
-- level_min=30, level_max=75

-- =====================================================
-- MONITORING (모니터링/관측성) - 25문제
-- =====================================================

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('monitoring', 'prometheus', 3, 30, 75, '대규모 Kubernetes 환경에서 Prometheus 메모리 OOM이 반복적으로 발생할 때, 근본 원인 분석 및 해결 전략을 설명해주세요.', '주요 원인은 높은 카디널리티 메트릭입니다. 1) tsdb status로 고카디널리티 메트릭 식별, 2) relabel_configs로 불필요한 레이블 drop, 3) metric_relabel_configs로 고카디널리티 메트릭 필터링, 4) Kubernetes label의 pod name 대신 deployment name 사용, 5) recording rules로 집계 후 원본 drop, 6) 필요시 Prometheus 샤딩 또는 Thanos/Mimir로 전환합니다.', ARRAY['Prometheus', 'OOM', '카디널리티', 'relabel_configs', 'recording rules'], '카디널리티 폭발의 대표적 원인은 user_id, request_id, pod_name 등 고유 값을 레이블로 사용하는 경우입니다.', 'docs/05-monitoring-observability.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('monitoring', 'grafana', 3, 30, 75, 'Grafana 대시보드가 로딩에 30초 이상 걸리는 성능 문제가 발생했습니다. 체계적인 성능 최적화 접근 방법을 설명해주세요.', '1) 패널 수 줄이기(화면당 7개 이하 권장), 2) 시간 범위 제한(기본 1시간), 3) recording rules로 복잡한 쿼리 사전 계산, 4) 변수 쿼리에 캐시 적용 및 refresh 간격 조정, 5) 패널별 쿼리 인스펙터로 느린 쿼리 식별, 6) 데이터소스 프록시 타임아웃 조정, 7) Max data points 설정으로 데이터 포인트 수 제한, 8) 대시보드를 계층화하여 overview -> detail 분리합니다.', ARRAY['Grafana', '성능', 'recording rules', '대시보드 최적화', '쿼리 인스펙터'], '느린 대시보드는 사용자 경험을 해치고 장애 대응 시간을 지연시킵니다.', 'docs/05-monitoring-observability.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('monitoring', 'alerting', 3, 30, 75, '프로덕션에서 알림 피로(Alert Fatigue)가 심각하여 실제 장애 알림을 놓치는 상황이 발생했습니다. 알림 시스템 개선 전략을 제시해주세요.', '1) 알림 리뷰 미팅으로 최근 알림 분석 및 분류, 2) 조치 불가능한 알림 제거 또는 대시보드로 이동, 3) 임계값 재조정(데이터 기반 동적 임계값 고려), 4) 다중 윈도우 SLO 기반 알림으로 전환, 5) Alertmanager의 group_by/inhibit_rules 활용, 6) 심각도별 알림 채널 분리(Critical만 PagerDuty), 7) 알림당 조치율 90% 이상 목표, 8) 정기적 알림 품질 지표(MTTA, 거짓 양성률) 측정합니다.', ARRAY['알림 피로', 'Alert Fatigue', 'SLO', 'Alertmanager', '알림 품질'], '알림 피로는 팀 번아웃과 실제 장애 대응 지연으로 이어지는 심각한 운영 문제입니다.', 'docs/05-monitoring-observability.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('monitoring', 'tracing', 3, 30, 75, '마이크로서비스 환경에서 분산 트레이싱을 도입했으나 일부 서비스의 스팬이 연결되지 않아 끊어진 트레이스가 발생합니다. 원인과 해결 방법을 설명해주세요.', '원인: 1) HTTP 헤더 전파 누락(W3C traceparent 미전달), 2) 비동기 메시지 큐에서 컨텍스트 누락, 3) 외부 API 호출 시 계측 미적용, 4) 다른 트레이싱 포맷 혼용. 해결: 1) 공통 미들웨어에서 W3C Trace Context 헤더 강제, 2) Kafka/RabbitMQ 메시지 헤더에 trace context 포함, 3) HTTP 클라이언트 라이브러리에 자동 계측 적용, 4) OpenTelemetry로 표준화하여 B3/Jaeger 포맷 통일.', ARRAY['분산 트레이싱', '컨텍스트 전파', 'W3C Trace Context', 'OpenTelemetry', '스팬'], '트레이스 연결이 끊기면 분산 시스템 디버깅의 핵심 이점을 잃게 됩니다.', 'docs/05-monitoring-observability.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('monitoring', 'logging', 3, 30, 75, '하루 10TB의 로그가 발생하는 대규모 시스템에서 로그 비용을 50% 절감하면서도 문제 해결 능력을 유지하는 전략을 설명해주세요.', '1) 로그 레벨 정책 수립(프로덕션 INFO 이상, DEBUG는 동적 활성화), 2) 성공 요청 로그 샘플링(10% 또는 100개당 1개), 3) 에러/지연 요청은 100% 보존, 4) 구조화 로그로 전환하여 불필요한 필드 제거, 5) Hot/Warm/Cold 티어링(7일 Hot, 30일 Warm, 90일 Cold), 6) 로그 집계(동일 메시지 카운트로 압축), 7) Loki 같은 라벨 인덱싱 시스템으로 전환 고려, 8) 수집 단계에서 필터링(drop DEBUG, 건강체크 제외).', ARRAY['로그 비용', '샘플링', '티어링', 'Loki', '구조화 로그'], '로그 비용은 볼륨에 비례하므로 수집 단계 최적화가 가장 효과적입니다.', 'docs/05-monitoring-observability.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('monitoring', 'elk', 3, 30, 75, 'Elasticsearch 클러스터의 검색 성능이 저하되어 Kibana 대시보드 응답이 느려졌습니다. 성능 분석 및 튜닝 방법을 설명해주세요.', '1) _nodes/hot_threads로 CPU 병목 확인, 2) _cat/shards로 샤드 분포 불균형 확인, 3) _stats API로 쿼리 캐시 히트율 확인, 4) 샤드 크기 최적화(20-50GB), 5) 과도한 샤드 수 줄이기(노드당 20개 미만 권장), 6) 느린 쿼리 로그 활성화로 문제 쿼리 식별, 7) 와일드카드/정규식 쿼리 최소화, 8) 핫 노드에 SSD 적용, 9) ILM으로 오래된 인덱스 Cold/Frozen으로 이동.', ARRAY['Elasticsearch', '성능 튜닝', '샤드', 'ILM', '쿼리 최적화'], 'Elasticsearch 성능 저하의 80%는 샤드 설계와 쿼리 패턴 문제에서 기인합니다.', 'docs/05-monitoring-observability.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('monitoring', 'loki', 3, 30, 75, 'Loki에서 특정 로그 검색이 타임아웃되는 문제가 발생했습니다. 쿼리 성능을 개선하는 방법을 설명해주세요.', '1) 라벨 셀렉터를 최대한 구체화하여 스트림 범위 축소, 2) 시간 범위를 좁게 설정(1시간 이내), 3) 고카디널리티 값은 라벨 대신 로그 본문에 포함, 4) Query Frontend의 캐시 활용, 5) 쿼리 샤딩/스플리팅 설정 조정, 6) 불필요한 파싱 파이프라인 제거(json, logfmt은 필요시만), 7) 라벨 카디널리티 모니터링 및 제한, 8) Querier 리소스 증설. Loki는 라벨로 스트림을 좁힌 후 본문 풀스캔하므로 라벨 설계가 핵심입니다.', ARRAY['Loki', 'LogQL', '라벨 카디널리티', 'Query Frontend', '쿼리 성능'], 'Loki의 비용 효율성은 라벨 기반 인덱싱에서 오지만, 잘못된 라벨 설계는 성능 저하를 유발합니다.', 'docs/05-monitoring-observability.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('monitoring', 'otel', 3, 30, 75, 'OpenTelemetry Collector를 프로덕션에 배포할 때 안정성과 성능을 위한 설정 모범 사례를 설명해주세요.', '1) memory_limiter 프로세서로 메모리 보호(limit_mib 설정), 2) batch 프로세서로 배치 처리(timeout: 1s, send_batch_size: 1000), 3) 헬스체크 엔드포인트 노출(extensions), 4) 재시도 설정(retry_on_failure), 5) 큐 설정(sending_queue)으로 버퍼링, 6) 불필요한 텔레메트리 filter 프로세서로 제거, 7) 리소스 limits 설정(CPU/Memory), 8) 고가용성을 위한 복제본 배포, 9) 계층형 배포(에이전트 -> 게이트웨이)로 확장성 확보.', ARRAY['OpenTelemetry', 'Collector', 'memory_limiter', 'batch', '고가용성'], 'Collector 장애는 모든 텔레메트리 유실로 이어지므로 안정성 설정이 매우 중요합니다.', 'docs/05-monitoring-observability.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('monitoring', 'slo-sli', 3, 30, 75, '새로운 마이크로서비스에 SLO를 도입하려고 합니다. SLI 선정부터 SLO 설정, 에러 버짓 운영까지의 프로세스를 설명해주세요.', '1) SLI 선정: 사용자 경험과 직결된 지표(가용성: 성공률, 지연: p99 응답시간), 2) 현재 성능 측정: 2-4주간 베이스라인 데이터 수집, 3) SLO 설정: 베이스라인보다 약간 낮게(현재 99.95%면 SLO 99.9%), 4) 에러 버짓 계산: 30일 기준 0.1% = 43분 다운타임 허용, 5) 알림 설정: 번 레이트 기반(1시간 5% + 6시간 10% 동시 초과), 6) 대시보드: 에러 버짓 잔여량, 번 레이트 시각화, 7) 정기 리뷰: 월간 SLO 달성률 검토 및 조정.', ARRAY['SLO', 'SLI', '에러 버짓', '번 레이트', '가용성'], 'SLO는 완벽함보다 측정 가능하고 개선 가능한 것이 중요합니다.', 'docs/05-monitoring-observability.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('monitoring', 'apm', 3, 30, 75, '프로덕션 환경에서 APM 에이전트로 인한 성능 오버헤드가 5% 이상 발생하고 있습니다. 오버헤드를 최소화하면서 관측성을 유지하는 방법을 설명해주세요.', '1) 트레이스 샘플링 비율 조정(1-10%), 2) 에러/지연 발생 시에만 100% 수집(적응형 샘플링), 3) 스팬 개수 제한(max_spans_per_trace), 4) 불필요한 트랜잭션 제외(건강체크, 정적 파일), 5) 스팬 속성/태그 최소화, 6) 비동기 전송 및 배치 처리, 7) 경량 바이너리 프로토콜 사용(OTLP/gRPC), 8) 프로파일링은 온디맨드로만, 9) 에이전트 버전 최신화(성능 개선 반영).', ARRAY['APM', '오버헤드', '샘플링', 'OpenTelemetry', '성능'], 'APM 오버헤드는 1-3% 이내로 유지하는 것이 권장됩니다.', 'docs/05-monitoring-observability.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('monitoring', 'metrics', 3, 30, 75, 'PromQL에서 histogram_quantile()로 계산한 p99 지연 시간이 실제 사용자 경험과 다르게 느껴집니다. 원인과 개선 방법을 설명해주세요.', '원인: 1) 버킷 경계가 실제 지연 분포와 맞지 않음(버킷이 너무 성김), 2) 버킷 간 선형 보간으로 인한 오차, 3) 레이블별 집계 시 합산 왜곡. 개선: 1) 서비스 특성에 맞는 버킷 설계(지연 분포 분석 후), 2) 핵심 지연 구간에 버킷 촘촘하게 배치, 3) 주기적으로 버킷 설계 재평가, 4) 정확한 분위수가 필요하면 Summary 고려(집계 불가 단점), 5) 클라이언트 측 RUM 지표와 비교 검증.', ARRAY['histogram_quantile', 'PromQL', '버킷', '분위수', '지연 시간'], '분위수 정확도는 쿼리보다 버킷 설계에 크게 좌우됩니다.', 'docs/05-monitoring-observability.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('monitoring', 'dashboards', 3, 30, 75, '조직 내 팀별로 수백 개의 대시보드가 난립하여 관리가 어렵습니다. 대시보드 거버넌스 전략을 수립해주세요.', '1) 대시보드 계층 구조 정의(Overview -> Service -> Detail), 2) 명명 규칙 표준화([팀]-[서비스]-[용도]), 3) 폴더 구조 표준화(팀/환경별), 4) 골든 시그널 기반 템플릿 제공, 5) 대시보드 리뷰 프로세스 도입(PR 리뷰처럼), 6) 미사용 대시보드 정기 정리(90일 미접근 시 아카이브), 7) 대시보드 프로비저닝(IaC, GitOps), 8) 플랫폼 팀이 코어 템플릿 관리, 서비스 팀이 확장, 9) 대시보드 카탈로그 문서화.', ARRAY['대시보드', '거버넌스', 'Grafana', '템플릿', '표준화'], '대시보드 난립은 유지보수 부담, 일관성 부족, 장애 대응 혼란을 야기합니다.', 'docs/05-monitoring-observability.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('monitoring', 'incident-management', 3, 30, 75, '온콜 엔지니어가 새벽에 알림을 받았을 때 효과적으로 대응할 수 있도록 런북(Runbook)을 설계하는 원칙을 설명해주세요.', '런북 필수 구성요소: 1) 알림 의미 설명(무엇이 문제인가), 2) 영향 범위(어떤 사용자/서비스가 영향), 3) 초기 진단 단계(확인해야 할 대시보드/로그/명령어), 4) 즉각적 완화 조치(롤백, 스케일아웃, 트래픽 전환), 5) 에스컬레이션 기준과 연락처, 6) 관련 문서 링크, 7) 최근 변경사항 확인 방법. 원칙: 1) 3분 내 이해 가능, 2) 복사-붙여넣기 가능한 명령어, 3) 정기적 검증과 업데이트, 4) 사후 분석으로 개선.', ARRAY['런북', 'Runbook', '온콜', '인시던트', '에스컬레이션'], '좋은 런북은 새벽 3시에 피곤한 상태에서도 따라할 수 있어야 합니다.', 'docs/05-monitoring-observability.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('monitoring', 'anomaly-detection', 3, 30, 75, '트래픽 패턴이 시간대/요일별로 크게 다른 서비스에서 정적 임계값 알림의 한계를 극복하는 이상 탐지 전략을 설명해주세요.', '1) 계절성 기반 동적 기준선: 시계열 분해(STL, Prophet)로 트렌드/계절성/잔차 분리, 잔차에서 이상 탐지, 2) 이동 평균 기반: 1시간 평균 대비 1.5배 초과 시 알림, 3) Z-score 기반: (현재값 - 평균) / 표준편차 > 3 시 이상, 4) 머신러닝: Isolation Forest, LSTM Autoencoder, 5) 주의사항: 학습 데이터에 장애 포함 방지, 거짓 양성 피드백 루프 구축, 설명 가능성 확보, 6) 정적 임계값과 병행(명확한 한계값은 정적 유지).', ARRAY['이상 탐지', '동적 임계값', '계절성', 'Z-score', 'Prophet'], '동적 임계값은 정상 패턴 학습이 전제되므로 학습 데이터 품질이 중요합니다.', 'docs/05-monitoring-observability.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('monitoring', 'thanos', 3, 30, 75, 'Prometheus에서 Thanos로 전환하여 장기 메트릭 저장과 글로벌 뷰를 구현할 때 아키텍처 설계와 주의사항을 설명해주세요.', '아키텍처: 1) Sidecar 모드로 기존 Prometheus에 Thanos Sidecar 추가, 2) 객체 스토리지(S3/GCS)에 블록 업로드, 3) Thanos Query로 여러 Prometheus + Store Gateway 통합 조회, 4) Compactor로 다운샘플링 및 블록 압축, 5) Store Gateway로 객체 스토리지 블록 조회. 주의사항: 1) external_labels로 클러스터 식별 필수, 2) 다운샘플링 해상도 결정(5m, 1h), 3) Query 앞단에 캐시 레이어, 4) Compactor는 단일 인스턴스로 운영, 5) 객체 스토리지 비용 모니터링.', ARRAY['Thanos', 'Prometheus', '장기 저장', '글로벌 뷰', '객체 스토리지'], 'Thanos는 Prometheus의 확장성 한계를 극복하면서 기존 인프라를 활용할 수 있습니다.', 'docs/05-monitoring-observability.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('monitoring', 'correlation', 3, 30, 75, '장애 발생 시 메트릭, 로그, 트레이스를 빠르게 연계하여 근본 원인을 찾는 관측성 워크플로우를 설계해주세요.', '워크플로우: 1) 메트릭 알림 수신 → SLO 대시보드에서 영향 범위 확인, 2) 문제 시간대의 에러 스팬 검색(Jaeger/Tempo), 3) 트레이스에서 지연/에러 발생 스팬 식별, 4) trace_id로 해당 시점 로그 검색, 5) 로그에서 상세 에러 메시지/스택트레이스 확인, 6) 관련 인프라 메트릭(CPU, 메모리, 네트워크) 확인. 구현 요건: 1) trace_id를 모든 로그에 포함, 2) Grafana에서 데이터소스 간 링크 설정, 3) 공통 시간 범위 동기화, 4) 서비스명/인스턴스 레이블 통일.', ARRAY['관측성', '상관관계', 'trace_id', '근본 원인', '워크플로우'], '메트릭 → 트레이스 → 로그 흐름이 끊기지 않아야 MTTR을 단축할 수 있습니다.', 'docs/05-monitoring-observability.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('monitoring', 'datadog', 3, 30, 75, 'Datadog 같은 SaaS 관측성 플랫폼 비용이 급증하고 있습니다. 비용 최적화 전략을 수립해주세요.', '1) 호스트 기반 과금 분석: 유휴 호스트 제거, 적절한 인스턴스 사이징, 2) 커스텀 메트릭 수 최적화: 불필요한 메트릭 제거, 카디널리티 낮추기, 3) 로그 인덱싱 최적화: 필수 로그만 인덱싱, 나머지는 아카이브, 4) APM 트레이스 샘플링: Ingestion Control로 수집량 조절, 5) 인덱스 보존 기간 최적화, 6) 태그 카디널리티 제한, 7) 하이브리드 구성 고려: 중요 데이터만 SaaS, 대량 로그는 자체 운영(Loki), 8) 비용 대시보드로 팀별/서비스별 사용량 가시화.', ARRAY['Datadog', '비용 최적화', 'SaaS', '샘플링', '하이브리드'], '관측성 SaaS 비용은 데이터 볼륨에 비례하므로 수집 단계 최적화가 핵심입니다.', 'docs/05-monitoring-observability.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('monitoring', 'use-method', 3, 30, 75, '서비스 응답 지연이 발생했을 때 USE Method를 활용한 체계적인 리소스 병목 분석 방법을 설명해주세요.', 'USE Method: 각 리소스에 대해 Utilization(사용률), Saturation(포화도), Errors(에러) 점검. CPU: 1) Utilization: CPU 사용률 확인, 2) Saturation: 런큐 길이(load average), 3) Errors: CPU throttling. Memory: 1) Utilization: 메모리 사용률, 2) Saturation: 스왑 사용, OOM 이벤트, 3) Errors: 할당 실패. Disk I/O: 1) Utilization: IO 사용률, 2) Saturation: 대기 큐 길이(avgqu-sz), 3) Errors: 디스크 에러. Network: 1) Utilization: 대역폭 사용률, 2) Saturation: 드롭/재전송, 3) Errors: 인터페이스 에러. 모든 리소스를 체계적으로 점검하면 누락 없이 병목을 찾을 수 있습니다.', ARRAY['USE Method', 'Utilization', 'Saturation', 'Errors', '병목 분석'], 'USE Method는 Brendan Gregg가 제안한 체계적 성능 분석 프레임워크입니다.', 'docs/05-monitoring-observability.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('monitoring', 'service-mesh', 3, 30, 75, 'Istio Service Mesh 환경에서 관측성 데이터(메트릭, 트레이스, 로그)를 효과적으로 수집하는 아키텍처를 설명해주세요.', '메트릭: 1) Istio 프록시(Envoy)가 자동으로 RED 메트릭 생성, 2) Prometheus가 istio-proxy /stats/prometheus 스크랩, 3) 서비스 레벨 메트릭 자동 수집. 트레이스: 1) Envoy가 B3/W3C 헤더 자동 전파, 2) 애플리케이션은 헤더만 전달하면 됨, 3) Jaeger/Tempo로 트레이스 수집, 4) 샘플링 설정(meshConfig.defaultConfig.tracing.sampling). 로그: 1) Envoy 액세스 로그 활성화, 2) 구조화 JSON 포맷으로 요청/응답 정보 포함, 3) Fluentbit으로 수집. 장점: 애플리케이션 수정 없이 투명한 관측성 확보.', ARRAY['Istio', 'Service Mesh', 'Envoy', '관측성', '투명한 계측'], 'Service Mesh는 사이드카 프록시로 애플리케이션 수정 없이 관측성을 제공합니다.', 'docs/05-monitoring-observability.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('monitoring', 'tail-sampling', 3, 30, 75, 'OpenTelemetry Collector에서 테일 기반 샘플링(Tail-based Sampling)을 구현할 때 아키텍처와 설정 방법을 설명해주세요.', '아키텍처: 1) 모든 스팬을 일단 수집(에이전트 레벨), 2) 중앙 Collector에서 전체 트레이스가 완료될 때까지 대기, 3) 완료된 트레이스에 대해 샘플링 결정, 4) 에러/지연 트레이스만 선별 저장. 설정: processors에 tail_sampling 추가, policies 정의(latency: {threshold_ms: 500}, status_code: {status_codes: [ERROR]}), decision_wait: 10s(트레이스 완료 대기), num_traces: 100000(메모리 내 유지할 트레이스 수). 주의사항: 1) 메모리 사용량 모니터링, 2) 분산 환경에서 같은 트레이스가 같은 Collector로 라우팅 필요(load balancing exporter).', ARRAY['Tail Sampling', 'OpenTelemetry', 'Collector', '샘플링', '트레이스'], '테일 샘플링은 중요한 트레이스(에러, 지연)를 누락 없이 수집할 수 있습니다.', 'docs/05-monitoring-observability.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('monitoring', 'multi-cluster', 3, 30, 75, '여러 Kubernetes 클러스터에서 통합된 관측성을 구현할 때 아키텍처 설계와 도전 과제를 설명해주세요.', '아키텍처: 1) 클러스터별 로컬 Prometheus + Thanos Sidecar, 2) 중앙 Thanos Query로 글로벌 뷰 제공, 3) external_labels로 클러스터/리전 식별(cluster: prod-us-east-1), 4) 중앙 Alertmanager로 통합 알림, 5) 로그/트레이스도 중앙 집중화(Loki, Tempo). 도전 과제: 1) 네트워크 지연 및 비용, 2) 클러스터 간 시간 동기화(NTP), 3) 레이블 명명 규칙 통일, 4) 글로벌 뷰 쿼리 성능, 5) 중앙 시스템 가용성, 6) 데이터 주권/규정 준수. 해결: 계층형 아키텍처(로컬 자율성 + 글로벌 집계), 쿼리 페더레이션, 적절한 데이터 보존 정책.', ARRAY['멀티클러스터', 'Thanos', 'Federation', '글로벌 뷰', 'Kubernetes'], '멀티클러스터 관측성은 로컬 자율성과 글로벌 가시성의 균형이 핵심입니다.', 'docs/05-monitoring-observability.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('monitoring', 'continuous-profiling', 3, 30, 75, '프로덕션에서 지속적 프로파일링(Continuous Profiling)을 도입할 때 고려사항과 활용 방법을 설명해주세요.', '도입 고려사항: 1) 오버헤드 1-3% 이내 유지, 2) 샘플링 기반 프로파일링(항상 실행), 3) 민감 데이터 마스킹, 4) 프로파일 데이터 보존 정책. 활용: 1) CPU 프로파일: 핫스팟 함수 식별, 2) 메모리 프로파일: 메모리 누수 탐지, 3) 락 프로파일: 동시성 병목 발견, 4) 배포 전후 프로파일 비교로 성능 회귀 탐지, 5) 트레이스와 연계하여 느린 스팬의 코드 레벨 원인 분석. 도구: Pyroscope, Parca, Datadog Continuous Profiler, AWS CodeGuru Profiler. 프로파일 데이터로 최적화 대상 우선순위를 데이터 기반으로 결정합니다.', ARRAY['Continuous Profiling', 'Pyroscope', '프로파일링', 'CPU', '메모리 누수'], '지속적 프로파일링은 프로덕션에서 코드 레벨 성능 문제를 발견하는 강력한 도구입니다.', 'docs/05-monitoring-observability.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('monitoring', 'sre-practices', 3, 30, 75, '포스트모템(Post-mortem) 프로세스를 통해 장애로부터 학습하고 재발을 방지하는 체계를 구축하는 방법을 설명해주세요.', '포스트모템 프로세스: 1) 장애 후 24-48시간 내 작성 시작, 2) 비난 없는(Blameless) 문화 필수, 3) 타임라인 작성: 탐지 → 대응 → 완화 → 복구, 4) 근본 원인 분석(5 Whys 또는 Fishbone), 5) 영향 측정: 영향받은 사용자 수, 다운타임, 비즈니스 손실, 6) 교훈(Lessons Learned) 도출, 7) 액션 아이템: 담당자, 기한, 우선순위 명시, 8) 공유: 팀/조직 전체에 투명하게 공유. 재발 방지: 1) 액션 아이템 추적 시스템, 2) 월간 장애 리뷰 미팅, 3) 유사 패턴 알림 추가, 4) 카오스 엔지니어링으로 취약점 사전 발견.', ARRAY['포스트모템', 'Blameless', '근본 원인', '액션 아이템', 'SRE'], '비난 없는 포스트모템 문화가 없으면 사람들은 문제를 숨기게 됩니다.', 'docs/05-monitoring-observability.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('monitoring', 'synthetic-monitoring', 3, 30, 75, '합성 모니터링(Synthetic Monitoring)과 실사용자 모니터링(RUM)의 차이점과 각각의 활용 시나리오를 설명해주세요.', '합성 모니터링: 1) 정의: 스크립트로 사용자 행동을 시뮬레이션, 2) 장점: 일관된 조건, 24/7 실행, 배포 전 테스트, 외부 관점, 3) 활용: 가용성 체크, SLA 모니터링, 핵심 사용자 여정 테스트, 글로벌 리전별 성능 비교. RUM(Real User Monitoring): 1) 정의: 실제 사용자 브라우저에서 데이터 수집, 2) 장점: 실제 사용자 경험, 다양한 디바이스/네트워크 조건, 3) 활용: Core Web Vitals 측정, 성능 회귀 탐지, 사용자 세그먼트별 분석. 조합: 합성으로 기준선 확보, RUM으로 실제 경험 검증. 두 방식을 함께 사용해야 완전한 그림을 얻을 수 있습니다.', ARRAY['Synthetic Monitoring', 'RUM', '합성 모니터링', 'Core Web Vitals', '사용자 경험'], '합성 모니터링은 통제된 환경, RUM은 실제 환경에서의 사용자 경험을 측정합니다.', 'docs/05-monitoring-observability.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('monitoring', 'capacity-planning', 3, 30, 75, '메트릭 기반 용량 계획(Capacity Planning)을 수행하여 인프라 확장 시점을 예측하는 방법을 설명해주세요.', '용량 계획 프로세스: 1) 핵심 리소스 식별: CPU, 메모리, 디스크, 네트워크, DB 커넥션, 2) 현재 사용량 베이스라인 수집: 피크 시간대 평균/최대값, 3) 성장률 분석: 주간/월간 트렌드, 비즈니스 이벤트 영향, 4) 임계점 정의: 리소스 80% 도달 시 확장 필요. 예측 방법: 1) 선형 회귀: 단순한 성장 패턴, 2) 시계열 분해: 계절성 반영(Prophet), 3) 비즈니스 이벤트 캘린더 반영(프로모션, 출시). 자동화: 1) Prometheus로 메트릭 수집, 2) 대시보드에 예측 그래프 포함, 3) 임계점 도달 예상일 알림, 4) 클라우드 Auto Scaling 정책과 연계. 주의: 갑작스러운 트래픽 급증에 대비한 여유 용량 확보.', ARRAY['용량 계획', 'Capacity Planning', '트렌드 분석', '예측', 'Auto Scaling'], '용량 계획은 비용 효율성과 서비스 안정성의 균형을 찾는 것입니다.', 'docs/05-monitoring-observability.md');

-- =====================================================
-- SECURITY (보안) - 25문제
-- =====================================================

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('security', 'authentication', 3, 30, 75, 'OAuth 2.0 Authorization Code 플로우에서 발생할 수 있는 주요 보안 위협과 방어 방법을 설명해주세요.', '위협 및 방어: 1) Authorization Code 가로채기 → PKCE 적용(code_verifier/code_challenge), 2) 리다이렉트 URI 변조 → 정확한 URI 화이트리스트(와일드카드 금지), 3) CSRF → state 파라미터로 요청 출처 검증, 4) 토큰 유출 → Access Token 짧은 만료(15분), HTTPS 필수, 5) Refresh Token 탈취 → Refresh Token Rotation 적용, secure/httpOnly 쿠키, 6) 클라이언트 위장 → 클라이언트 인증(client_secret, mTLS), 7) 토큰 재사용 → Audience(aud) 클레임 검증. OAuth 2.1에서는 PKCE가 모든 클라이언트에 필수입니다.', ARRAY['OAuth', 'Authorization Code', 'PKCE', 'state', '토큰 보안'], 'OAuth 2.0의 보안은 PKCE, state, 정확한 리다이렉트 URI 검증이 핵심입니다.', 'docs/06-security.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('security', 'authorization', 3, 30, 75, '마이크로서비스 환경에서 서비스 간 인가(Authorization)를 구현하는 패턴과 각각의 장단점을 설명해주세요.', '패턴: 1) 토큰 전파: 사용자 JWT를 서비스 체인에 전달, 장점-사용자 컨텍스트 유지, 단점-토큰 만료 관리, 2) 서비스 어카운트: 서비스별 자격 증명, 장점-서비스 독립성, 단점-사용자 정보 손실, 3) 사이드카 인가: Service Mesh에서 정책 적용, 장점-일관된 정책, 단점-복잡성, 4) 중앙 인가 서비스(OPA, Cedar): 통합 정책 관리, 장점-정책 일원화, 단점-지연/가용성 의존. 권장: 토큰 전파 + 사이드카 정책으로 사용자 컨텍스트 유지하면서 일관된 정책 적용. 최소 권한 원칙과 서비스 간 mTLS 필수.', ARRAY['서비스 간 인가', 'JWT', 'OPA', 'Service Mesh', '토큰 전파'], '마이크로서비스 인가는 사용자 컨텍스트 유지와 서비스 경계 보호의 균형이 필요합니다.', 'docs/06-security.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('security', 'encryption', 3, 30, 75, '데이터베이스에 저장된 민감 데이터(PII)를 암호화할 때 애플리케이션 레벨 암호화와 TDE(Transparent Data Encryption)의 차이점과 선택 기준을 설명해주세요.', '애플리케이션 레벨 암호화: 1) 장점: 데이터 소유자(앱)가 키 통제, DB 관리자도 평문 접근 불가, 세밀한 필드별 암호화, 2) 단점: 암호화된 필드는 검색/인덱싱 불가, 앱 복잡성 증가, 키 관리 부담. TDE: 1) 장점: 투명함(앱 수정 불필요), 검색/인덱싱 가능, 관리 용이, 2) 단점: DB 관리자는 평문 접근 가능, 런타임에는 복호화됨. 선택 기준: 1) 규정 준수 요건(관리자 접근 제한 필요 시 앱 레벨), 2) 검색 필요성, 3) 성능 요구사항, 4) 팀 역량. 둘을 조합하는 것도 가능(TDE + 특정 필드 앱 레벨).', ARRAY['암호화', 'TDE', '애플리케이션 암호화', 'PII', '키 관리'], '암호화 방식 선택은 위협 모델과 운영 요구사항에 따라 결정됩니다.', 'docs/06-security.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('security', 'waf', 3, 30, 75, 'WAF(Web Application Firewall) 규칙을 튜닝할 때 거짓 양성(False Positive)을 줄이면서 보안 수준을 유지하는 전략을 설명해주세요.', '튜닝 전략: 1) 학습 모드(Detect Only)로 시작하여 정상 트래픽 패턴 파악, 2) 거짓 양성 로그 분석 및 패턴 식별, 3) 특정 경로/파라미터에 대한 규칙 예외 추가(화이트리스트), 4) 민감도(Paranoia Level) 단계적 조정, 5) 커스텀 규칙으로 애플리케이션 특성 반영, 6) 정기적인 규칙 세트 업데이트(OWASP CRS), 7) 차단 전 알림으로 영향 사전 확인. 모니터링: 1) 차단/탐지 비율 추적, 2) 거짓 양성 티켓 추적, 3) 규칙별 트리거 빈도 분석. 균형: 너무 느슨하면 공격 통과, 너무 엄격하면 서비스 장애.', ARRAY['WAF', '거짓 양성', '튜닝', 'OWASP CRS', '화이트리스트'], 'WAF 효과는 지속적인 튜닝과 모니터링에 달려있습니다.', 'docs/06-security.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('security', 'ddos', 3, 30, 75, '대규모 DDoS 공격에 대응하기 위한 다계층 방어 아키텍처를 설계해주세요.', '다계층 방어: 1) 네트워크 에지(L3/L4): CDN/Anycast로 트래픽 분산(CloudFlare, AWS Shield), 업스트림 제공자의 스크러빙 센터, 2) 전송 계층: SYN 쿠키로 SYN flood 방어, 연결 제한, 3) 애플리케이션 계층(L7): Rate Limiting(IP, 사용자별), 봇 탐지/CAPTCHA, WAF로 악성 패턴 차단, 4) 인프라: Auto Scaling으로 용량 확장, 지리적 분산, 5) 모니터링: 실시간 트래픽 이상 탐지, 알림. 대응 계획: 1) 런북 준비, 2) 공급자 연락처 확보, 3) 정기 모의 훈련. 각 계층이 독립적으로 방어하여 단일 실패 지점을 제거합니다.', ARRAY['DDoS', '다계층 방어', 'CDN', 'Rate Limiting', 'Auto Scaling'], 'DDoS 방어는 단일 솔루션이 아닌 다계층 접근이 필수입니다.', 'docs/06-security.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('security', 'xss', 3, 30, 75, 'Content Security Policy(CSP)를 활용하여 XSS 공격을 효과적으로 방어하는 전략과 단계적 도입 방법을 설명해주세요.', 'CSP 전략: 1) 인라인 스크립트/스타일 제거 → nonce 또는 hash 사용, 2) 외부 스크립트 출처 제한(script-src ''self'' trusted-cdn.com), 3) unsafe-inline, unsafe-eval 금지, 4) report-uri로 위반 보고 수집. 단계적 도입: 1) Content-Security-Policy-Report-Only로 시작, 2) 위반 보고 분석 및 코드 수정, 3) 점진적으로 정책 강화, 4) 최종적으로 enforce 모드 전환. 추가 방어: default-src ''none''으로 시작해서 필요한 것만 허용, frame-ancestors로 Clickjacking 방어, upgrade-insecure-requests. CSP는 XSS의 마지막 방어선으로 출력 인코딩과 함께 사용해야 합니다.', ARRAY['CSP', 'XSS', 'nonce', 'Content Security Policy', '인라인 스크립트'], 'CSP는 XSS의 심층 방어 계층으로, 다른 방어가 실패해도 공격 영향을 제한합니다.', 'docs/06-security.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('security', 'sql-injection', 3, 30, 75, 'ORM을 사용하더라도 SQL Injection이 발생할 수 있는 시나리오와 방어 방법을 설명해주세요.', '취약 시나리오: 1) Raw SQL 쿼리 직접 작성(raw(), execute()), 2) 동적 테이블/컬럼명 사용(f"SELECT * FROM {table}"), 3) 동적 ORDER BY/GROUP BY 구성, 4) 저장 프로시저 파라미터 미처리, 5) 검색 조건 동적 생성. 방어: 1) Raw SQL 최소화, 불가피 시 파라미터 바인딩, 2) 테이블/컬럼명은 화이트리스트 검증, 3) ORDER BY는 허용된 컬럼명 매핑, 4) ORM의 안전한 쿼리 빌더 사용, 5) 코드 리뷰에서 Raw SQL 사용 검토, 6) 정적 분석 도구(Semgrep, CodeQL)로 패턴 탐지, 7) DB 계정 최소 권한 적용(SELECT만, DROP 불가).', ARRAY['SQL Injection', 'ORM', 'Raw SQL', '파라미터 바인딩', '화이트리스트'], 'ORM이 자동으로 모든 SQL Injection을 막아주지는 않습니다.', 'docs/06-security.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('security', 'csrf', 3, 30, 75, 'SPA(Single Page Application)에서 CSRF 방어 전략과 토큰 기반 인증 시 CSRF 위험성을 설명해주세요.', 'SPA CSRF 방어: 1) 쿠키가 아닌 Authorization 헤더로 토큰 전송 → CSRF 위험 감소, 2) SameSite=Strict/Lax 쿠키 설정, 3) CORS 정책 엄격 설정(allowed origins), 4) 커스텀 헤더(X-Requested-With) 검증. 토큰 기반 인증 시: 1) LocalStorage 저장 → CSRF 면역이나 XSS에 취약, 2) HttpOnly 쿠키 저장 → CSRF 위험 있으나 XSS에 안전, 3) 권장: 짧은 Access Token은 메모리, Refresh Token은 HttpOnly/SameSite 쿠키, 4) API 요청 시 Origin/Referer 헤더 검증. 트레이드오프: XSS vs CSRF 방어의 균형을 고려해야 합니다.', ARRAY['CSRF', 'SPA', 'SameSite', '토큰', 'CORS'], 'SPA에서는 토큰 저장 위치에 따라 XSS와 CSRF 위험의 트레이드오프가 있습니다.', 'docs/06-security.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('security', 'secrets-management', 3, 30, 75, 'Kubernetes 환경에서 HashiCorp Vault를 통한 시크릿 주입 아키텍처와 구현 방법을 설명해주세요.', '아키텍처 옵션: 1) Vault Agent Injector: 사이드카가 시크릿을 파일로 주입, 어노테이션 기반, 앱 수정 불필요, 2) CSI Secret Store Driver: 볼륨으로 마운트, 표준화된 방식, 3) External Secrets Operator: Vault 시크릿을 K8s Secret으로 동기화, 기존 워크플로우 유지, 4) 앱 내 직접 조회: Vault SDK 사용, 가장 유연하나 코드 수정 필요. 구현: 1) Kubernetes Auth Method로 Pod 인증(ServiceAccount JWT), 2) 정책으로 시크릿 접근 범위 제한, 3) TTL 설정으로 자동 갱신. 보안: 1) 네임스페이스로 테넌트 격리, 2) 감사 로그 활성화, 3) 동적 시크릿으로 DB 자격 증명 생성.', ARRAY['Vault', 'Kubernetes', '시크릿', 'Sidecar', 'External Secrets'], 'Vault 통합은 애플리케이션 복잡도와 운영 요구사항에 따라 방식을 선택합니다.', 'docs/06-security.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('security', 'ssl-tls', 3, 30, 75, 'TLS 인증서 만료로 인한 서비스 장애를 방지하기 위한 인증서 관리 자동화 전략을 설명해주세요.', '자동화 전략: 1) Let''s Encrypt + Certbot/cert-manager로 자동 발급/갱신, 2) 만료 30일 전 자동 갱신, 3) 갱신 실패 알림 설정, 4) 인증서 만료 모니터링(Prometheus blackbox exporter), 5) cert-manager로 K8s Ingress 인증서 자동 관리. 모니터링: 1) 인증서 만료일 메트릭 수집, 2) 14일/7일/1일 전 알림, 3) 인증서 인벤토리 관리. 추가 고려: 1) 인증서 체인 완전성 검증, 2) HSTS 설정으로 다운그레이드 공격 방지, 3) 인증서 투명성(CT) 로그 모니터링으로 오발급 탐지, 4) 와일드카드 인증서 사용 시 보안 영향 검토.', ARRAY['TLS', '인증서', 'cert-manager', 'Let''s Encrypt', '자동화'], '인증서 만료는 예방 가능한 장애 원인 중 가장 흔한 것 중 하나입니다.', 'docs/06-security.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('security', 'zero-trust', 3, 30, 75, 'Zero Trust 아키텍처에서 네트워크 세그멘테이션과 마이크로세그멘테이션의 차이점과 구현 방법을 설명해주세요.', '네트워크 세그멘테이션: 1) VLAN/서브넷 기반 큰 단위 분리, 2) 전통적 방화벽으로 세그먼트 간 트래픽 제어, 3) 장점: 단순, 검증됨, 단점: 세그먼트 내 lateral movement 가능. 마이크로세그멘테이션: 1) 워크로드/컨테이너 단위 세밀한 분리, 2) 구현: K8s Network Policy, Security Group per Pod, Service Mesh(Istio AuthorizationPolicy), 3) 장점: 최소 권한, lateral movement 제한, 단점: 복잡성. Zero Trust 적용: 1) 기본 거부(deny-all) 시작, 2) 필요한 통신만 명시적 허용, 3) 워크로드 ID 기반 정책(IP 의존 안 함), 4) 지속적 검증(세션 중에도 재인증), 5) 모든 내부 트래픽 암호화(mTLS).', ARRAY['Zero Trust', '마이크로세그멘테이션', 'Network Policy', 'Service Mesh', 'lateral movement'], 'Zero Trust는 네트워크 위치가 아닌 검증된 신원과 정책에 기반합니다.', 'docs/06-security.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('security', 'iam', 3, 30, 75, 'AWS IAM에서 최소 권한 원칙을 적용하기 위한 정책 설계와 지속적 권한 관리 전략을 설명해주세요.', '정책 설계: 1) 역할 기반 정책(서비스별 최소 권한), 2) 리소스 범위 제한(Resource: arn:aws:s3:::specific-bucket/*), 3) 조건 활용(Condition: IP, MFA, 시간), 4) 관리형 정책보다 커스텀 정책 선호, 5) 와일드카드(*) 최소화. 지속적 관리: 1) IAM Access Analyzer로 미사용 권한 식별, 2) CloudTrail로 실제 사용 API 추적, 3) 정기적 권한 리뷰(분기별), 4) 서비스 제어 정책(SCP)으로 조직 레벨 가드레일, 5) Permission Boundary로 위임 범위 제한. 자동화: 1) IaC로 IAM 정책 관리(Terraform), 2) 정책 변경 PR 리뷰 프로세스, 3) 정책 시뮬레이터로 테스트.', ARRAY['IAM', '최소 권한', 'AWS', '정책', 'Access Analyzer'], '과도한 권한은 침해 시 피해를 확대시키는 주요 원인입니다.', 'docs/06-security.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('security', 'penetration-testing', 3, 30, 75, '프로덕션 환경에서 안전하게 침투 테스트를 수행하기 위한 계획 수립과 주의사항을 설명해주세요.', '계획 수립: 1) 범위 정의: 테스트 대상 시스템, IP 범위, 제외 항목, 2) 시간 계획: 피크 시간 회피, 비상 연락처 확보, 3) 테스트 유형: 블랙박스/그레이박스/화이트박스, 4) 승인: 경영진, 법무, 클라우드 제공자 사전 승인, 5) 백업 확인: 롤백 계획. 주의사항: 1) DoS 테스트는 스테이징에서만, 2) 실제 데이터 유출 금지(테스트 데이터 사용), 3) 발견 취약점 즉시 보고(Critical은 실시간), 4) 테스트 흔적 로깅 및 정리, 5) 모니터링 팀 사전 공지(오탐 방지). 결과물: 1) 취약점 목록(심각도 분류), 2) 공격 경로 문서, 3) 재현 단계, 4) 권고 조치 및 우선순위.', ARRAY['침투 테스트', '펜테스트', '취약점', '범위 정의', '승인'], '침투 테스트는 실제 공격자 관점에서 보안을 검증하는 필수 활동입니다.', 'docs/06-security.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('security', 'compliance', 3, 30, 75, 'SOC 2 Type 2 인증을 위한 보안 통제 구현과 증적 수집 자동화 전략을 설명해주세요.', 'SOC 2 핵심 통제: 1) 접근 통제: SSO/MFA, 권한 리뷰, 퇴사자 접근 해제, 2) 변경 관리: PR 리뷰, 승인 워크플로우, 배포 로그, 3) 위험 평가: 정기 취약점 스캔, 침투 테스트, 4) 인시던트 대응: 대응 계획, 포스트모템, 5) 모니터링: 보안 로깅, 알림, 이상 탐지. 증적 자동화: 1) IaC로 설정 변경 추적(Git 히스토리 = 증적), 2) CI/CD 로그 자동 보관, 3) Vanta/Drata 같은 컴플라이언스 플랫폼으로 자동 수집, 4) AWS Config/CloudTrail로 설정 변경 기록, 5) 자동화된 스크린샷/리포트 생성. 지속적 컴플라이언스: 감사 때만이 아닌 상시 통제 모니터링.', ARRAY['SOC 2', '컴플라이언스', '통제', '증적', '자동화'], 'SOC 2는 보안 통제의 설계뿐 아니라 지속적인 운영 효과를 검증합니다.', 'docs/06-security.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('security', 'container', 3, 30, 75, 'Pod Security Standards(PSS)의 세 가지 레벨을 설명하고, 프로덕션 워크로드에 적합한 보안 정책을 설계해주세요.', 'PSS 레벨: 1) Privileged: 제한 없음, 시스템 워크로드용, 2) Baseline: 최소 제한(privileged 컨테이너, hostNetwork 차단), 일반 워크로드, 3) Restricted: 엄격(root 실행 금지, capability 최소화), 보안 민감 워크로드. 프로덕션 정책: 1) 기본 Restricted 적용, 필요시 Baseline 예외, 2) runAsNonRoot: true 강제, 3) readOnlyRootFilesystem: true, 4) allowPrivilegeEscalation: false, 5) capabilities drop ALL, 6) seccompProfile: RuntimeDefault. 구현: 1) Namespace에 PSS 라벨 적용, 2) Admission Controller로 강제(enforce), 3) Kyverno/OPA Gatekeeper로 추가 커스텀 정책, 4) 위반 시 배포 차단 및 알림.', ARRAY['Pod Security Standards', 'PSS', 'Kubernetes', 'seccomp', 'Restricted'], 'PSS는 Kubernetes 1.23+에서 PodSecurityPolicy를 대체하는 표준입니다.', 'docs/06-security.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('security', 'container', 3, 30, 75, 'CI/CD 파이프라인에 컨테이너 이미지 보안 스캔을 통합하고 취약점 관리 프로세스를 구축하는 방법을 설명해주세요.', '파이프라인 통합: 1) 빌드 단계에서 Trivy/Snyk로 이미지 스캔, 2) 심각도 기준 설정(CRITICAL/HIGH 발견 시 빌드 실패), 3) 결과를 PR 코멘트로 자동 게시, 4) SBOM 생성 및 저장. 취약점 관리: 1) 심각도별 SLA 정의(Critical: 24시간, High: 7일, Medium: 30일), 2) 예외 승인 프로세스(만료일 있는 허용 목록), 3) 취약점 대시보드로 현황 가시화, 4) 정기 리포트 생성. 지속적 관리: 1) 레지스트리에서 주기적 재스캔(새 CVE 반영), 2) 베이스 이미지 업데이트 자동화(Renovate/Dependabot), 3) 최소 베이스 이미지 사용(distroless, alpine), 4) 서명된 이미지만 배포 허용(Sigstore/Cosign).', ARRAY['이미지 스캔', 'Trivy', 'SBOM', '취약점 관리', 'CI/CD'], '이미지 취약점은 배포 전에 차단하는 것이 가장 효과적입니다.', 'docs/06-security.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('security', 'runtime-security', 3, 30, 75, 'Kubernetes 환경에서 Falco를 활용한 런타임 보안 모니터링 아키텍처와 탐지 규칙 설계를 설명해주세요.', '아키텍처: 1) DaemonSet으로 모든 노드에 Falco 배포, 2) eBPF 또는 커널 모듈로 시스템 콜 모니터링, 3) falcosidekick으로 알림 라우팅(Slack, PagerDuty, Webhook), 4) 이벤트를 Elasticsearch/Loki로 저장 및 분석. 탐지 규칙 예시: 1) 컨테이너 내 쉘 실행(shell_in_container), 2) 민감 파일 접근(/etc/shadow, /etc/passwd), 3) 네트워크 도구 실행(curl, wget), 4) 권한 상승 시도(setuid 바이너리), 5) 암호화폐 채굴 프로세스, 6) 예상치 못한 아웃바운드 연결. 운영: 1) 기본 규칙 세트로 시작, 2) 거짓 양성 튜닝(예외 추가), 3) 애플리케이션별 커스텀 규칙, 4) 심각도별 대응 정책.', ARRAY['Falco', '런타임 보안', 'eBPF', 'Kubernetes', '시스템 콜'], 'Falco는 런타임에 이상 행동을 탐지하여 침해를 조기에 발견합니다.', 'docs/06-security.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('security', 'ssrf', 3, 30, 75, '클라우드 환경에서 SSRF 공격으로 메타데이터 서비스를 통한 자격 증명 탈취를 방어하는 전략을 설명해주세요.', 'SSRF 방어: 1) 아웃바운드 요청 URL 화이트리스트 검증, 2) 내부 IP 범위 차단(169.254.x.x, 10.x.x.x, 192.168.x.x), 3) DNS rebinding 방어(요청 전 DNS 해석 후 IP 검증). 메타데이터 보호(AWS 예시): 1) IMDSv2 강제(토큰 기반, hop limit=1), 2) 불필요한 인스턴스에서 IMDS 비활성화, 3) IAM 역할 최소 권한. 네트워크 레벨: 1) 프라이빗 서브넷에서 NAT로만 아웃바운드, 2) Security Group 이그레스 규칙 제한, 3) VPC 엔드포인트로 AWS 서비스 직접 연결. 모니터링: 1) 메타데이터 서비스 접근 로깅, 2) 비정상 아웃바운드 요청 알림. SSRF는 클라우드 환경에서 특히 치명적입니다.', ARRAY['SSRF', '메타데이터', 'IMDSv2', '클라우드', 'IAM'], 'SSRF로 인한 클라우드 자격 증명 탈취는 가장 심각한 클라우드 보안 위협 중 하나입니다.', 'docs/06-security.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('security', 'incident-response', 3, 30, 75, '보안 침해 사고 발생 시 초기 24시간 내 수행해야 할 기술적 대응 절차를 설명해주세요.', '초기 대응(1-2시간): 1) 사고 확인 및 범위 초기 평가, 2) 사고 대응팀 소집, 3) 커뮤니케이션 채널 확립(전용 채널), 4) 임원진 최초 보고. 격리(2-6시간): 1) 감염 시스템 네트워크 격리(연결 해제, SG 차단), 2) 의심 계정 자격 증명 무효화, 3) 추가 확산 방지. 증거 수집(6-12시간): 1) 휘발성 데이터 우선 수집(메모리 덤프, 네트워크 연결), 2) 로그 보존(삭제 방지), 3) 타임라인 구성, 4) IoC(침해 지표) 식별. 분석(12-24시간): 1) 침투 경로 추적, 2) 영향받은 시스템/데이터 파악, 3) 지속 메커니즘 확인. 병행: 법률팀 연락, 규정 신고 준비(GDPR 72시간), 포렌식 외부 전문가 필요 여부 판단.', ARRAY['인시던트 대응', '격리', '증거 수집', 'IoC', '포렌식'], '초기 대응 속도와 증거 보존이 사고 해결과 법적 대응의 핵심입니다.', 'docs/06-security.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('security', 'supply-chain', 3, 30, 75, '소프트웨어 공급망 보안을 위한 SBOM(Software Bill of Materials) 생성과 활용 전략을 설명해주세요.', 'SBOM 생성: 1) 빌드 시점에 자동 생성(Syft, Trivy), 2) 포맷: SPDX 또는 CycloneDX, 3) 직접 의존성 + 전이 의존성 포함, 4) 컨테이너 이미지, 애플리케이션 모두 대상, 5) CI/CD 파이프라인에 통합. 활용: 1) 취약점 발생 시 영향 범위 신속 파악(Log4j 사태 대응), 2) 라이선스 컴플라이언스 확인, 3) 컴포넌트 EOL 추적, 4) 규정 준수 요건 충족(미국 행정명령). 관리: 1) SBOM 중앙 저장소 운영, 2) 새 CVE 발표 시 SBOM 대조 자동화, 3) 영향받는 서비스 자동 알림, 4) SBOM 버전 관리(배포별 연결). SBOM은 투명성과 신속한 대응의 기반입니다.', ARRAY['SBOM', '공급망 보안', 'SPDX', 'CycloneDX', '취약점'], 'SBOM은 공급망 공격 대응과 취약점 관리의 핵심 자산입니다.', 'docs/06-security.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('security', 'api-security', 3, 30, 75, 'REST API 보안을 위한 인증, 인가, Rate Limiting, 입력 검증 전략을 종합적으로 설명해주세요.', '인증: 1) OAuth 2.0 + PKCE(SPA/모바일), 2) API Key(서비스 간, 낮은 권한), 3) JWT 검증(알고리즘, 서명, 만료, iss/aud). 인가: 1) 리소스별 접근 제어(RBAC/ABAC), 2) 스코프 기반 권한 제한, 3) 객체 레벨 인가(IDOR 방지). Rate Limiting: 1) 사용자/IP/API Key별 제한, 2) 슬라이딩 윈도우 알고리즘, 3) 429 응답과 Retry-After 헤더. 입력 검증: 1) 스키마 검증(JSON Schema, OpenAPI), 2) 타입/길이/범위 검증, 3) 출력 인코딩. 추가: 1) HTTPS 필수, 2) 보안 헤더(CORS, CSP), 3) 요청/응답 로깅(민감정보 제외), 4) API 버전 관리로 보안 업데이트 적용.', ARRAY['API 보안', 'OAuth', 'Rate Limiting', '입력 검증', 'JWT'], 'API는 현대 애플리케이션의 핵심 공격 표면입니다.', 'docs/06-security.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('security', 'devsecops', 3, 30, 75, 'DevSecOps 파이프라인에 SAST, DAST, SCA를 통합하여 보안 테스트를 자동화하는 전략을 설명해주세요.', 'SAST (Static Application Security Testing): 1) 코드 커밋/PR 시 실행, 2) 도구: Semgrep, CodeQL, SonarQube, 3) 빠른 피드백, 개발 초기 취약점 발견. SCA (Software Composition Analysis): 1) 빌드 시 의존성 스캔, 2) 도구: Snyk, Dependabot, 3) 알려진 취약 라이브러리 탐지. DAST (Dynamic Application Security Testing): 1) 스테이징 환경에서 실행, 2) 도구: OWASP ZAP, 3) 런타임 취약점 발견. 통합 전략: 1) 심각도별 차단 기준(Critical: 즉시 차단, High: 48시간 내 수정), 2) 거짓 양성 관리(승인된 예외 목록), 3) 개발자 친화적 리포트(수정 방법 포함), 4) 보안 대시보드로 트렌드 추적, 5) 보안 챔피언이 팀별 지원.', ARRAY['DevSecOps', 'SAST', 'DAST', 'SCA', '보안 자동화'], 'Shift Left: 보안 테스트를 개발 초기에 통합하여 수정 비용을 줄입니다.', 'docs/06-security.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('security', 'logging-monitoring', 3, 30, 75, '보안 사고 탐지를 위한 SIEM 구축과 효과적인 탐지 규칙 설계 전략을 설명해주세요.', 'SIEM 구축: 1) 로그 소스 식별: 인증 시스템, 방화벽, WAF, 애플리케이션, 클라우드 서비스, 2) 로그 수집 파이프라인 구성(Fluentd → Kafka → SIEM), 3) 정규화 및 상관관계 분석, 4) 도구: Splunk, Elastic SIEM, Sentinel. 탐지 규칙 설계: 1) 인증 이상: 반복 실패 후 성공, 비정상 시간대 로그인, 2) 권한 이상: 권한 상승, 민감 리소스 접근, 3) 데이터 유출 징후: 대량 다운로드, 비정상 아웃바운드, 4) 공격 패턴: SQL Injection, 스캔 시도. 운영: 1) 규칙 우선순위(심각도 기반), 2) 거짓 양성 튜닝, 3) MITRE ATT&CK 프레임워크 매핑, 4) 정기적 규칙 리뷰, 5) 위협 인텔리전스 피드 연동.', ARRAY['SIEM', '탐지 규칙', 'MITRE ATT&CK', '로그 분석', '보안 모니터링'], 'SIEM의 효과는 수집하는 로그의 품질과 탐지 규칙의 정교함에 달려있습니다.', 'docs/06-security.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('security', 'data-protection', 3, 30, 75, '개인정보 보호 규정(GDPR, 개인정보보호법)을 준수하기 위한 기술적 조치를 설계해주세요.', '데이터 최소화: 1) 수집 시 필수 정보만, 2) 보유 기간 정책 및 자동 삭제, 3) 목적 외 사용 금지. 보안 조치: 1) 암호화: 저장 시 AES-256, 전송 시 TLS 1.3, 2) 가명처리/익명화, 3) 접근 통제: RBAC, 로깅. 권리 보장: 1) 열람권: 데이터 내보내기 기능, 2) 삭제권: soft delete가 아닌 완전 삭제, 백업 포함, 3) 이동권: 표준 포맷 내보내기. 침해 대응: 1) 72시간 내 신고 체계, 2) 영향 평가 절차, 3) 이해관계자 통지 프로세스. 기술 구현: 1) 개인정보 인벤토리(데이터 맵), 2) 동의 관리 플랫폼, 3) 감사 로그, 4) Privacy by Design.', ARRAY['GDPR', '개인정보보호', '암호화', '삭제권', '데이터 최소화'], '규정 준수는 법적 의무이자 사용자 신뢰의 기반입니다.', 'docs/06-security.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('security', 'threat-modeling', 3, 30, 75, '새로운 시스템을 설계할 때 위협 모델링(Threat Modeling)을 수행하는 방법과 STRIDE 프레임워크 활용법을 설명해주세요.', '위협 모델링 프로세스: 1) 시스템 이해: 아키텍처 다이어그램, 데이터 흐름, 신뢰 경계 식별, 2) 위협 식별: STRIDE 프레임워크 적용, 3) 위협 평가: 가능성 x 영향으로 우선순위, 4) 대응 전략: 완화, 전가, 수용, 회피, 5) 검증: 대응책 효과 확인. STRIDE: 1) Spoofing(위장): 인증 강화, 2) Tampering(변조): 무결성 검증, 서명, 3) Repudiation(부인): 감사 로그, 4) Information Disclosure(정보 노출): 암호화, 접근 제어, 5) Denial of Service(서비스 거부): Rate Limiting, 용량 계획, 6) Elevation of Privilege(권한 상승): 최소 권한, 샌드박싱. 도구: Microsoft Threat Modeling Tool, OWASP Threat Dragon.', ARRAY['위협 모델링', 'STRIDE', '신뢰 경계', '보안 설계', '위협 식별'], '위협 모델링은 설계 단계에서 보안 결함을 발견하는 가장 효과적인 방법입니다.', 'docs/06-security.md');
