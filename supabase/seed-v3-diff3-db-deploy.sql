-- CS Knowledge Quiz - Senior Level (Difficulty 3)
-- Database 25 Questions + Deployment 25 Questions = 50 Questions Total
-- level_min=30, level_max=75

-- ============================================
-- DATABASE CATEGORY (25 questions)
-- ============================================

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('database', 'query-optimization', 3, 30, 75, '대용량 주문 테이블에서 특정 사용자의 최근 10건 주문을 조회하는 쿼리가 있습니다. user_id와 created_at에 각각 단일 인덱스가 있지만 성능이 저조합니다. 어떤 인덱스 전략이 최적인지 설명하세요.', '(user_id, created_at DESC) 복합 인덱스를 생성해야 합니다. 이 인덱스는 특정 user_id로 필터링한 후 created_at 역순으로 정렬된 상태로 바로 접근할 수 있어, 정렬 작업(Sort) 없이 인덱스만으로 결과를 반환합니다. 추가로 SELECT 컬럼을 인덱스에 포함하면 커버링 인덱스로 테이블 접근을 완전히 제거할 수 있습니다.', ARRAY['복합 인덱스', 'covering index', '쿼리 최적화', 'order by'], '복합 인덱스의 컬럼 순서와 정렬 방향이 쿼리 패턴과 정확히 일치해야 최적의 성능을 얻을 수 있다.', 'docs/03-database.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('database', 'schema-design', 3, 30, 75, '이커머스 시스템에서 상품 가격이 자주 변경됩니다. 주문 테이블에 상품 가격을 저장할 때 products 테이블의 price를 참조할지, 주문 시점의 가격을 스냅샷으로 저장할지 결정해야 합니다. 각 접근법의 트레이드오프를 설명하세요.', '주문 시점의 가격을 스냅샷으로 order_items 테이블에 직접 저장해야 합니다. 참조 방식은 저장 공간을 절약하지만, 가격 변경 시 과거 주문의 총액이 변경되어 재무/회계 데이터 정합성이 깨집니다. 스냅샷 방식은 중복 저장이지만 히스토리 보존, 감사 추적, 법적 요구사항 준수가 가능합니다. 비정규화의 대표적인 정당한 사례입니다.', ARRAY['스냅샷', '비정규화', '데이터 정합성', '이력 관리'], '금액, 주소, 할인율 등 시간에 따라 변하는 비즈니스 데이터는 트랜잭션 시점의 값을 보존해야 한다.', 'docs/03-database.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('database', 'locking', 3, 30, 75, '재고 차감 로직에서 SELECT ... FOR UPDATE를 사용하지 않고 UPDATE products SET stock = stock - 1 WHERE id = ? AND stock > 0 만으로 처리했을 때 발생할 수 있는 문제와 해결 방안을 설명하세요.', '해당 쿼리 자체는 원자적이므로 음수 재고는 방지됩니다. 하지만 애플리케이션에서 재고 확인 후 다른 비즈니스 로직을 수행한 뒤 차감하는 패턴에서는 Lost Update 문제가 발생합니다. SELECT FOR UPDATE로 행 잠금을 먼저 획득하거나, 낙관적 잠금(version 컬럼)을 사용해 affected_rows가 0이면 재시도하는 방식으로 해결합니다. 충돌이 적으면 낙관적 잠금이, 많으면 비관적 잠금이 효율적입니다.', ARRAY['SELECT FOR UPDATE', '낙관적 잠금', 'Lost Update', '동시성 제어'], '동시성 제어 전략은 충돌 빈도와 비즈니스 로직의 복잡도에 따라 선택해야 한다.', 'docs/03-database.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('database', 'replication', 3, 30, 75, 'Primary-Replica 구조에서 쓰기 직후 읽기(Read-After-Write) 일관성 문제가 발생합니다. 사용자가 게시글을 작성한 직후 목록에서 자신의 글이 보이지 않는 현상을 해결하는 방법을 설명하세요.', '여러 전략을 조합할 수 있습니다. 1) 쓰기 직후 일정 시간 동안 해당 사용자의 읽기를 Primary로 라우팅 2) 클라이언트에 마지막 쓰기 타임스탬프를 전달하고 Replica에서 해당 시점 이후 데이터가 반영될 때까지 대기 3) 세션 기반 일관성(Session Consistency)으로 같은 세션 내 읽기는 자신의 쓰기를 보장 4) 동기 복제 사용(성능 저하 감수). 비즈니스 요구사항과 성능 간 트레이드오프를 고려해 선택합니다.', ARRAY['Read-After-Write', '복제 지연', 'Session Consistency', '라우팅'], '분산 시스템에서 강한 일관성과 가용성/성능은 트레이드오프 관계이다.', 'docs/03-database.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('database', 'partitioning', 3, 30, 75, '5년치 로그 데이터 50억 건이 저장된 테이블의 조회 성능이 저하되었습니다. 월별 Range 파티셔닝을 도입할 때 고려해야 할 사항과 마이그레이션 전략을 설명하세요.', '고려사항: 1) 파티션 키(created_at)가 모든 쿼리 WHERE 절에 포함되어야 파티션 프루닝 효과를 얻음 2) 유니크 제약조건에 파티션 키 포함 필요 3) 외래 키 제약 사용 어려움 4) 파티션 수가 많아지면 메타데이터 오버헤드 증가. 마이그레이션: 새 파티션 테이블 생성 후 pg_partman 같은 도구로 데이터를 점진적으로 이동하거나, 뷰와 INSTEAD OF 트리거로 신/구 테이블을 투명하게 전환합니다. 서비스 중단 없이 진행하려면 이중 쓰기 기간이 필요합니다.', ARRAY['Range 파티셔닝', '파티션 프루닝', 'pg_partman', '무중단 마이그레이션'], '파티셔닝은 쿼리 패턴과 일치해야 효과가 있으며, 기존 시스템에 도입 시 신중한 마이그레이션이 필요하다.', 'docs/03-database.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('database', 'connection-pool', 3, 30, 75, 'Kubernetes에서 Pod가 오토스케일링될 때 각 Pod마다 커넥션 풀을 가지면 데이터베이스 max_connections를 초과하는 문제가 발생합니다. 이를 해결하기 위한 아키텍처를 설명하세요.', 'PgBouncer나 ProxySQL 같은 중앙 집중식 커넥션 풀러를 DB 앞에 배치합니다. 각 Pod는 풀러에 연결하고, 풀러가 제한된 수의 실제 DB 연결을 관리합니다. Transaction 모드를 사용하면 트랜잭션 단위로 연결을 공유하여 효율성이 극대화됩니다. 단, Prepared Statement, 세션 변수, LISTEN/NOTIFY 등 세션 기능은 Session 모드에서만 지원됩니다. 풀러 자체의 고가용성도 구성해야 합니다.', ARRAY['PgBouncer', '중앙 커넥션 풀', 'Transaction 모드', '오토스케일링'], '컨테이너 환경에서는 애플리케이션 레벨 풀만으로는 부족하며 외부 풀러가 필수적이다.', 'docs/03-database.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('database', 'indexing', 3, 30, 75, 'PostgreSQL에서 주문 상태가 ''pending''인 행만 자주 조회됩니다. 전체 주문의 95%는 ''completed'' 상태입니다. 이 쿼리를 최적화하기 위한 인덱스 전략을 설명하세요.', '부분 인덱스(Partial Index)를 사용합니다. CREATE INDEX idx_pending_orders ON orders (created_at) WHERE status = ''pending'' 처럼 조건을 지정하면 pending 상태인 5%의 행만 인덱싱됩니다. 전체 인덱스 대비 크기가 1/20로 줄어들고, 메모리 효율과 쓰기 성능이 향상됩니다. 쿼리 WHERE 절에 status = ''pending''이 포함되어야 인덱스가 사용됩니다.', ARRAY['부분 인덱스', 'Partial Index', '인덱스 최적화', '선택적 인덱싱'], '데이터 분포가 편향된 경우 부분 인덱스로 인덱스 크기와 유지 비용을 크게 줄일 수 있다.', 'docs/03-database.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('database', 'transaction', 3, 30, 75, 'PostgreSQL에서 MVCC로 인해 UPDATE/DELETE된 행의 이전 버전이 계속 남아 테이블이 비대해지는 현상이 발생합니다. 이 문제의 원인과 해결 방법을 설명하세요.', '이를 테이블 블로트(Bloat)라고 합니다. MVCC에서 변경된 행은 즉시 삭제되지 않고 트랜잭션 가시성을 위해 보존됩니다. VACUUM이 오래된 버전을 정리하지만, 장기 실행 트랜잭션이 있으면 해당 시점 이후의 dead tuple을 제거할 수 없습니다. 해결: 1) 장기 트랜잭션 방지 및 모니터링 2) autovacuum 튜닝(더 공격적으로 설정) 3) 심각한 경우 pg_repack이나 VACUUM FULL로 테이블 재구성 4) hot_standby_feedback 설정 시 Replica의 긴 쿼리도 고려해야 합니다.', ARRAY['MVCC', '테이블 블로트', 'VACUUM', 'autovacuum'], 'MVCC의 트레이드오프로 발생하는 블로트는 적극적인 VACUUM 정책으로 관리해야 한다.', 'docs/03-database.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('database', 'sharding', 3, 30, 75, '사용자 기반 샤딩을 적용한 시스템에서 관리자가 모든 사용자의 주문을 날짜순으로 조회해야 합니다. 크로스 샤드 쿼리의 성능 문제를 해결하는 방법을 설명하세요.', '크로스 샤드 쿼리는 근본적으로 비효율적이므로 다음 전략을 고려합니다. 1) 관리자용 읽기 전용 집계 데이터베이스를 별도로 구축하고 CDC로 동기화 2) Elasticsearch 같은 검색 엔진에 인덱싱하여 전체 검색 제공 3) 분석 쿼리는 Data Warehouse(BigQuery, Redshift)로 분리 4) Vitess나 Citus 같은 분산 쿼리 미들웨어 사용. OLTP와 OLAP 워크로드를 분리하는 것이 핵심입니다.', ARRAY['크로스 샤드 쿼리', 'CDC', 'CQRS', '읽기 모델 분리'], '샤딩 시스템에서 분석/관리 쿼리는 별도의 읽기 최적화 저장소로 분리하는 것이 일반적이다.', 'docs/03-database.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('database', 'backup', 3, 30, 75, '프로덕션 데이터베이스에서 실수로 중요 테이블을 DROP했습니다. 마지막 전체 백업은 6시간 전이고 WAL 아카이빙이 설정되어 있습니다. PITR(Point-In-Time Recovery)을 수행하는 절차를 설명하세요.', '1) 복구용 별도 서버에 마지막 기본 백업(base backup)을 복원합니다 2) recovery.signal 파일을 생성하고 postgresql.conf에 restore_command(WAL 아카이브 경로)와 recovery_target_time(DROP 직전 시점)을 설정합니다 3) 서버를 시작하면 WAL을 순차 적용하여 지정 시점까지 복구합니다 4) 복구된 데이터를 검증 후 프로덕션 DB로 필요한 테이블/데이터를 옮깁니다. 전체 교체가 아닌 부분 복구 시 pg_dump로 해당 테이블만 추출합니다.', ARRAY['PITR', 'WAL 아카이빙', 'recovery_target_time', '재해 복구'], 'WAL 아카이빙과 정기 백업이 구성되어 있어야 초 단위 정밀도의 복구가 가능하다.', 'docs/03-database.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('database', 'query-optimization', 3, 30, 75, 'EXPLAIN ANALYZE 결과에서 실제 행 수(actual rows)가 예상 행 수(estimated rows)와 1000배 이상 차이납니다. 이 문제의 원인과 해결 방법을 설명하세요.', '통계 정보가 실제 데이터 분포를 반영하지 못하는 것이 원인입니다. 해결: 1) ANALYZE 명령으로 테이블 통계를 즉시 갱신 2) default_statistics_target을 높여 더 정밀한 히스토그램 생성 3) 함수나 표현식으로 변환된 컬럼은 통계가 없으므로 표현식 인덱스나 생성 컬럼 고려 4) 상관관계 있는 컬럼들은 CREATE STATISTICS로 다중 컬럼 통계 생성 5) 정기적 ANALYZE 스케줄링. 잘못된 통계는 옵티마이저가 비효율적인 실행계획을 선택하게 만듭니다.', ARRAY['EXPLAIN ANALYZE', '통계 정보', 'ANALYZE', 'default_statistics_target'], '옵티마이저의 판단은 통계 품질에 의존하므로 정확한 통계 유지가 쿼리 성능의 기반이다.', 'docs/03-database.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('database', 'migration', 3, 30, 75, '운영 중인 서비스에서 users 테이블의 email 컬럼에 UNIQUE 제약조건을 추가해야 합니다. 수억 건의 데이터가 있을 때 서비스 중단 없이 안전하게 적용하는 방법을 설명하세요.', 'PostgreSQL에서는 CREATE UNIQUE INDEX CONCURRENTLY를 사용합니다. 이 방식은 테이블에 SHARE UPDATE EXCLUSIVE 잠금만 걸어 다른 트랜잭션의 읽기/쓰기를 차단하지 않습니다. 완료 후 ALTER TABLE ... ADD CONSTRAINT ... USING INDEX로 제약조건을 연결합니다. 주의사항: 1) CONCURRENTLY는 트랜잭션 안에서 실행 불가 2) 중복 데이터가 있으면 실패하므로 사전 검증 필수 3) 긴 트랜잭션이 있으면 완료까지 대기 4) 실패 시 INVALID 상태 인덱스 정리 필요.', ARRAY['CONCURRENTLY', 'UNIQUE 제약조건', '무중단 DDL', '온라인 스키마 변경'], '대용량 테이블의 스키마 변경은 잠금을 최소화하는 CONCURRENTLY 옵션을 활용해야 한다.', 'docs/03-database.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('database', 'nosql', 3, 30, 75, 'Redis를 세션 저장소로 사용 중인데 메모리가 부족해지면서 예상치 못한 키가 삭제됩니다. maxmemory 정책과 적절한 설정 방법을 설명하세요.', 'maxmemory-policy 설정으로 메모리 초과 시 동작을 제어합니다. 세션 저장소에는 volatile-lru(TTL 설정된 키 중 LRU) 또는 allkeys-lru(전체 키 중 LRU)가 적합합니다. 세션에 TTL을 반드시 설정하고 volatile-lru를 사용하면 일반 캐시 키는 보존됩니다. 주의: noeviction 정책은 메모리 초과 시 쓰기 거부되어 서비스 장애로 이어집니다. Redis Cluster로 수평 확장하거나, 콜드 세션을 DB로 이동하는 티어링 전략도 고려할 수 있습니다.', ARRAY['maxmemory-policy', 'Redis eviction', 'LRU', '세션 관리'], 'Redis 메모리 정책은 데이터 특성에 맞게 설정하고, 예측 가능한 동작을 보장해야 한다.', 'docs/03-database.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('database', 'cache', 3, 30, 75, '인기 상품 페이지의 캐시 TTL이 만료될 때 수천 개의 요청이 동시에 DB를 조회하여 서버가 다운되었습니다. 이 Thundering Herd 문제를 방지하는 캐시 전략을 설명하세요.', '여러 전략을 조합합니다. 1) 뮤텍스/분산 락: 첫 요청만 DB 조회하고 나머지는 락 해제까지 대기하거나 stale 데이터 반환 2) 사전 갱신(Background Refresh): TTL 만료 전에 백그라운드에서 캐시 갱신 3) TTL 지터(Jitter): 캐시 만료 시간에 랜덤 값을 추가해 동시 만료 방지 4) Stale-While-Revalidate: 만료된 캐시를 즉시 반환하면서 비동기로 갱신. Redis에서는 SETNX로 락을 구현하거나 Redisson 같은 라이브러리를 사용합니다.', ARRAY['Thundering Herd', '캐시 스탬피드', '분산 락', 'Stale-While-Revalidate'], '인기 데이터의 캐시 만료는 시스템 부하의 급격한 스파이크를 유발할 수 있어 사전 대응이 필수다.', 'docs/03-database.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('database', 'schema-design', 3, 30, 75, '댓글 시스템에서 대댓글(답글)을 무한 깊이로 지원해야 합니다. parent_id만 사용하는 인접 리스트 모델의 한계와 더 나은 대안을 설명하세요.', '인접 리스트(parent_id)는 구현이 단순하지만 전체 트리 조회 시 재귀 쿼리(WITH RECURSIVE)가 필요해 깊이가 깊으면 성능이 저하됩니다. 대안: 1) 경로 열거(Materialized Path): ''/1/4/7'' 형식으로 경로 저장, LIKE ''1/4/%''로 하위 조회, 이동 시 경로 업데이트 필요 2) Closure Table: 별도 테이블에 모든 조상-후손 관계 저장, 조회가 빠르지만 저장 공간과 쓰기 비용 증가 3) Nested Set: 좌/우 값으로 범위 표현, 조회 최적화되나 삽입/이동 비용 높음. 조회/쓰기 패턴에 따라 선택합니다.', ARRAY['계층 구조', 'Closure Table', 'Materialized Path', '재귀 쿼리'], '계층 데이터 모델링은 조회와 수정 빈도에 따라 최적의 방식이 다르다.', 'docs/03-database.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('database', 'monitoring', 3, 30, 75, 'PostgreSQL에서 특정 쿼리가 갑자기 느려졌습니다. pg_stat_statements와 실행계획을 활용하여 원인을 진단하는 체계적인 절차를 설명하세요.', '진단 절차: 1) pg_stat_statements에서 해당 쿼리의 calls, total_time, mean_time 변화 추이 확인 2) EXPLAIN (ANALYZE, BUFFERS, FORMAT TEXT)로 실제 실행계획 분석 3) 예상 vs 실제 행 수 비교로 통계 정확도 검증 4) Seq Scan이 발생하면 인덱스 누락 또는 미사용 원인 파악 5) buffers 정보로 캐시 히트율 확인 6) pg_stat_user_tables에서 테이블의 dead tuple 비율과 마지막 VACUUM 시점 확인 7) 락 대기가 있다면 pg_locks와 pg_stat_activity 조인으로 블로킹 쿼리 식별. 변경 이력(배포, 데이터 증가)과 상관관계를 파악합니다.', ARRAY['pg_stat_statements', 'EXPLAIN ANALYZE', '쿼리 진단', '성능 모니터링'], '체계적인 진단 프로세스와 모니터링 도구 활용이 성능 문제 해결의 핵심이다.', 'docs/03-database.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('database', 'transaction', 3, 30, 75, '마이크로서비스 환경에서 주문 서비스와 재고 서비스가 각각 독립된 데이터베이스를 가집니다. 두 서비스에 걸친 트랜잭션의 원자성을 보장하는 방법을 설명하세요.', '분산 트랜잭션을 위해 Saga 패턴을 사용합니다. 1) Choreography: 각 서비스가 이벤트를 발행하고 다음 서비스가 구독하여 처리. 실패 시 보상 이벤트 발행 2) Orchestration: 중앙 오케스트레이터가 각 서비스를 순차 호출하고 실패 시 보상 로직 실행. 2PC는 분산 시스템에서 가용성 저하와 성능 문제로 권장되지 않습니다. 보상 트랜잭션은 멱등성을 보장해야 하며, 아웃박스 패턴으로 이벤트 발행의 신뢰성을 확보합니다. 결과적 일관성(Eventual Consistency)을 수용하는 설계가 필요합니다.', ARRAY['Saga 패턴', '분산 트랜잭션', '보상 트랜잭션', 'Eventual Consistency'], '마이크로서비스에서는 강한 일관성 대신 보상 기반의 결과적 일관성 패턴을 사용한다.', 'docs/03-database.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('database', 'replication', 3, 30, 75, 'Primary 데이터베이스 장애 시 Replica를 자동으로 Primary로 승격하는 자동 페일오버 시스템을 구축할 때 고려해야 할 위험 요소와 해결 방안을 설명하세요.', '주요 위험: 1) 스플릿 브레인(Split Brain): 네트워크 파티션으로 두 노드가 모두 Primary가 되면 데이터 충돌 발생. 해결: 쿼럼 기반 합의(Raft, Paxos), Witness 노드, STONITH(Shoot The Other Node In The Head)로 이전 Primary 강제 종료 2) 데이터 손실: 비동기 복제 시 미전파 트랜잭션 유실. 해결: 동기 복제 사용 또는 유실 허용 범위 정의 3) 클라이언트 연결 전환: DNS TTL 고려, 커넥션 풀 재연결, VIP 또는 프록시 계층 사용. Patroni, repmgr 같은 HA 솔루션이 이러한 복잡성을 관리합니다.', ARRAY['자동 페일오버', '스플릿 브레인', 'Patroni', 'STONITH'], '자동 페일오버는 편리하지만 스플릿 브레인과 데이터 손실 위험을 신중히 관리해야 한다.', 'docs/03-database.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('database', 'indexing', 3, 30, 75, 'B-Tree 인덱스가 LIKE ''%keyword%'' 패턴 검색에 효과적이지 않은 이유와 대안을 설명하세요.', 'B-Tree 인덱스는 값의 접두사(prefix) 기준으로 정렬되므로 ''keyword%''는 범위 스캔이 가능하지만 ''%keyword''나 ''%keyword%''는 전체 스캔이 필요합니다. 대안: 1) PostgreSQL의 pg_trgm 확장과 GIN/GiST 인덱스: trigram 기반으로 부분 문자열 검색 지원 2) Full-Text Search: tsvector/tsquery로 자연어 검색 3) Elasticsearch 같은 전문 검색 엔진: 복잡한 검색 요구사항에 적합 4) 리버스 인덱스: ''%keyword'' 패턴만 필요하면 reverse(column)에 인덱스. 검색 요구사항의 복잡도에 따라 적절한 솔루션을 선택합니다.', ARRAY['B-Tree 한계', 'pg_trgm', 'GIN 인덱스', 'Full-Text Search'], 'B-Tree의 정렬 특성을 이해하면 언제 다른 인덱스 타입이 필요한지 판단할 수 있다.', 'docs/03-database.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('database', 'sharding', 3, 30, 75, 'user_id를 샤드 키로 사용하는 시스템에서 샤드 수를 4개에서 8개로 늘려야 합니다. Consistent Hashing을 사용한 리샤딩 과정과 주의점을 설명하세요.', 'Consistent Hashing에서는 새 샤드를 해시 링에 추가할 때 일부 키만 재배치됩니다. 리샤딩 절차: 1) 새 샤드 노드 준비 및 해시 링에 등록 2) 영향받는 키 범위의 데이터를 신규 샤드로 복사(이중 쓰기 시작) 3) 복사 완료 후 라우팅 테이블 업데이트로 읽기 전환 4) 이전 샤드에서 해당 데이터 정리. 주의점: 1) 복사 중 데이터 변경 처리(CDC 또는 타임스탬프 기반 동기화) 2) 원자적 전환이 어려우므로 일시적 불일치 허용 범위 정의 3) 롤백 계획 수립 4) 키가 균등 분포되지 않으면 가상 노드(Virtual Node) 사용.', ARRAY['Consistent Hashing', '리샤딩', '가상 노드', '데이터 마이그레이션'], 'Consistent Hashing은 샤드 추가/제거 시 재배치되는 데이터 양을 최소화한다.', 'docs/03-database.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('database', 'query-optimization', 3, 30, 75, '대량의 INSERT 작업을 수행할 때 개별 INSERT 대신 COPY 명령이나 배치 INSERT를 사용해야 하는 이유와 추가 최적화 방법을 설명하세요.', '개별 INSERT는 매번 파싱, 계획, 실행, 커밋 오버헤드가 발생합니다. COPY 명령은 바이너리 프로토콜로 대량 데이터를 스트리밍하여 10-100배 빠릅니다. 추가 최적화: 1) 임시로 인덱스 비활성화 후 작업 완료 시 재생성 2) 트리거/제약조건 일시 비활성화 3) WAL 부하 감소를 위해 UNLOGGED 테이블 사용(복구 불가 감수 시) 4) maintenance_work_mem 증가로 인덱스 빌드 속도 향상 5) 배치 크기 조절(너무 크면 메모리 부담, 너무 작으면 오버헤드). 파티션 테이블은 파티션별로 분리하여 로드하면 더 효율적입니다.', ARRAY['COPY 명령', '배치 INSERT', '대량 로딩', 'ETL 최적화'], '대량 데이터 로딩은 개별 쿼리 방식과 완전히 다른 최적화 전략이 필요하다.', 'docs/03-database.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('database', 'locking', 3, 30, 75, 'MySQL InnoDB에서 UPDATE 문 실행 시 인덱스가 없는 컬럼을 WHERE 조건으로 사용하면 어떤 문제가 발생하며, 그 이유를 설명하세요.', '인덱스가 없으면 테이블 풀 스캔이 발생하고, InnoDB는 스캔한 모든 행에 배타적 잠금(X Lock)을 걸어 테이블 전체가 사실상 잠깁니다. 이로 인해 다른 트랜잭션의 읽기/쓰기가 모두 차단되어 심각한 동시성 저하가 발생합니다. REPEATABLE READ 격리 수준에서는 갭 락도 함께 걸려 범위 전체가 잠깁니다. 해결: 1) WHERE 조건 컬럼에 인덱스 추가 2) 작은 배치로 분할하여 처리 3) 트랜잭션을 짧게 유지 4) READ COMMITTED 격리 수준 고려(갭 락 감소).', ARRAY['테이블 락', 'InnoDB 잠금', '인덱스 누락', '동시성 저하'], 'InnoDB의 행 수준 잠금은 인덱스를 통해서만 정확히 동작한다.', 'docs/03-database.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('database', 'nosql', 3, 30, 75, 'DynamoDB에서 핫 파티션(Hot Partition) 문제가 발생했습니다. 원인과 해결을 위한 테이블 설계 전략을 설명하세요.', '핫 파티션은 특정 파티션 키에 트래픽이 집중되어 처리량(Throughput)이 해당 파티션의 한도에 제한되는 현상입니다. 해결 전략: 1) Write Sharding: 파티션 키에 랜덤 접미사 추가(예: user_123#2)하여 쓰기 분산, 읽기 시 모든 샤드 병렬 조회 2) 복합 키 설계: 시계열 데이터는 날짜+시간을 조합하여 파티션 분산 3) GSI 활용: 핫한 액세스 패턴을 별도 인덱스로 분리 4) DAX 캐싱: 읽기 핫스팟은 캐시로 흡수. 파티션 키 설계가 DynamoDB 성능의 핵심입니다.', ARRAY['Hot Partition', 'DynamoDB', 'Write Sharding', '파티션 키 설계'], 'DynamoDB의 성능은 파티션 키 설계에 의해 결정되며 균등 분산이 핵심이다.', 'docs/03-database.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('database', 'migration', 3, 30, 75, '운영 중인 테이블에 NOT NULL 제약조건이 있는 새 컬럼을 추가해야 합니다. 기존 행에 기본값을 설정하면서 테이블 잠금을 최소화하는 방법을 설명하세요.', 'PostgreSQL 11+에서는 휘발성이 아닌 기본값(상수)으로 NOT NULL 컬럼 추가 시 테이블 재작성 없이 메타데이터만 변경됩니다. 기존 행은 읽기 시점에 기본값이 적용됩니다. 이전 버전이나 복잡한 경우: 1) NULL 허용 컬럼으로 먼저 추가 2) 배치로 기존 데이터 업데이트(작은 트랜잭션으로 분할) 3) NOT NULL 제약조건 추가(ADD CONSTRAINT ... NOT VALID 후 VALIDATE CONSTRAINT CONCURRENTLY). 이 과정에서 애플리케이션은 새 컬럼을 점진적으로 사용하도록 배포 순서를 조율해야 합니다.', ARRAY['스키마 마이그레이션', 'NOT NULL', '무중단 DDL', 'Expand and Contract'], '스키마 변경은 DB 버전별 동작 차이를 이해하고 점진적 전환 전략을 수립해야 한다.', 'docs/03-database.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('database', 'cache', 3, 30, 75, '캐시와 데이터베이스 간의 데이터 일관성을 유지하기 위한 캐시 무효화 전략을 비교하고, 각각의 적합한 사용 사례를 설명하세요.', '주요 전략: 1) Cache-Aside + 삭제: 쓰기 시 캐시를 삭제하고 다음 읽기 시 DB에서 로드. 구현 단순, 대부분의 경우 적합 2) Write-Through: 쓰기 시 캐시와 DB 동시 업데이트. 일관성 높지만 쓰기 지연 증가 3) Write-Behind(Back): 캐시에 쓰고 비동기로 DB 반영. 쓰기 성능 우수하나 데이터 손실 위험 4) 이벤트 기반 무효화: DB 변경 시 이벤트 발행하여 캐시 갱신/삭제. 분산 시스템에 적합 5) TTL만 의존: 허용 가능한 불일치 시간이 있는 경우. 완벽한 일관성이 필요하면 캐시를 쓰지 않거나 Write-Through를 사용합니다.', ARRAY['캐시 무효화', 'Write-Through', 'Write-Behind', '이벤트 기반'], '캐시 전략은 일관성 요구수준, 읽기/쓰기 비율, 허용 지연에 따라 선택해야 한다.', 'docs/03-database.md');

-- ============================================
-- DEPLOYMENT CATEGORY (25 questions)
-- ============================================

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('deployment', 'blue-green', 3, 30, 75, 'Blue-Green 배포에서 데이터베이스 스키마 변경이 포함된 경우 롤백이 복잡해집니다. 이 문제를 해결하기 위한 DB 마이그레이션 전략을 설명하세요.', 'Expand and Contract(또는 Parallel Change) 패턴을 사용합니다. 1) Expand: 새 컬럼/테이블을 추가하되 기존 구조 유지. 애플리케이션은 양쪽에 쓰기(Dual Write) 2) Migrate: 기존 데이터를 새 구조로 점진적 마이그레이션 3) Contract: 모든 애플리케이션이 새 구조만 사용하면 기존 컬럼/테이블 제거. 이 방식은 Blue와 Green이 동시에 같은 DB를 사용할 수 있게 하며, 언제든 롤백이 가능합니다. 스키마 변경은 배포와 분리하여 별도로 관리합니다.', ARRAY['Expand and Contract', 'Blue-Green', 'DB 마이그레이션', 'Dual Write'], '데이터베이스 변경과 애플리케이션 배포는 분리하여 각각 롤백 가능해야 한다.', 'docs/04-deployment-cicd.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('deployment', 'canary', 3, 30, 75, 'Canary 배포에서 새 버전의 성공 여부를 자동으로 판단하기 위한 메트릭 기반 분석 시스템을 설계하세요. 어떤 지표를 어떻게 비교해야 하나요?', '자동 분석 시스템 설계: 1) 핵심 지표 선정: 에러율(5xx 비율), 지연 시간(p50, p95, p99), 비즈니스 메트릭(전환율, 주문 성공률) 2) 비교 방법: Canary와 Baseline(기존 버전)의 동일 시간대 트래픽을 비교. 통계적 유의성 검정(Mann-Whitney U, T-test) 적용 3) 판단 기준: 각 지표별 허용 오차 범위 정의. 에러율 10% 증가 또는 p99 지연 20% 증가 시 실패 4) 단계별 승격: 1% → 5% → 25% → 100%로 점진적 확대, 각 단계에서 분석 수행 5) 자동 롤백: 실패 조건 충족 시 즉시 트래픽을 Baseline으로 전환. Argo Rollouts, Flagger가 이 기능을 제공합니다.', ARRAY['Canary 분석', 'Progressive Delivery', 'Argo Rollouts', '자동 롤백'], '수동 판단 대신 메트릭 기반 자동 분석으로 배포 안전성과 속도를 모두 확보한다.', 'docs/04-deployment-cicd.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('deployment', 'kubernetes', 3, 30, 75, 'Kubernetes에서 Deployment의 Rolling Update 중 새 Pod가 Ready 상태가 되기 전에 이전 Pod가 종료되어 다운타임이 발생합니다. 이를 방지하기 위한 설정을 설명하세요.', '여러 설정을 조합합니다. 1) Readiness Probe: 애플리케이션이 트래픽을 받을 준비가 되었는지 확인. DB 연결, 캐시 워밍 등 포함 2) minReadySeconds: Pod가 Ready 상태를 유지해야 하는 최소 시간. 안정성 확인 후 다음 단계 진행 3) maxSurge/maxUnavailable: maxUnavailable=0으로 설정하면 기존 Pod가 먼저 종료되지 않음 4) preStop hook: 종료 전 트래픽 드레이닝 시간 확보. sleep으로 지연 후 graceful shutdown 5) terminationGracePeriodSeconds: 충분한 종료 대기 시간 설정. Probe의 initialDelaySeconds와 periodSeconds도 애플리케이션 특성에 맞게 조정해야 합니다.', ARRAY['Rolling Update', 'Readiness Probe', 'minReadySeconds', 'Zero Downtime'], '무중단 배포는 Probe 설정, 업데이트 전략, 종료 처리의 조합으로 달성된다.', 'docs/04-deployment-cicd.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('deployment', 'gitops', 3, 30, 75, 'GitOps 환경에서 Secret을 Git에 저장해야 하는데 평문으로 커밋할 수 없습니다. 이 문제를 해결하기 위한 전략들을 비교 설명하세요.', '주요 전략: 1) Sealed Secrets: kubeseal로 암호화된 Secret을 Git에 저장. 클러스터의 컨트롤러만 복호화 가능. 단일 클러스터에 적합 2) External Secrets Operator: Vault, AWS Secrets Manager 등 외부 저장소의 시크릿을 참조. ExternalSecret CRD로 선언적 관리. 중앙 집중식 시크릿 관리에 적합 3) SOPS + Age/KMS: Git에 저장되는 YAML 파일의 특정 필드만 암호화. 클라우드 KMS 키로 관리 4) Vault Agent Injector: Pod에 사이드카로 주입하여 런타임에 시크릿 획득. 동적 시크릿과 자동 갱신 지원. 조직의 시크릿 관리 정책과 복잡도에 따라 선택합니다.', ARRAY['Sealed Secrets', 'External Secrets', 'SOPS', 'GitOps 시크릿'], 'GitOps의 선언적 특성을 유지하면서 시크릿 보안을 확보하는 전략이 필요하다.', 'docs/04-deployment-cicd.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('deployment', 'ci-cd', 3, 30, 75, '모노레포에서 수백 개의 마이크로서비스를 관리할 때, 변경된 서비스만 빌드/배포하는 CI/CD 파이프라인을 설계하세요.', '영향 분석 기반 파이프라인 설계: 1) 변경 탐지: git diff로 변경된 파일 목록 추출, 디렉토리 구조 기반으로 영향받는 서비스 식별 2) 의존성 그래프: 서비스 간 의존성 분석. 공유 라이브러리 변경 시 의존하는 모든 서비스 재빌드 3) 병렬 실행: 독립적인 서비스는 병렬로 빌드/테스트. GitHub Actions의 matrix strategy 또는 전용 빌드 시스템 사용 4) 캐싱 최적화: 의존성(node_modules, .m2)과 빌드 결과를 캐싱하여 증분 빌드 5) 도구 활용: Turborepo, Nx, Bazel 같은 모노레포 빌드 시스템이 위 기능을 내장. 작은 변경에도 전체 빌드가 실행되면 CI 비용과 시간이 폭증합니다.', ARRAY['모노레포', '영향 분석', 'Turborepo', '증분 빌드'], '모노레포 CI/CD는 영향 분석과 캐싱을 통해 효율성을 확보해야 한다.', 'docs/04-deployment-cicd.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('deployment', 'docker', 3, 30, 75, 'Docker 이미지 빌드 시간이 15분 이상 걸립니다. 레이어 캐싱과 멀티스테이지 빌드를 활용한 최적화 전략을 설명하세요.', '최적화 전략: 1) 레이어 순서 최적화: 변경 빈도가 낮은 명령어를 먼저 배치. 의존성 파일(package.json)을 먼저 COPY하고 npm install 후 소스 코드 COPY 2) 멀티스테이지 빌드: 빌드 도구는 builder 스테이지에만, 최종 이미지에는 실행 파일만 포함. 이미지 크기와 보안 개선 3) BuildKit 캐시 마운트: RUN --mount=type=cache로 패키지 캐시(apt, npm, pip)를 빌드 간 유지 4) 병렬 빌드: BuildKit의 기본 병렬 실행 활용, 독립적인 스테이지는 동시 처리 5) .dockerignore: 불필요한 파일(node_modules, .git, 테스트)을 빌드 컨텍스트에서 제외하여 전송 시간 단축 6) 베이스 이미지 최적화: 가능하면 alpine이나 distroless 사용.', ARRAY['레이어 캐싱', '멀티스테이지 빌드', 'BuildKit', '빌드 최적화'], 'Docker 빌드 최적화는 캐시 활용 극대화와 최종 이미지 최소화에 집중해야 한다.', 'docs/04-deployment-cicd.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('deployment', 'terraform', 3, 30, 75, 'Terraform으로 관리하는 인프라에서 State와 실제 리소스가 불일치(Drift)하는 상황이 발생했습니다. 원인과 해결 방법을 설명하세요.', 'Drift 원인: 1) 콘솔이나 CLI로 직접 수정 2) 다른 도구/프로세스가 리소스 변경 3) State 파일 손상 또는 불일치. 해결 방법: 1) terraform refresh(또는 plan -refresh-only): 실제 상태를 State에 반영 2) terraform import: State에 없는 기존 리소스 가져오기 3) 코드 수정: 실제 상태와 일치하도록 Terraform 코드 업데이트 4) State 수정: terraform state mv, rm으로 State 조작(신중히). 예방: 1) 수동 변경 금지 정책 수립 2) CI/CD에서만 apply 실행 3) 정기적 drift 탐지(atlantis, spacelift의 drift detection) 4) RBAC로 프로덕션 콘솔 접근 제한.', ARRAY['Terraform Drift', 'State 관리', 'terraform import', 'IaC 거버넌스'], 'Drift 방지를 위해 인프라 변경은 반드시 코드를 통해서만 이루어져야 한다.', 'docs/04-deployment-cicd.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('deployment', 'rollback', 3, 30, 75, '배포 후 심각한 버그가 발견되어 즉시 롤백해야 합니다. Kubernetes 환경에서 빠르고 안전한 롤백을 수행하는 방법과 롤백 실패에 대비한 전략을 설명하세요.', '롤백 방법: 1) kubectl rollout undo deployment/<name>: 이전 ReplicaSet으로 즉시 전환 2) GitOps: git revert로 이전 커밋 상태 복원 후 동기화 3) Helm: helm rollback <release> <revision> 4) Argo Rollouts: 분석 실패 시 자동 롤백 또는 수동 abort. 실패 대비: 1) revisionHistoryLimit 충분히 설정(기본 10)하여 이전 버전 보존 2) 이미지 태그를 불변으로 관리(latest 금지) 3) 롤백 대상 버전의 이미지가 레지스트리에 존재하는지 확인 4) DB 마이그레이션이 포함된 경우 롤백 스크립트 사전 준비 5) 롤백 런북 작성 및 정기 훈련. 롤백도 배포의 일부로 자동화되어야 합니다.', ARRAY['롤백', 'kubectl rollout undo', 'revisionHistoryLimit', '장애 복구'], '롤백은 장애 대응의 핵심이므로 언제든 빠르게 수행할 수 있어야 한다.', 'docs/04-deployment-cicd.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('deployment', 'helm', 3, 30, 75, 'Helm 차트를 개발/스테이징/프로덕션 환경에서 재사용하면서 환경별 설정을 관리하는 전략을 설명하세요.', '환경별 설정 관리 전략: 1) Values 파일 분리: values-dev.yaml, values-staging.yaml, values-prod.yaml로 환경별 설정 정의. helm install -f values-prod.yaml 2) 공통 설정 상속: 기본 values.yaml에 공통 설정, 환경별 파일에서 오버라이드 3) 환경 변수 주입: Helm의 --set 또는 --set-file로 CI/CD에서 동적 값 주입 4) 조건부 템플릿: {{- if eq .Values.env "prod" }}로 환경별 리소스 분기 5) Helmfile: 여러 차트와 환경을 선언적으로 관리, 환경별 values 참조 6) Kustomize + Helm: helm template 출력을 Kustomize로 후처리. 시크릿은 values에 평문으로 두지 말고 External Secrets나 Sealed Secrets 사용.', ARRAY['Helm values', '환경 분리', 'Helmfile', '설정 관리'], 'Helm 차트는 환경에 독립적으로 설계하고 values로 환경별 차이를 주입해야 한다.', 'docs/04-deployment-cicd.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('deployment', 'kubernetes', 3, 30, 75, 'Kubernetes 클러스터에서 노드 업그레이드나 유지보수 시 워크로드를 안전하게 이동시키는 절차를 설명하세요.', '노드 유지보수 절차: 1) cordon: kubectl cordon <node>로 새 Pod 스케줄링 차단. 기존 Pod는 계속 실행 2) drain: kubectl drain <node> --ignore-daemonsets --delete-emptydir-data로 Pod 퇴거. Pod는 다른 노드에 재생성됨 3) 유지보수 수행: OS 패치, 하드웨어 교체, 노드 교체 등 4) uncordon: kubectl uncordon <node>로 스케줄링 재개. 안전 장치: 1) PodDisruptionBudget(PDB) 설정으로 최소 가용 Pod 보장. minAvailable 또는 maxUnavailable 지정 2) drain 시 --grace-period와 --timeout 적절히 설정 3) 중요 워크로드는 여러 노드에 분산(podAntiAffinity) 4) 롤링 방식으로 한 번에 하나의 노드만 작업.', ARRAY['cordon', 'drain', 'PodDisruptionBudget', '노드 유지보수'], 'Drain과 PDB 조합으로 워크로드 가용성을 유지하면서 노드 작업을 수행한다.', 'docs/04-deployment-cicd.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('deployment', 'monitoring', 3, 30, 75, '배포 직후 성능 저하나 에러 증가를 빠르게 감지하기 위한 배포 모니터링 전략을 설계하세요.', '배포 모니터링 전략: 1) 배포 이벤트 마커: Grafana Annotation으로 배포 시점 표시. 지표 변화와 배포 상관관계 시각화 2) Golden Signals 대시보드: 에러율, 지연 시간, 트래픽, 포화도를 실시간 모니터링 3) 비교 분석: 배포 전후 5-15분 구간의 지표 비교. 자동 이상 탐지 적용 4) 배포 알림 채널: 배포 시작/완료/롤백을 Slack 등에 알림. 담당자가 모니터링에 집중 5) Canary 지표 분석: Canary와 Baseline의 에러율/지연 시간 실시간 비교 6) 합성 모니터링(Synthetic): 배포 후 자동으로 주요 사용자 시나리오 테스트 실행 7) 로그 이상 탐지: 새로운 에러 패턴이나 에러 로그 급증 감지.', ARRAY['배포 모니터링', 'Golden Signals', 'Grafana Annotation', '이상 탐지'], '배포 직후는 문제가 발생하기 쉬운 시점이므로 집중 모니터링이 필요하다.', 'docs/04-deployment-cicd.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('deployment', 'registry', 3, 30, 75, '컨테이너 이미지 레지스트리의 저장 비용이 급증하고 있습니다. 이미지 보존 정책과 가비지 컬렉션 전략을 설명하세요.', '비용 최적화 전략: 1) 보존 정책 정의: 최신 N개 태그 유지(예: 최근 10개), 특정 기간 이전 이미지 삭제(예: 90일), 정식 릴리스 태그(v*.*.*)는 장기 보존 2) 태그 없는 매니페스트 정리: 태그가 제거되어 dangling 상태인 레이어 삭제 3) 레지스트리별 기능 활용: ECR Lifecycle Policy, GCR Retention Policy, Harbor Tag Retention 4) 멀티스테이지로 이미지 크기 최소화: 빌드 도구 제외, 경량 베이스 사용 5) 베이스 이미지 공유: 공통 베이스를 조직 내에서 재사용하여 중복 레이어 감소 6) 정기적 감사: 사용되지 않는 리포지토리와 이미지 식별 및 정리.', ARRAY['이미지 보존 정책', '가비지 컬렉션', 'ECR Lifecycle', '레지스트리 비용'], '레지스트리 비용 관리는 보존 정책 자동화와 이미지 크기 최적화로 해결한다.', 'docs/04-deployment-cicd.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('deployment', 'infrastructure-as-code', 3, 30, 75, 'Terraform 모듈을 조직 전체에서 재사용하기 위한 모듈 설계 원칙과 버전 관리 전략을 설명하세요.', '모듈 설계 원칙: 1) 단일 책임: 하나의 모듈은 하나의 논리적 리소스 그룹만 관리(VPC, EKS, RDS 등 분리) 2) 입출력 명확화: 필요한 변수를 variables.tf에 명시하고 기본값 제공. 중요 속성은 outputs.tf로 노출 3) 문서화: README에 사용법, 예제, 변수 설명 포함 4) 테스트: Terratest나 terraform validate로 모듈 테스트. 버전 관리: 1) 시맨틱 버저닝: MAJOR(호환성 깨짐).MINOR(기능 추가).PATCH(버그 수정) 2) Git 태그로 버전 릴리스: source = "git::...?ref=v1.2.0" 3) Private Module Registry: Terraform Cloud나 S3 기반 레지스트리로 중앙 관리 4) 버전 제약: 사용처에서 ~> 1.2로 패치만 자동 업데이트 허용.', ARRAY['Terraform 모듈', '시맨틱 버저닝', 'Module Registry', 'IaC 재사용'], '잘 설계된 모듈과 버전 관리는 IaC의 유지보수성과 재사용성을 높인다.', 'docs/04-deployment-cicd.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('deployment', 'ci-cd', 3, 30, 75, 'CI 파이프라인에서 취약점이 있는 컨테이너 이미지가 프로덕션에 배포되는 것을 방지하기 위한 보안 게이트를 설계하세요.', '보안 게이트 설계: 1) 이미지 스캔: Trivy, Snyk, Grype로 빌드 시 이미지 스캔. HIGH/CRITICAL 취약점 발견 시 빌드 실패 2) SBOM 생성: syft로 소프트웨어 구성요소 목록 생성. 라이선스 검증 및 추적성 확보 3) 정책 적용: OPA/Conftest로 Dockerfile 모범 사례 검증(root 실행 금지, 베이스 이미지 허용 목록 등) 4) 이미지 서명: cosign으로 서명, 배포 시 Kyverno/Gatekeeper로 서명 검증 5) 예외 관리: 허용된 취약점 목록(ignore list)과 만료 기한 관리 6) 어드미션 컨트롤: 클러스터에서 검증되지 않은 이미지 배포 차단. 각 단계의 결과를 아티팩트로 저장하여 감사 추적이 가능해야 합니다.', ARRAY['이미지 스캐닝', 'Trivy', 'cosign', '공급망 보안'], 'CI 보안 게이트는 취약한 코드가 프로덕션에 도달하기 전에 차단하는 최후의 방어선이다.', 'docs/04-deployment-cicd.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('deployment', 'gitops', 3, 30, 75, 'ArgoCD를 사용한 GitOps 환경에서 수백 개의 마이크로서비스를 효율적으로 관리하기 위한 구조를 설계하세요.', 'GitOps 구조 설계: 1) App of Apps 패턴: 루트 Application이 모든 하위 Application을 관리. 새 서비스 추가 시 루트에 등록만 하면 자동 배포 2) ApplicationSet: 동적 Application 생성. 디렉토리 구조, Git 파일, 클러스터 목록 기반으로 자동 생성 3) 환경별 분리: overlays/dev, overlays/prod 디렉토리로 Kustomize 활용 4) Project 분리: 팀별 ArgoCD Project로 권한과 배포 대상 분리 5) 동기화 전략: 자동 동기화, Self-Heal, Prune 정책을 서비스 중요도에 따라 차등 적용 6) Wave 기반 배포: sync-wave annotation으로 인프라 → 의존성 → 애플리케이션 순서 제어 7) 알림 통합: Slack/Teams로 동기화 상태 알림.', ARRAY['App of Apps', 'ApplicationSet', 'ArgoCD Project', '대규모 GitOps'], 'GitOps의 확장성은 계층적 구조와 자동화된 Application 관리로 확보한다.', 'docs/04-deployment-cicd.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('deployment', 'rolling-update', 3, 30, 75, 'HTTP 기반 서비스에서 Rolling Update 중 기존 연결이 강제 종료되어 사용자에게 에러가 발생합니다. 이를 방지하기 위한 Graceful Shutdown 구현 방법을 설명하세요.', 'Graceful Shutdown 구현: 1) SIGTERM 핸들링: 애플리케이션이 SIGTERM 수신 시 새 연결 수락 중단, 진행 중인 요청 완료 대기 2) preStop Hook: Kubernetes에서 컨테이너 종료 전 실행. sleep 5-10초로 엔드포인트에서 제거될 시간 확보 3) terminationGracePeriodSeconds: 충분한 시간 설정(기본 30초). 긴 요청이 있다면 늘림 4) 로드밸런서 연동: 서비스에서 Pod IP 제거 후 실제 트래픽이 끊길 때까지 지연 5) 연결 드레이닝: 인그레스 컨트롤러의 draining 설정 활용 6) 헬스체크 즉시 실패: 종료 신호 수신 시 readiness probe 실패 반환. 이 순서가 중요: Endpoint 제거 → 트래픽 중단 확인 → 기존 요청 완료 → 프로세스 종료.', ARRAY['Graceful Shutdown', 'preStop Hook', 'SIGTERM', '연결 드레이닝'], 'Graceful Shutdown은 종료 신호부터 프로세스 종료까지의 전체 흐름을 설계해야 한다.', 'docs/04-deployment-cicd.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('deployment', 'kubernetes', 3, 30, 75, 'Kubernetes에서 HPA(Horizontal Pod Autoscaler)와 Cluster Autoscaler를 함께 사용할 때 발생할 수 있는 문제와 최적화 방법을 설명하세요.', '문제와 최적화: 1) 스케일 아웃 지연: HPA가 Pod를 늘리지만 노드 부족으로 Pending 상태 지속. Cluster Autoscaler가 노드 추가에 수 분 소요. 해결: 오버프로비저닝 Pod로 여유 노드 확보, 또는 Karpenter로 빠른 노드 프로비저닝 2) 스케일 다운 경쟁: HPA가 Pod를 줄이고 Cluster Autoscaler가 노드를 줄이는 타이밍 불일치. 해결: HPA의 scaleDown stabilizationWindowSeconds 설정, Cluster Autoscaler의 scale-down-delay 조정 3) 리소스 요청 정확성: HPA는 requests 대비 사용률로 판단. requests가 부정확하면 스케일링도 부정확. VPA 추천값 참고 4) 커스텀 메트릭: CPU 외에 큐 길이, 요청 수 등 비즈니스 메트릭 기반 스케일링(KEDA 활용).', ARRAY['HPA', 'Cluster Autoscaler', 'Karpenter', '오토스케일링'], 'Pod와 노드 레벨 오토스케일링의 조화로운 동작을 위해 타이밍과 버퍼를 고려해야 한다.', 'docs/04-deployment-cicd.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('deployment', 'ci-cd', 3, 30, 75, 'GitHub Actions 워크플로우에서 OIDC를 사용하여 AWS에 인증하는 것이 장기 Access Key를 사용하는 것보다 안전한 이유를 설명하세요.', 'OIDC 인증의 장점: 1) 단기 자격증명: 각 워크플로우 실행 시 임시 토큰 발급(기본 1시간). 유출되어도 피해 범위 제한 2) 시크릿 저장 불필요: Access Key를 GitHub Secrets에 저장하지 않아 관리 부담과 유출 위험 감소 3) 세밀한 제어: IAM Role의 trust policy로 특정 리포지토리, 브랜치, 환경에서만 assume 허용 4) 감사 추적: CloudTrail에서 어떤 워크플로우가 어떤 권한을 사용했는지 추적 5) 키 로테이션 불필요: 장기 키의 정기 교체 부담 제거 6) 최소 권한 원칙: 워크플로우별로 필요한 최소 권한만 가진 Role 정의. 설정: AWS에 OIDC Identity Provider 등록, IAM Role 생성 및 trust 정책 설정, 워크플로우에서 aws-actions/configure-aws-credentials 사용.', ARRAY['OIDC', 'GitHub Actions', 'IAM Role', '단기 자격증명'], 'CI/CD의 클라우드 인증은 장기 키 대신 OIDC 기반 단기 자격증명을 사용해야 한다.', 'docs/04-deployment-cicd.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('deployment', 'docker', 3, 30, 75, 'distroless 또는 scratch 베이스 이미지를 사용할 때의 장점과 운영상 주의점을 설명하세요.', '장점: 1) 최소 크기: 불필요한 패키지 없이 애플리케이션만 포함. scratch는 0바이트에서 시작 2) 보안 강화: 셸, 패키지 관리자 없어 공격 표면 최소화. 취약점 스캔 대상 감소 3) 빠른 배포: 이미지 풀 시간 단축 4) 불변성: 런타임에 패키지 설치 불가로 구성 변경 방지. 주의점: 1) 디버깅 어려움: 셸이 없어 kubectl exec 불가. kubectl debug로 임시 컨테이너 연결 필요 2) 정적 빌드 필요: scratch는 동적 라이브러리 없음. Go는 CGO_ENABLED=0, 다른 언어는 정적 링킹 필요 3) 인증서 번들: HTTPS 호출을 위한 CA 인증서 별도 포함 필요 4) 사용자 설정: 기본 사용자 없으므로 USER 지시어로 명시.', ARRAY['distroless', 'scratch', '최소 이미지', '컨테이너 보안'], 'distroless/scratch는 보안과 크기 최적화에 탁월하지만 운영 방식 변화가 필요하다.', 'docs/04-deployment-cicd.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('deployment', 'kubernetes', 3, 30, 75, 'Kubernetes에서 ConfigMap이나 Secret이 변경되었을 때 Pod를 자동으로 재시작하는 방법을 설명하세요.', '자동 재시작 방법: 1) Reloader: stakater/Reloader 컨트롤러 설치. ConfigMap/Secret에 reloader.stakater.com/auto: "true" 어노테이션 추가하면 변경 시 관련 Deployment 롤링 업데이트 2) 해시 기반 어노테이션: CI/CD에서 ConfigMap 내용의 해시를 계산하여 Deployment의 spec.template.metadata.annotations에 추가. 해시 변경 시 Pod 재생성 3) 볼륨 마운트 활용: ConfigMap을 볼륨으로 마운트하면 kubelet이 주기적으로 업데이트(기본 1분). 단, 애플리케이션이 파일 변경을 감지해야 함 4) 환경변수는 재시작 필요: envFrom으로 주입된 값은 Pod 재시작 없이 변경 불가 5) immutable ConfigMap: 변경 불가로 설정하면 새 ConfigMap 생성 후 참조 변경 방식. Reloader가 가장 널리 사용되는 솔루션입니다.', ARRAY['ConfigMap 재시작', 'Reloader', 'Secret 갱신', '설정 변경'], 'ConfigMap/Secret 변경의 자동 반영은 애플리케이션 특성에 맞는 전략을 선택해야 한다.', 'docs/04-deployment-cicd.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('deployment', 'terraform', 3, 30, 75, '여러 팀이 동시에 같은 Terraform State를 수정하려 할 때 발생하는 충돌을 방지하기 위한 State Locking과 워크플로우를 설명하세요.', 'State Locking 구현: 1) 백엔드 설정: S3+DynamoDB(AWS), GCS(GCP), Azure Blob 등 잠금 지원 백엔드 사용 2) DynamoDB 테이블: LockID를 파티션 키로 하는 테이블 생성. terraform apply 시 자동 잠금 획득 3) 잠금 타임아웃: 비정상 종료로 잠금이 남으면 terraform force-unlock으로 해제(신중히 사용). 워크플로우: 1) CI/CD에서만 apply: 로컬에서는 plan만 허용, apply는 PR 머지 후 CI에서 실행 2) PR 기반 변경: Atlantis, Terraform Cloud로 PR에서 plan 결과 검토 후 승인 시 apply 3) 환경별 State 분리: 워크스페이스나 디렉토리로 dev/staging/prod State 분리하여 독립 작업 4) 변경 큐잉: 동시 변경 요청을 순차 처리.', ARRAY['State Locking', 'DynamoDB', 'Atlantis', 'Terraform 협업'], '팀 협업 환경에서 Terraform은 State Locking과 PR 기반 워크플로우가 필수다.', 'docs/04-deployment-cicd.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('deployment', 'canary', 3, 30, 75, 'Service Mesh(Istio)를 활용한 트래픽 기반 Canary 배포와 Kubernetes 네이티브 방식의 차이점과 장단점을 비교하세요.', 'Kubernetes 네이티브(Deployment 기반): Pod 수 비율로 트래픽 분배. 예: 10개 중 1개가 새 버전이면 10% 트래픽. 장점: 추가 도구 불필요, 간단. 단점: 세밀한 비율 제어 어려움, 정확히 1%는 100개 Pod 필요. Service Mesh(Istio VirtualService): 네트워크 레벨에서 가중치 기반 트래픽 분배. Pod 수와 무관하게 정확히 1% 라우팅 가능. 장점: 세밀한 트래픽 제어, 헤더/쿠키 기반 라우팅(특정 사용자에게만 새 버전), 메트릭 수집 내장. 단점: Service Mesh 도입 복잡성, 리소스 오버헤드(사이드카), 학습 곡선. Argo Rollouts는 양쪽 방식 모두 지원하며 Service Mesh 없이도 Nginx Ingress 연동으로 가중치 라우팅 가능.', ARRAY['Istio', 'VirtualService', 'Service Mesh', '트래픽 분배'], '정밀한 트래픽 제어가 필요하면 Service Mesh, 단순함이 우선이면 Deployment 기반을 선택한다.', 'docs/04-deployment-cicd.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('deployment', 'ci-cd', 3, 30, 75, 'CI 파이프라인의 실행 시간을 분석하고 최적화하기 위한 체계적인 접근 방법을 설명하세요.', 'CI 최적화 접근법: 1) 병목 식별: 각 단계별 소요 시간 측정. 가장 오래 걸리는 단계부터 최적화 2) 의존성 캐싱: package-lock.json, go.sum 해시 기반 캐시 키. 캐시 히트 시 설치 시간 대폭 단축 3) 병렬화: 독립적인 테스트/빌드를 동시 실행. GitHub Actions의 matrix strategy, 모노레포의 affected 분석 4) 계층적 테스트: 빠른 단위 테스트 먼저, 느린 통합/E2E 테스트는 조건부 실행 5) 증분 빌드: 변경된 부분만 빌드. 빌드 시스템(Gradle, Bazel)의 캐시 활용 6) 리소스 최적화: 더 큰 러너 사용(빌드 시간 vs 비용 트레이드오프) 7) 불필요한 단계 제거: 매번 실행 불필요한 작업은 조건부 또는 스케줄 실행. 정기적으로 파이프라인 성능을 리뷰하고 개선해야 합니다.', ARRAY['CI 최적화', '캐싱', '병렬화', '빌드 시간'], 'CI 최적화는 개발자 생산성과 피드백 루프 속도에 직접적인 영향을 미친다.', 'docs/04-deployment-cicd.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('deployment', 'kubernetes', 3, 30, 75, 'Kubernetes 클러스터에서 리소스 요청(requests)과 제한(limits)을 적절하게 설정하기 위한 전략과 도구를 설명하세요.', '리소스 설정 전략: 1) 관측 기반 설정: 프로덕션 메트릭(Prometheus)으로 실제 사용량 분석 후 requests 설정. P95-P99 사용량을 기준으로 2) VPA 활용: Vertical Pod Autoscaler를 추천 모드(Off)로 실행하여 적절한 값 제안 받기 3) Requests vs Limits: requests는 스케줄링 기준, limits는 OOM Kill 임계값. limits를 requests의 1.5-2배로 설정하여 버스트 허용 4) 메모리 특성: Java/Node는 힙 크기 고정되므로 예측 가능. 메모리는 limits 초과 시 OOM Kill 5) CPU 특성: limits 초과 시 스로틀링(성능 저하). CPU는 limits을 높게 또는 미설정 고려 6) 네임스페이스 쿼터: ResourceQuota로 팀별 총량 제한, LimitRange로 기본값과 범위 설정. 초기에는 보수적으로 설정하고 운영 데이터 기반으로 조정합니다.', ARRAY['requests', 'limits', 'VPA', 'ResourceQuota'], '적절한 리소스 설정은 안정성, 효율성, 비용의 균형을 맞추는 핵심이다.', 'docs/04-deployment-cicd.md');

INSERT INTO questions (category, subcategory, difficulty, level_min, level_max, question_text, correct_answer, keywords, explanation, source_doc) VALUES
('deployment', 'gitops', 3, 30, 75, 'GitOps 환경에서 개발자가 PR을 올리면 임시 Preview 환경이 자동 생성되고 머지 시 삭제되는 시스템을 설계하세요.', 'Preview 환경 설계: 1) PR 이벤트 트리거: GitHub Actions/Webhook으로 PR open/close 감지 2) 네임스페이스 생성: PR 번호 기반 고유 네임스페이스(preview-pr-123) 생성 3) 이미지 빌드: PR 브랜치에서 이미지 빌드, 태그는 pr-123-<sha> 4) 매니페스트 생성: Kustomize/Helm으로 해당 이미지와 네임스페이스 사용하는 매니페스트 생성 5) ArgoCD 연동: ApplicationSet의 Pull Request Generator 또는 수동 Application 생성 6) DNS/Ingress: 와일드카드 DNS(*.preview.example.com)와 동적 Ingress로 pr-123.preview.example.com 접근 7) 리소스 제한: 네임스페이스 ResourceQuota로 비용 통제 8) 자동 정리: PR 머지/클로즈 시 네임스페이스와 Application 삭제. PR 코멘트에 Preview URL 자동 게시.', ARRAY['Preview 환경', 'Pull Request Generator', '임시 환경', '동적 환경'], 'Preview 환경은 변경사항을 격리된 상태에서 검증할 수 있어 품질과 협업을 개선한다.', 'docs/04-deployment-cicd.md');
